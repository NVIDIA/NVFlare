{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d4afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict,Optional\n",
    "\n",
    "def client_gpu_assignments(clients: List[str], gpu_ids: List[int]) -> Dict[str, List[int]]:\n",
    "    n_gpus = len(gpu_ids)\n",
    "    n_clients = len(clients)\n",
    "    gpu_assignments = {}\n",
    "    if n_gpus == 0:\n",
    "        for client in clients:\n",
    "            gpu_assignments[client] = []\n",
    "\n",
    "    if 0 < n_gpus <= n_clients:\n",
    "        for client_id, client in enumerate(clients):\n",
    "            gpu_index = client_id % n_gpus\n",
    "            gpu_assignments[client] = [gpu_ids[gpu_index]]\n",
    "    elif n_gpus > n_clients > 0:\n",
    "        client_name_map = {}\n",
    "        for client_id, client in enumerate(clients):\n",
    "            client_name_map[client_id] = client\n",
    "\n",
    "        for gpu_index, gpu_id in enumerate(gpu_ids):\n",
    "            client_id = gpu_index % n_clients\n",
    "            client = client_name_map[client_id]\n",
    "            if client not in gpu_assignments:\n",
    "                gpu_assignments[client] = []\n",
    "            gpu_assignments[client].append(gpu_ids[gpu_index])\n",
    "    return gpu_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531daf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site-1': [0, 3], 'site-2': [1, 4], 'site-3': [2, 5]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_gpu_assignments(clients = [\"site-1\", \"site-2\", \"site-3\"], gpu_ids = [0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bf154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _run_poc(cmd_type: str, poc_workspace: str, gpu_ids: List[int], excluded: list, white_list=None):\n",
    "    if white_list is None:\n",
    "        white_list = []\n",
    "    package_commands = _build_commands(cmd_type, poc_workspace, excluded, white_list)\n",
    "    clients = _get_clients(package_commands)\n",
    "    gpu_assignments: Dict[str, List[int]] = client_gpu_assignments(clients, gpu_ids)\n",
    "    for package_name, cmd_path in package_commands:\n",
    "        print(f\"'{cmd_type}', package: '{package_name}', executing '{cmd_path}'\")\n",
    "        if package_name == global_packages[SC.FLARE_PROJ_ADMIN]:\n",
    "            sync_process(cmd_path)\n",
    "        elif package_name == global_packages[SC.FLARE_SERVER]:\n",
    "            async_process(cmd_path, None)\n",
    "        else:\n",
    "            async_process(cmd_path, gpu_assignments[package_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b3a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [\"site-1\", \"site-2\", \"site-3\"]\n",
    "gpu_ids = [0,1,2,3,4,5]\n",
    "gpu_assignments: Dict[str, List[int]] = client_gpu_assignments(clients, gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98955df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_env(gpu_ids: Optional[List[int]] = None):\n",
    "    import os\n",
    "    my_env = None\n",
    "    if gpu_ids:\n",
    "        my_env = os.environ.copy()\n",
    "        if len(gpu_ids) > 0:\n",
    "            my_env[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(gid) for gid in gpu_ids])\n",
    "\n",
    "    if global_packages.get(SC.IS_DOCKER_RUN):\n",
    "        my_env = os.environ.copy() if my_env is None else my_env\n",
    "        if gpu_ids and len(gpu_ids) > 0:\n",
    "            my_env[\"GPU2USE\"] = my_env[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "        my_env[\"MY_DATA_DIR\"] = os.path.join(get_poc_workspace(), \"data\")\n",
    "\n",
    "    return my_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f8e0edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,3'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "gpu_ids2 = gpu_assignments[\"site-1\"]\n",
    "my_env = os.environ.copy()\n",
    "my_env[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(gid) for gid in gpu_ids2])\n",
    "my_env[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13021d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
