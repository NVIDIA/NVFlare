{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5933f2eb-463a-4d01-a806-b6fc0fe9b4de",
   "metadata": {},
   "source": [
    "# NVFLARE JOB CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce4e61-da7f-4ba1-96f1-822c578e53a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook, we will go through the different commands of the Job CLI to show the syntax and usage of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154531fd-2a94-4062-bbc6-76086b099093",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install NVIDIA FLARE\n",
    "\n",
    "For this notebook, we will need a running NVFLARE project that we can connect to.\n",
    "Follow the [Installation](https://nvflare.readthedocs.io/en/main/getting_started.html#installation) \n",
    "instructions to set up an environment that has NVIDIA FLARE installed if you do not have one already.\n",
    "\n",
    "If you use job submit CLI, you will need a running NVFLARE system with client and server. You can either running a local system via nvflare poc commands, or \n",
    "use the running production systemm. \n",
    "\n",
    "To see how to setup a local system, please refer to setup_poc tutorial. \n",
    "\n",
    "\n",
    "## Step-by-step work though: from creating a job to running a job. \n",
    "\n",
    "Assuming we like to run with CIFAR10 data, we have converted the CIFAR10 with pytorch training code to a 2-client federated learning [program](../hello-world/step-by-step/cifar10/code]. To demonstrate the Job CLI, we would like to use the standard Scatter and Gatter (SAG) workflow pattern. \n",
    "\n",
    "Now, we would like to see what are the available pre-configured job templates the user can use and modify. \n",
    "\n",
    "\n",
    "### Checkout the availalble nvflare job templates\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c635e02-7fe6-401c-82d2-e2cde1dc86c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### List Job Templates\n",
    "\n",
    "NVFLARE 2.4.0 release introduces an job templates where the different type of job configurations are created as templates.  \n",
    "\n",
    "To list the available templates, you can use the ```nvflare job list_templates``` command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "447619d5-d917-4d93-b806-6c673e216b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following job templates are available: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  name            Description                                                  Controller Type      Client Category     \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  sag_cross_np    scatter & gather and cross-site validation using numpy       server               client executor     \n",
      "  sag_lightning   scatter & gather workflow using lightning                    server               client_api          \n",
      "  sag_pt          scatter & gather workflow using pytorch                      server               client_api          \n",
      "  stats_df        FedStats: tabular data with pandas                           server               stats executor      \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job list_templates -d \"../../job_templates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abba0f2-17c9-4e09-a34e-8543238e4039",
   "metadata": {},
   "source": [
    "Where the -d \"<job_templates_dir>\" or --job_template_dir \"<job_templates_dir>\" is the location of the job_templates. \n",
    "\n",
    "We can also simplify the command by simply \n",
    "```\n",
    "! nvflare job list_templates\n",
    "```\n",
    "\n",
    "without specify the  -d \"<job_templates_dir>\" location. When the job templates directory is not specified, the Job CLI will try to find the location in the following logics: \n",
    "\n",
    "* see if the NVFALRE_HOME env variable is set, if yes, we assume that you have clone the github repo and the job_templates is located at \n",
    " \n",
    " ```${NVFLARE_HOME}/job_templates```\n",
    " \n",
    "* If NVFLARE_HOME env. variable is not set, the CLI Job will look at the nvflare hidden config directory \n",
    "\n",
    "```\n",
    "cat ~/.nvflare/config.conf \n",
    "\n",
    "startup_kit {\n",
    "  path = \"/tmp/nvflare/poc1/example_project/prod_00\"\n",
    "}\n",
    "poc_workspace {\n",
    "  path = \"/tmp/nvflare/poc1\"\n",
    "}\n",
    "job_template {\n",
    "  path = \"../../job_templates\"\n",
    "}\n",
    "\n",
    "```\n",
    "and will use the job_templates path sepecified in the location.  \n",
    "\n",
    "once you used the -d <job_template_dir> once, the ~/.nvflare/config.conf will be updated. you don't need to specify -d again. \n",
    "\n",
    "You can also directly edit this file or simply use\n",
    "\n",
    "```\n",
    "nvflare config -jt ../../job_templates. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bea478d-42fb-4223-8155-3c996699a052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -jt ../../job_templates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7b708-40e9-4f4f-beec-b83d0e893a0b",
   "metadata": {},
   "source": [
    "Now we can list again with job_templates directory argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bab293-7fef-476f-8aa9-f2b2868a0fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following job templates are available: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  name            Description                                                  Controller Type      Client Category     \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  sag_cross_np    scatter & gather and cross-site validation using numpy       server               client executor     \n",
      "  sag_lightning   scatter & gather workflow using lightning                    server               client_api          \n",
      "  sag_pt          scatter & gather workflow using pytorch                      server               client_api          \n",
      "  stats_df        FedStats: tabular data with pandas                           server               stats executor      \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10720b0b-af4c-4d71-a751-2d5c301eb05a",
   "metadata": {
    "tags": []
   },
   "source": [
    "one we find the job templates that might fit our needs, we can use the job template name to create a new job folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd0cc7-f410-457e-a6bd-d4c999182850",
   "metadata": {},
   "source": [
    "### Create a job folder\n",
    "\n",
    "Since our code is written in pytorch and we would like to try FedAvg algorithm using Scatter & Gather (SAG) workflow, the job template **\"sag_pt\"** is what we are looking for. We will use this template to create our job folder. \n",
    "\n",
    "Creat a job folder is to create a job directory that contains the job configuration.  First, we create job folder and intend to be modified, without specify our code.\n",
    "\n",
    "\n",
    "#### First Try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3c9750-070f-4655-9128-757ab136b30d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  config_exchange.conf           exchange_format                pytorch                                                                \n",
      "  config_exchange.conf           transfer_type                  DIFF                                                                   \n",
      "\n",
      "  config_fed_client.conf         app_config                                                                                            \n",
      "  config_fed_client.conf         app_script                     cifar10.py                                                             \n",
      "  config_fed_client.conf         global_evaluation              True                                                                   \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                                                    \n",
      "  config_fed_client.conf         heartbeat_timeout              60                                                                     \n",
      "  config_fed_client.conf         pipe_name                      pipe                                                                   \n",
      "  config_fed_client.conf         read_interval                  0.1                                                                    \n",
      "  config_fed_client.conf         result_poll_interval           0.1                                                                    \n",
      "  config_fed_client.conf         script                         python custom/{app_script}  {app_co SubprocessLauncher                 \n",
      "  config_fed_client.conf         training                       True                                                                   \n",
      "  config_fed_client.conf         workers                        1                                                                      \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHTS                             InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         num_rounds                     2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            True                                InTimeAccumulateWeightedAggregator \n",
      "\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    1                                                                      \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -w sag_pt -force\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf08b1e-ca7c-4902-b8d0-01968c3801be",
   "metadata": {
    "tags": []
   },
   "source": [
    "The above command create a job folder at ```/tmp/nvflare/my_job``` with job template ```sag_pt```. \n",
    "We can see few configuration files are created. And some of the configurations are open to overwrite. We can take a look at the job_folder structure first. \n",
    "\n",
    "If you have ```tree``` command installed ( ```python -m pip install``` on linux), you can use the ```tree``` command, otherwise, you can just \"ls -al\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87410e3-c498-44ae-b7f7-2a51af237e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/nvflare/my_job\u001b[0m\n",
      "├── \u001b[01;34mapp\u001b[0m\n",
      "│   ├── \u001b[01;34mconfig\u001b[0m\n",
      "│   │   ├── config_exchange.conf\n",
      "│   │   ├── config_fed_client.conf\n",
      "│   │   └── config_fed_server.conf\n",
      "│   └── \u001b[01;34mcustom\u001b[0m\n",
      "└── meta.conf\n",
      "\n",
      "3 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "! tree /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393ae90b-640b-4dd7-a325-e2b026e7703b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = \"my_job\"\n",
      "resource_spec {}\n",
      "deploy_map {\n",
      "  app = [\n",
      "    \"@ALL\"\n",
      "  ]\n",
      "}\n",
      "min_clients = 1\n",
      "mandatory_clients = []\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/nvflare/my_job/meta.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142c0a0d-8c40-4fc3-a201-08764cde0c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  exchange_path = \"./\"\n",
      "  exchange_format =  \"pytorch\"\n",
      "  transfer_type =  \"DIFF\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat /tmp/nvflare/my_job/app/config/config_exchange.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba16495-eaa3-431c-84da-432635ec8e29",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice the app_name is \"my_job\" and config_exchange is used for Client API where it specify the data exchange path, exchange format is for pytorch and the model diff will be transferred. Let's look at the server side configuration. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c4f50f-b715-42de-a217-f2feced182ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  # version of the configuration\n",
      "  format_version = 2\n",
      "\n",
      "  # task data filter: if filters are provided, the filter will filter the data flow out of server to client.\n",
      "  task_data_filters =[]\n",
      "\n",
      "  # task result filter: if filters are provided, the filter will filter the result flow out of server to client.\n",
      "  task_result_filters = []\n",
      "\n",
      " # workflows: Array of workflows the control the Federated Learning workflow lifecycle.\n",
      " # One can specify mutliple workflows. The NVFLARE will run them in the order specified.\n",
      "  workflows = [\n",
      "      {\n",
      "        # 1st workflow\"\n",
      "        id = \"scatter_and_gather\"\n",
      "\n",
      "        # name = ScatterAndGather, path is the class path of the scatterAndGatter controller.\n",
      "        path = \"nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather\"\n",
      "        args {\n",
      "            # argument of the ScatterAndGather class.\n",
      "            # min number of clients required for ScatterAndGather controller to move to the next round\n",
      "            # during the workflow cycle. The controller will wait until the min_clinets returned from clients\n",
      "            # before move to the next step.\n",
      "            min_clients = 2\n",
      "\n",
      "            # number of global round of the training.\n",
      "            num_rounds = 2\n",
      "\n",
      "            # starting round is 0-based\n",
      "            start_round = 0\n",
      "\n",
      "            # after received min number of clients' result,\n",
      "            # how much time should we wait further before move to the next step\n",
      "            wait_time_after_min_received = 0\n",
      "\n",
      "            # For ScatterAndGatter, the server will aggregate the weights based on the client's result.\n",
      "            # the aggregagtor component id is named here. One can use the this ID to find the corresponding\n",
      "            # aggregator component listed beflow\n",
      "            #\n",
      "            aggregator_id = \"aggregator\"\n",
      "\n",
      "            # The Scatter and Gather controller use an persistor to load the model and save the model.\n",
      "            # The persistent component can be identified by component ID specified here.\n",
      "            persistor_id = \"persistor\"\n",
      "\n",
      "            # Shareable to a communication message, i.e. shared between clients and server.\n",
      "            # Sahreable generator is a component that responsible to take the model convert to/from this communication message: shearable.\n",
      "            # The component can be identified via \"shareable_generator_id\"\n",
      "            shareable_generator_id =  \"shareable_generator\"\n",
      "\n",
      "            # train task name: Client will start training once received such task.\n",
      "            train_task_name =  \"train\"\n",
      "\n",
      "            # train timeout in second. If zero, meaning no timeout.\n",
      "            train_timeout =  0\n",
      "        }\n",
      "      }\n",
      "  ]\n",
      "\n",
      "  # List of components used in the server side workflow.\n",
      "  components = [\n",
      "    {\n",
      "      # This is the persistence component used in above workflow.\n",
      "      # PTFileModelPersistor is a Pytorch persistor which save/read the model to/from file.\n",
      "\n",
      "      id = \"persistor\"\n",
      "      path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\n",
      "\n",
      "      # the persitor class take mode class as argument\n",
      "      # and the model path take \"Net\" model as class\n",
      "      # This imply that the model is initialized from Server-side. The initialized model \"net.Net\",\n",
      "      # will be broadcast to all the clients to start the training.\n",
      "      # This implies that there will be an \"net.py\" file with class name \"Net\".\n",
      "      # If you model file name is not \"net.py\" and class name is not \"Net\", please modify there.\n",
      "\n",
      "      args.model.path = \"net.Net\"\n",
      "    },\n",
      "    {\n",
      "      # This is the generator that convert the model to shareable communication message structure used in workflow\n",
      "      id = \"shareable_generator\"\n",
      "      path = \"nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator\"\n",
      "      args = {}\n",
      "    },\n",
      "    {\n",
      "      # This is the aggregator that perform the weighted average aggergation.\n",
      "      # the aggragtion is \"in-time\", so it doesn't wait for client results, but aggregates as soon as it received the data.\n",
      "      id = \"aggregator\"\n",
      "      path =  \"nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator\"\n",
      "      args.expected_data_kind = \"WEIGHTS\"\n",
      "    },\n",
      "    {\n",
      "      # This component is not directly used in Workflow.\n",
      "      # it select the best model based on the incoming global validation metrics.\n",
      "      id = \"model_selector\"\n",
      "      name =  \"IntimeModelSelector\"\n",
      "      args.key_metric = \"accuracy\"\n",
      "    }\n",
      "  ]\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/nvflare/my_job/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24bebc20-5351-40a7-af7b-0a3c9bb271ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  # version of the configuration\n",
      "  format_version = 2\n",
      "\n",
      "  # This is application scripts which will be invoked.\n",
      "  # Client can replaced this script with user's own traning script.\n",
      "  app_script = \"cifar10.py\"\n",
      "\n",
      "  # Additional arguments needed by the training code. For example, in lightning, these can be --trainer.batch_size=xxx.\n",
      "  app_config = \"\"\n",
      "\n",
      "  # Client Computing Executors.\n",
      "  executors = [\n",
      "    {\n",
      "      # tasks the executors are defined to handle\n",
      "      tasks = [\"train\"]\n",
      "\n",
      "      # This particular executor\n",
      "      executor {\n",
      "\n",
      "        # Eexecutor name : PTFilePipeLauncherExecutor\n",
      "        # This is an executor for pytorch. The underline data exchange is using FilePipe.\n",
      "        path = \"nvflare.app_opt.pt.file_pipe_launcher_executor.PTFilePipeLauncherExecutor\"\n",
      "\n",
      "        args {\n",
      "\n",
      "          # This executor take an component named \"launcher\"\n",
      "          launcher_id = \"launcher\"\n",
      "\n",
      "          heartbeat_timeout = 60\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "\n",
      "  # this defined an arru of task data filters. If provided, it will control the data from to server\n",
      "  task_data_filters =  []\n",
      "\n",
      "  # this defined an arru of task result filters. If provided, it will control the result from to server\n",
      "  task_result_filters = []\n",
      "\n",
      "  components =  [\n",
      "    {\n",
      "     # This \"launcher\" component\n",
      "      id = \"launcher\"\n",
      "\n",
      "      # the name of component is SubprocessLauncher and path is the class path\n",
      "      path = \"nvflare.app_common.launchers.subprocess_launcher.SubprocessLauncher\"\n",
      "\n",
      "      # the launcher will invoke the scrupt\n",
      "      args.script = \"python custom/{app_script}  {app_config} \"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! ! cat /tmp/nvflare/my_job/app/config/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11767829-65e5-47e1-bae1-6c587c315100",
   "metadata": {},
   "source": [
    "> Note both client and server configurations are nicely commented with explainations. \n",
    "> But if you create the job with customizations such as -f or configurations, the configurations files would be overwritten, which will the comments will be > lost in the final files. Just a note. You can always fine \n",
    "\n",
    "### Show variables\n",
    "\n",
    "Now, we can see the job folder is auto-created for me with pre-defined configurations. We need to make sure this template works for our code and the variables can be updated. Let's check the variables again with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74adcc28-9f52-4f2b-b4b2-1bd9b053dd80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  config_exchange.conf           exchange_format                pytorch                                                                \n",
      "  config_exchange.conf           transfer_type                  DIFF                                                                   \n",
      "\n",
      "  config_fed_client.conf         app_config                                                                                            \n",
      "  config_fed_client.conf         app_script                     train.py                                                               \n",
      "  config_fed_client.conf         global_evaluation              True                                                                   \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                                                    \n",
      "  config_fed_client.conf         heartbeat_timeout              60                                                                     \n",
      "  config_fed_client.conf         pipe_name                      pipe                                                                   \n",
      "  config_fed_client.conf         read_interval                  0.1                                                                    \n",
      "  config_fed_client.conf         result_poll_interval           0.1                                                                    \n",
      "  config_fed_client.conf         script                         python custom/{app_script}  {app_co SubprocessLauncher                 \n",
      "  config_fed_client.conf         training                       True                                                                   \n",
      "  config_fed_client.conf         workers                        1                                                                      \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHTS                             InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         num_rounds                     1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            True                                InTimeAccumulateWeightedAggregator \n",
      "\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    1                                                                      \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job show_variables -j /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ede943-4c76-42b2-81ad-8d9364637cfb",
   "metadata": {},
   "source": [
    "You can see there are many variables we might awant to change.  \n",
    "\n",
    "* I want to change num_rounds to 1 to test out in simular first\n",
    "* I also to use my own cifar10 code which already written based on Flare 2.4.0 Client API.\n",
    "\n",
    "Let's do the send try, \n",
    "\n",
    "#### The second Try\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4878eb4d-8cf3-43c9-892c-2f43a5ad1511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nvflare job create [-h] [-j [JOB_FOLDER]] [-w [TEMPLATE]] [-s [SCRIPT]]\n",
      "                          [-sd [SCRIPT_DIR]]\n",
      "                          [-f [CONFIG_FILE [CONFIG_FILE ...]]]\n",
      "                          [-a [APP_CONFIG [APP_CONFIG ...]]] [-debug] [-force]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -j [JOB_FOLDER], --job_folder [JOB_FOLDER]\n",
      "                        job_folder path, default to current directory\n",
      "  -w [TEMPLATE], --template [TEMPLATE]\n",
      "                        template name, use liste_templates to see available\n",
      "                        jobs from job templates\n",
      "  -s [SCRIPT], --script [SCRIPT]\n",
      "                        code script such as train.py\n",
      "  -sd [SCRIPT_DIR], --script_dir [SCRIPT_DIR]\n",
      "                        script directory contains additional related files.\n",
      "                        All files or directories under this directory will be\n",
      "                        copied over to the custom directory.\n",
      "  -f [CONFIG_FILE [CONFIG_FILE ...]], --config_file [CONFIG_FILE [CONFIG_FILE ...]]\n",
      "                        Training config file with corresponding optional\n",
      "                        key=value pairs. If key presents in the preceding\n",
      "                        config file, the value in the config file will be\n",
      "                        overwritten by the new value\n",
      "  -a [APP_CONFIG [APP_CONFIG ...]], --app_config [APP_CONFIG [APP_CONFIG ...]]\n",
      "                        key=value options will be passed directly to script\n",
      "                        argument\n",
      "  -debug, --debug       debug is on\n",
      "  -force, --force       force create is on, if -force, overwrite existing\n",
      "                        configuration with newly created configurations\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d32eb0-1384-4d49-9b6e-a369c53e7163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  config_exchange.conf           exchange_format                pytorch                                                                \n",
      "  config_exchange.conf           transfer_type                  DIFF                                                                   \n",
      "\n",
      "  config_fed_client.conf         app_config                                                                                            \n",
      "  config_fed_client.conf         app_script                     train.py                                                               \n",
      "  config_fed_client.conf         global_evaluation              True                                                                   \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                                                    \n",
      "  config_fed_client.conf         heartbeat_timeout              60                                                                     \n",
      "  config_fed_client.conf         pipe_name                      pipe                                                                   \n",
      "  config_fed_client.conf         read_interval                  0.1                                                                    \n",
      "  config_fed_client.conf         result_poll_interval           0.1                                                                    \n",
      "  config_fed_client.conf         script                         python custom/{app_script}  {app_co SubprocessLauncher                 \n",
      "  config_fed_client.conf         training                       True                                                                   \n",
      "  config_fed_client.conf         workers                        1                                                                      \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHTS                             InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         num_rounds                     1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            True                                InTimeAccumulateWeightedAggregator \n",
      "\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    1                                                                      \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -force -w sag_pt -f config_fed_server.conf num_rounds=1 -s ../hello-world/step-by-step/cifar10/code/fl/train.py -sd ../hello-world/step-by-step/cifar10/code/fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aae893-0371-488e-9883-aa2d736a6807",
   "metadata": {},
   "source": [
    "Now, num_rounds is set to 1 and app_script is \"train.py\", the pyton script will invoked ```python custom/{app_script}```, this essentially do ```python custom/train.py```. Now, let's \n",
    "take a look the code structure again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09239cb-39cb-4ccf-858e-619d2b1072a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/nvflare/my_job\u001b[0m\n",
      "├── \u001b[01;34mapp\u001b[0m\n",
      "│   ├── \u001b[01;34mconfig\u001b[0m\n",
      "│   │   ├── config_exchange.conf\n",
      "│   │   ├── config_fed_client.conf\n",
      "│   │   └── config_fed_server.conf\n",
      "│   └── \u001b[01;34mcustom\u001b[0m\n",
      "│       ├── net.py\n",
      "│       └── train.py\n",
      "└── meta.conf\n",
      "\n",
      "3 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "! tree /tmp/nvflare/my_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103b02a-1ada-4201-b848-811d237be3fd",
   "metadata": {},
   "source": [
    "Notice that the code we had written is copied to the job directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fa61b-2c30-4421-a74c-75f0725a86f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice on config_fed_server.conf, we have ```PTFileModelPersistor``` is file-based persistor for pytorch. It requires net.Net class which used for model initialization and also for save the final model\n",
    "this file \"net.py\" is matching such configuration.  If your model file name and class Name is not matching to net.Net, we will need to update configuration to match this. \n",
    "\n",
    "We will rest of values as default. And try to run the job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9308ba5-ad4d-4f3f-9377-76fd6a253687",
   "metadata": {},
   "source": [
    "### Run the Job in simulator \n",
    "\n",
    "We can first run the job in simulator and see if we have any issues. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2451ab27-68cf-4ab3-ae7f-f276f21185a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-25 20:40:47,639 - SimulatorRunner - WARNING - The number of simulator clients is not provided. Setting it to default: 2\n",
      "2023-08-25 20:40:47,639 - SimulatorRunner - WARNING - The number of threads is not provided. Set it to default: 1\n",
      "2023-08-25 20:40:47,639 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2023-08-25 20:40:47,640 - CoreCell - INFO - server: creating listener on tcp://0:57079\n",
      "2023-08-25 20:40:47,659 - CoreCell - INFO - server: created backbone external listener for tcp://0:57079\n",
      "2023-08-25 20:40:47,659 - ConnectorManager - INFO - 11671: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2023-08-25 20:40:47,659 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:64594] is starting\n",
      "2023-08-25 20:40:48,161 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:64594\n",
      "2023-08-25 20:40:48,161 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:57079] is starting\n",
      "2023-08-25 20:40:48,211 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 34333\n",
      "2023-08-25 20:40:48,211 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2023-08-25 20:40:48,214 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2023-08-25 20:40:48,225 - ClientManager - INFO - Client: New client site-1@192.168.86.32 joined. Sent token: 645d0fbf-f969-479b-bf0f-da701349e3ea.  Total clients: 1\n",
      "2023-08-25 20:40:48,225 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:645d0fbf-f969-479b-bf0f-da701349e3ea SSID:\n",
      "2023-08-25 20:40:48,227 - ClientManager - INFO - Client: New client site-2@192.168.86.32 joined. Sent token: 84cbf31f-d055-421f-8bad-b89771dcf4e1.  Total clients: 2\n",
      "2023-08-25 20:40:48,228 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:84cbf31f-d055-421f-8bad-b89771dcf4e1 SSID:\n",
      "2023-08-25 20:40:48,228 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2023-08-25 20:40:48,228 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2023-08-25 20:40:48,230 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "2023-08-25 20:40:49.488957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 20:40:50.080318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-25 20:40:51,189 - IntimeModelSelector - INFO - model selection weights control: None\n",
      "2023-08-25 20:40:51,201 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2023-08-25 20:40:51,201 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) ...\n",
      "2023-08-25 20:40:51,201 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Initializing ScatterAndGather workflow.\n",
      "2023-08-25 20:40:51,202 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Workflow scatter_and_gather (<class 'nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather'>) started\n",
      "2023-08-25 20:40:51,203 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Beginning ScatterAndGather training phase.\n",
      "2023-08-25 20:40:51,203 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Round 0 started.\n",
      "2023-08-25 20:40:51,203 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: scheduled task train\n",
      "2023-08-25 20:40:51,491 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2023-08-25 20:40:52,492 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: None\n",
      "2023-08-25 20:40:53,507 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-08-25 20:40:53,558 - CoreCell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:57079\n",
      "2023-08-25 20:40:53,558 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:57079] is starting\n",
      "2023-08-25 20:40:55.069414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-25 20:40:55,752 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: client runner started\n",
      "2023-08-25 20:40:55,752 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-1\n",
      "2023-08-25 20:40:55,755 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: assigned task to client site-1: name=train, id=07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:40:55,756 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: sent task assignment to client. client_name:site-1 task_id:07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:40:55,756 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: train   task_id: 07e374c8-4e94-41fe-850a-e39eb63f9315  sharable_header_task_id: 07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:40:55,759 - Communicator - INFO - Received from simulator_server server  (250506 Bytes). getTask: train time: 0.005004167556762695 seconds\n",
      "2023-08-25 20:40:55,760 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2023-08-25 20:40:55,760 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:40:55,760 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: invoking task executor PTFilePipeLauncherExecutor\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /tmp/nvflare/data/cifar10/cifar-10-python.tar.gz\n",
      "76.3%2023-08-25 20:41:55,859 - PTFilePipeLauncherExecutor - ERROR - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: received _PEER_GONE_ while waiting for result for train\n",
      "2023-08-25 20:41:55,871 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: finished processing task\n",
      "2023-08-25 20:41:55,872 - FederatedClient - INFO - Starting to push execute result.\n",
      "2023-08-25 20:41:55,874 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=train, id=07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:41:55,874 - ServerRunner - ERROR - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=SERVICE_UNAVAILABLE, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: Aborting current RUN due to FATAL_SYSTEM_ERROR received: Result from site-1 is bad, error code: SERVICE_UNAVAILABLE. ScatterAndGather exiting at round 0.\n",
      "2023-08-25 20:41:55,875 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=SERVICE_UNAVAILABLE, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-08-25 20:41:55,875 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-1, peer_run=simulate_job, peer_rc=SERVICE_UNAVAILABLE, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: finished processing client result by scatter_and_gather\n",
      "2023-08-25 20:41:55,875 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:41:55,876 - Communicator - INFO -  SubmitUpdate size: 558 Bytes. time: 0.0037682056427001953 seconds\n",
      "2023-08-25 20:41:55,876 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=07e374c8-4e94-41fe-850a-e39eb63f9315]: result sent to server for task: name=train, id=07e374c8-4e94-41fe-850a-e39eb63f9315\n",
      "2023-08-25 20:41:55,877 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "2023-08-25 20:41:55,877 - SimulatorClientRunner - INFO - Simulate Run client: site-2 on GPU group: None\n",
      "2023-08-25 20:41:55,877 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-1 \n",
      "2023-08-25 20:41:56,270 - ScatterAndGather - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Abort signal received. Exiting at round 0.\n",
      "2023-08-25 20:41:56,271 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Workflow: scatter_and_gather finalizing ...\n",
      "2023-08-25 20:41:56,283 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: ABOUT_TO_END_RUN fired\n",
      "2023-08-25 20:41:56,283 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: END_RUN fired\n",
      "2023-08-25 20:41:56,283 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: Server runner finished.\n",
      "2023-08-25 20:41:57,266 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2023-08-25 20:41:57,566 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 34333 shutdown!\n",
      "2023-08-25 20:41:57,566 - SimulatorServer - INFO - shutting down server\n",
      "2023-08-25 20:41:57,566 - SimulatorServer - INFO - canceling sync locks\n",
      "2023-08-25 20:41:57,566 - SimulatorServer - INFO - server off\n",
      "2023-08-25 20:41:57,897 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2023-08-25 20:41:57,952 - CoreCell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:57079\n",
      "2023-08-25 20:41:57,952 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:57079] is starting\n",
      "2023-08-25 20:41:59.485830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-25 20:42:00,158 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: client runner started\n",
      "2023-08-25 20:42:00,158 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-2\n",
      "2023-08-25 20:42:00,161 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather, peer=site-2, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2023-08-25 20:42:00,162 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2023-08-25 20:42:00,163 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2023-08-25 20:42:00,163 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2023-08-25 20:42:00,163 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2023-08-25 20:42:00,164 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: None\n",
      "2023-08-25 20:42:00,164 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-2 \n",
      "2023-08-25 20:42:00,164 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2023-08-25 20:42:00,164 - FederatedClient - INFO - Shutting down client run: site-2\n",
      "2023-08-25 20:42:00,165 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=scatter_and_gather]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2023-08-25 20:42:03,762 - MPM - INFO - MPM: Good Bye!\n"
     ]
    }
   ],
   "source": [
    "! nvflare simulator /tmp/nvflare/my_job -w /tmp/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041e784-d81e-4d7f-a497-4e3dbe050068",
   "metadata": {},
   "source": [
    "* If this doesn't work for you, let figure out what its complaining and change additional changes we need to make.  \n",
    "* If this works for you, we can move to next step. \n",
    "\n",
    "For now, assuming simulator works for you. And you would like to try out in real, but running locally with POC mode. to do this, let's first recreate the job configuration to set a larger number of rounds= 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbca437-a0be-45da-a438-c387266998a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following are the variables you can change in the template\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                                                                                       \n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \n",
      "                                                                                                                                       \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  file_name                      var_name                       value                               component                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "  config_exchange.conf           exchange_format                pytorch                                                                \n",
      "  config_exchange.conf           transfer_type                  DIFF                                                                   \n",
      "\n",
      "  config_fed_client.conf         app_config                                                                                            \n",
      "  config_fed_client.conf         app_script                     train.py                                                               \n",
      "  config_fed_client.conf         global_evaluation              True                                                                   \n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                                                    \n",
      "  config_fed_client.conf         heartbeat_timeout              60                                                                     \n",
      "  config_fed_client.conf         pipe_name                      pipe                                                                   \n",
      "  config_fed_client.conf         read_interval                  0.1                                                                    \n",
      "  config_fed_client.conf         result_poll_interval           0.1                                                                    \n",
      "  config_fed_client.conf         script                         python custom/{app_script}  {app_co SubprocessLauncher                 \n",
      "  config_fed_client.conf         training                       True                                                                   \n",
      "  config_fed_client.conf         workers                        1                                                                      \n",
      "\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \n",
      "  config_fed_server.conf         expected_data_kind             WEIGHTS                             InTimeAccumulateWeightedAggregator \n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         num_rounds                     100                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \n",
      "  config_fed_server.conf         weigh_by_local_iter            True                                InTimeAccumulateWeightedAggregator \n",
      "\n",
      "  meta.conf                      app                            ['@ALL']                                                               \n",
      "  meta.conf                      mandatory_clients              []                                                                     \n",
      "  meta.conf                      min_clients                    1                                                                      \n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -force -w sag_pt -f config_fed_server.conf num_rounds=100 -s ../hello-world/step-by-step/cifar10/code/fl/train.py -sd ../hello-world/step-by-step/cifar10/code/fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a878d-5518-4e41-9c3c-2f5098e7d018",
   "metadata": {},
   "source": [
    "\n",
    "### Setup and Start POC mode\n",
    "\n",
    "from a terminal, run\n",
    "\n",
    "```\n",
    "   nvflare poc prepare -n 2\n",
    "   nvflare poc start -ex admin@nvflare.com\n",
    "```\n",
    "here we will prepare a workspace for POC with n = 2 clients. Then start the POC clients and server except for the FLARE Admin Console (user name = 'admin@nvidia.com'). Since we are going to CLI to submit job, so we don't need admin console. Once the system started, we are ready to move to the next step: submit job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839570e-7522-4732-8034-d05a520fa4eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit Job from CLI\n",
    "\n",
    "We can use the following command to directly submit job from command line. \n",
    "\n",
    "even through the number_round = 100, I want to start with small number of round, but not changing the number_rounds = 100 value. \n",
    "\n",
    "Also, instead of relying on the default dataset_path, we are going to specify the dataset_path from the command line. \n",
    "\n",
    "lastly, I want to change the ```train_timeout``` to 300 seconds instead of 0, which means never timneout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5012082-5904-4a24-9211-0e46bc75d6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_path=/tmp/nvflare/data/cifar10']\n",
      "trying to connect to the server\n",
      "job: 'de707e28-4790-41f9-aba8-45ae405b3e01 was submitted\n"
     ]
    }
   ],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job -f config_fed_server.conf num_rounds=1 train_timeout=300 -a dataset_path=\"/tmp/nvflare/data/cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e34ddc-7f4c-4c14-b287-bedad1b603b3",
   "metadata": {},
   "source": [
    "You go to terminal to monitor the output log. \n",
    "\n",
    "> Note: \n",
    "> -a or --app_config specify the arguments to the training scripts. \n",
    "\n",
    "> the CLI argument\n",
    "> ```\n",
    ">   -a dataset_path=\"/tmp/nvflare/data/cifar10\"\n",
    "> ```\n",
    "> will be translate into \n",
    "\n",
    "> ```\n",
    ">    python custom/train.py --dataset_path \"/tmp/nvflare/data/cifar10\"\n",
    "> ```\n",
    "> in our case, the train.py takes --dataset_path as argument. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5522b5-38a8-4f95-98bf-0cd15c336f16",
   "metadata": {},
   "source": [
    "### Submit Job from CLI in Production\n",
    "\n",
    "Before you try to submit to production, the job CLI will need to know the location of the admin console startup kit directory. \n",
    "In the POC mode, we set this for user automatically, in prodcuction, user will need to tell the job CLI. \n",
    "\n",
    "First you can take a look at this file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52788f23-9e78-4396-ad84-c74ae9ef7937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    startup_kit {\n",
      "        path = /tmp/nvflare/poc/example_project/prod_00\n",
      "    }\n",
      "\n",
      "    poc_workspace {\n",
      "        path = /tmp/nvflare/poc\n",
      "    }\n",
      "    "
     ]
    }
   ],
   "source": [
    "! cat ~/.nvflare/config.conf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0dcc33-ff07-4554-8d6f-34b327b4ef44",
   "metadata": {},
   "source": [
    "You can directly edit the path\n",
    "```\n",
    "    startup_kit {\n",
    "        path = /tmp/nvflare/poc/example_project/prod_00\n",
    "    }\n",
    "```\n",
    "or use the following command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a57527-ee4e-4fc8-bfdf-e48fa6466527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config --startup_kit_dir  /tmp/nvflare/poc/example_project/prod_00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24105a-a80c-4c4c-b98f-f354ae5baaa1",
   "metadata": {},
   "source": [
    "or shorter form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ca3eca-2779-440d-86bc-9a23e1420e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -d  /tmp/nvflare/poc/example_project/prod_00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf52c39-cea7-4764-91b3-e061356089cc",
   "metadata": {},
   "source": [
    "Once the startup kit directory path is set, we can do the job submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106a7b0-371e-4504-aa26-a45a55a6347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job -f config_fed_server.conf num_rounds=1 -a dataset_path=\"/tmp/nvflare/data/cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c668def-55e3-477e-8e0a-f76c003b5c31",
   "metadata": {},
   "source": [
    "## Trouble Shooting\n",
    "\n",
    "The ```nvflare job submit``` command, since it should not overwrite the job folder configuration during submission, it has to use a temp job folder. \n",
    "If you want to check the final configs submited to the server or simply want to see the stack trace of the exception, you can use -debug flag. \n",
    "\n",
    "with -debug flag, the ``` nvflare job submit ``` command will not delete the temp job folder once its finished job submission, it will also prinit the exception stack trace in case of failure. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c676d8ab-6d35-4713-b551-8f5a40927a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_path=/tmp/nvflare/data/cifar10']\n",
      "trying to connect to the server\n",
      "job: '92f84b0a-246a-4aae-904a-78bd903e14b4 was submitted\n",
      "in debug mode, job configurations can be examined in temp job directory '/tmp/tmpdnusoyzj'\n"
     ]
    }
   ],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job -f config_fed_server.conf num_rounds=1 train_timeout=300 -a dataset_path=\"/tmp/nvflare/data/cifar10\" -debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3640447-52d8-47f5-80f6-98702efc5b35",
   "metadata": {},
   "source": [
    "See the statement: \n",
    "\n",
    "```\n",
    "in debug mode, job configurations can be examined in temp job directory '/tmp/tmp7nteenxr'\n",
    "```\n",
    "\n",
    "we can check the job folder with ```tree`` or ```ls -al ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a796f30-e99e-49e0-96ce-ad8809c27ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/tmpdnusoyzj\u001b[0m\n",
      "├── \u001b[01;34mapp\u001b[0m\n",
      "│   ├── \u001b[01;34mconfig\u001b[0m\n",
      "│   │   ├── config_exchange.conf\n",
      "│   │   ├── config_fed_client.conf\n",
      "│   │   └── config_fed_server.conf\n",
      "│   └── \u001b[01;34mcustom\u001b[0m\n",
      "│       ├── net.py\n",
      "│       └── train.py\n",
      "└── meta.conf\n",
      "\n",
      "3 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "! tree '/tmp/tmpdnusoyzj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b446bcda-f77a-4c2e-a548-c16822d28796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_version = 2\n",
      "app_script = \"train.py\"\n",
      "app_config = \"--dataset_path /tmp/nvflare/data/cifar10\"\n",
      "executors = [\n",
      "  {\n",
      "    tasks = [\n",
      "      \"train\"\n",
      "    ]\n",
      "    executor {\n",
      "      path = \"nvflare.app_opt.pt.file_pipe_launcher_executor.PTFilePipeLauncherExecutor\"\n",
      "      args {\n",
      "        launcher_id = \"launcher\"\n",
      "        heartbeat_timeout = 60\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "task_data_filters = []\n",
      "task_result_filters = []\n",
      "components = [\n",
      "  {\n",
      "    id = \"launcher\"\n",
      "    path = \"nvflare.app_common.launchers.subprocess_launcher.SubprocessLauncher\"\n",
      "    args {\n",
      "      script = \"python custom/{app_script}  {app_config} \"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!cat '/tmp/tmpdnusoyzj/app/config/config_fed_client.conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "703ed5d4-1cb2-426d-8efa-03ed2c3464e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_version = 2\n",
      "task_data_filters = []\n",
      "task_result_filters = []\n",
      "workflows = [\n",
      "  {\n",
      "    id = \"scatter_and_gather\"\n",
      "    path = \"nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather\"\n",
      "    args {\n",
      "      min_clients = 2\n",
      "      num_rounds = 1\n",
      "      start_round = 0\n",
      "      wait_time_after_min_received = 0\n",
      "      aggregator_id = \"aggregator\"\n",
      "      persistor_id = \"persistor\"\n",
      "      shareable_generator_id = \"shareable_generator\"\n",
      "      train_task_name = \"train\"\n",
      "      train_timeout = 300\n",
      "    }\n",
      "  }\n",
      "]\n",
      "components = [\n",
      "  {\n",
      "    id = \"persistor\"\n",
      "    path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\n",
      "    args {\n",
      "      model {\n",
      "        path = \"net.Net\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  {\n",
      "    id = \"shareable_generator\"\n",
      "    path = \"nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator\"\n",
      "    args {}\n",
      "  }\n",
      "  {\n",
      "    id = \"aggregator\"\n",
      "    path = \"nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator\"\n",
      "    args {\n",
      "      expected_data_kind = \"WEIGHTS\"\n",
      "    }\n",
      "  }\n",
      "  {\n",
      "    id = \"model_selector\"\n",
      "    name = \"IntimeModelSelector\"\n",
      "    args {\n",
      "      key_metric = \"accuracy\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!cat '/tmp/tmpdnusoyzj/app/config/config_fed_server.conf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493538a7-fe6d-4fc2-a65e-873bf26a09ee",
   "metadata": {},
   "source": [
    "you can see the configs in server and clients are indeed the values we specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9103e-9f45-4987-be8c-907ab86dfa1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Make sure you shutdown the poc system once you are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80086770-7a84-42aa-b981-5b9eabb22b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
