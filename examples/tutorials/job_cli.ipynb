{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5933f2eb-463a-4d01-a806-b6fc0fe9b4de",
   "metadata": {},
   "source": [
    "# NVFLARE JOB CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce4e61-da7f-4ba1-96f1-822c578e53a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook, we will go through the different commands of the Job CLI to show the syntax and usage of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154531fd-2a94-4062-bbc6-76086b099093",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Install NVIDIA FLARE\n",
    "\n",
    "For this notebook, we will need a running NVFLARE project that we can connect to.\n",
    "Follow the [installation](https://nvflare.readthedocs.io/en/main/getting_started.html#installation) \n",
    "instructions to set up an environment that has NVIDIA FLARE installed if you do not have one already.\n",
    "\n",
    "If you use the job CLI to submit job, you will need a running NVFLARE system with client and server. You can either run a local system via nvflare poc commands, or \n",
    "use a running production system. \n",
    "\n",
    "To see how to setup a local system, please refer to the [setup_poc tutorial](setup_poc.ipynb).\n",
    "\n",
    "\n",
    "## Step-by-step walk-through: from creating a job to running a job\n",
    "\n",
    "Taking the converted CIFAR10 with pytorch training code for a 2-client federated learning [program](https://github.com/NVIDIA/NVFlare/tree/main/examples/hello-world/step-by-step/cifar10/code), we can use the standard Scatter and Gatter (SAG) workflow pattern to demonstrate the features of the Job CLI. \n",
    "\n",
    "Now, we would like to see what are the available pre-configured job templates the user can use and modify. \n",
    "\n",
    "\n",
    "### Check out the available nvflare job templates\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c635e02-7fe6-401c-82d2-e2cde1dc86c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### List Job Templates and job templates directory\n",
    "\n",
    "The NVFLARE 2.4.0 release introduces job templates for the different types of job configurations.\n",
    "\n",
    "To list the available templates, you can use the ```nvflare job list_templates``` command:\n",
    "\n",
    "```\n",
    "! nvflare job list_templates\n",
    "```\n",
    "\n",
    "If you installed nvflare 2.4.x via `pip install nvflare`. The above command should show you available job templates (built-in default job templates). But if you cloned the github report of repository, and did not use the ```pip install nvflare```, the above command will expect you to provide the job_templates directory. When the job templates directory is not specified, the Job CLI will try to find the job_templates location with the following sequences of logic:\n",
    "\n",
    "* See if the NVFLARE_HOME environment variable is set. If NVFLARE_HOME is not empty, the Job CLI will look for the job_templates at:\n",
    " \n",
    " ```${NVFLARE_HOME}/job_templates```\n",
    " \n",
    "* If the NVFLARE_HOME env. variable is not set, the Job CLI will look for the `job_template` path of the config in the nvflare hidden directory \n",
    "\n",
    "```\n",
    "cat ~/.nvflare/config.conf \n",
    "\n",
    "startup_kit {\n",
    "  path = \"/tmp/nvflare/poc1/example_project/prod_00\"\n",
    "}\n",
    "poc_workspace {\n",
    "  path = \"/tmp/nvflare/poc1\"\n",
    "}\n",
    "job_template {\n",
    "  path = \"../../job_templates\"\n",
    "}\n",
    "\n",
    "```\n",
    "once the `-d <job_template_dir>` option is used, the `job_template` value in `~/.nvflare/config.conf` will be updated so you don't need to specify -d again. \n",
    "\n",
    "If you want to change the `job_template` path, you can directly edit this config file or use the `nvflare config` command:\n",
    "\n",
    "```\n",
    "nvflare config -jt ../../job_templates. \n",
    "\n",
    "```\n",
    "If the ~/.nvflare/config.conf is not defined yet, the command will look at the following location from installed NVFLARE package \n",
    "```\n",
    " job_templates_dir = os.path.join(nvflare.job.__file__, \"templates\")\n",
    "```\n",
    " \n",
    "If the nvflare is installed, this directory exists, then it should find the built-in job templates. \n",
    "\n",
    "> Note: this directory may not exist in the follow case: \n",
    "> * If you have done ```pip install nvflare```, but also installed the NVFLARE source code from github repo. the sys.path might point to your local NVFLARE repository when load nvflare.job module. In such a case, the above directory will not exist. As the job_templates is not located at nvflare/job/templates in the github repository. \n",
    "\n",
    "\n",
    "If Job templates directory still not found, the command will raise exception for missing Job Template directory. \n",
    "\n",
    "\n",
    "By now, you should understand that the ```nvflare job list_templates``` allows you to list built-in default job templates from the release, as well as provides your own job_templates to reflect the recent changes. \n",
    "\n",
    "For now, let's specify the job templates directory location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447619d5-d917-4d93-b806-6c673e216b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "The following job templates are available: \r\n",
      "\r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n",
      "  name                 Description                                                  Controller Type      Client Category     \r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n",
      "  cyclic_cc_pt         client-controlled cyclic workflow with PyTorch ClientAPI tra client               client_api          \r\n",
      "  cyclic_pt            server-controlled cyclic workflow with PyTorch ClientAPI tra server               client_api          \r\n",
      "  psi_csv              private-set intersection for csv data                        server               Executor            \r\n",
      "  sag_cross_np         scatter & gather and cross-site validation using numpy       server               client executor     \r\n",
      "  sag_cse_pt           scatter & gather workflow and cross-site evaluation with PyT server               client_api          \r\n",
      "  sag_gnn              scatter & gather workflow for gnn learning                   server               client_api          \r\n",
      "  sag_nemo             Scatter and Gather Workflow for NeMo                         server               client_api          \r\n",
      "  sag_np               scatter & gather workflow using numpy                        server               client_api          \r\n",
      "  sag_pt               scatter & gather workflow using pytorch                      server               client_api          \r\n",
      "  sag_pt_deploy_map    SAG workflow with pytorch, deploy_map, site-specific configs server               client_api          \r\n",
      "  sag_pt_executor      scatter & gather workflow and cross-site evaluation with PyT server               Executor            \r\n",
      "  sag_pt_model_learner scatter & gather workflow and cross-site evaluation with PyT server               ModelLearner        \r\n",
      "  sag_tf               scatter & gather workflow using TensorFlow                   server               client_api          \r\n",
      "  stats_df             FedStats: tabular data with pandas                           server               stats executor      \r\n",
      "  stats_image          FedStats: image intensity histogram                          server               stats executor      \r\n",
      "  swarm_cse_pt         Swarm Learning with Cross-Site Evaluation with PyTorch       client               client_api          \r\n",
      "  swarm_cse_pt_model_l Swarm Learning with Cross-Site Evaluation with PyTorch Model client               ModelLearner        \r\n",
      "  vertical_xgb         vertical federated xgboost                                   server               Executor            \r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "! nvflare job list_templates -d \"../../job_templates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abba0f2-17c9-4e09-a34e-8543238e4039",
   "metadata": {},
   "source": [
    "Where the option `-d \"<job_templates_dir>\"` or `--job_template_dir \"<job_templates_dir>\"` is the location of the job_templates.  By doing so, we have also save our job_templates into the hidden configuration,so we don't do it again next time. Let's look at the config file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fec3a1-71a6-40f7-a10f-52ea6595ad96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_template {\r\n",
      "  path = \"/home/chester/projects/NVFlare/job_templates\"\r\n",
      "}\r\n",
      "startup_kit {\r\n",
      "  path = \"/tmp/nvflare/poc/health_project/prod_00\"\r\n",
      "}\r\n",
      "poc_workspace {\r\n",
      "  path = \"/tmp/nvflare/poc\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! cat  ~/.nvflare/config.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663c2a0-3b36-4abb-ba8f-d1e77afea23a",
   "metadata": {},
   "source": [
    "You can also manually preset the job_templates directory if you don't want to reply on the default one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea478d-42fb-4223-8155-3c996699a052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -jt ../../job_templates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d793d-bc0c-458b-8a58-047cfde915f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cat  ~/.nvflare/config.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7b708-40e9-4f4f-beec-b83d0e893a0b",
   "metadata": {},
   "source": [
    "Now we can list the templates again without -d option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bab293-7fef-476f-8aa9-f2b2868a0fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "The following job templates are available: \r\n",
      "\r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n",
      "  name                 Description                                                  Controller Type      Client Category     \r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n",
      "  cyclic_cc_pt         client-controlled cyclic workflow with PyTorch ClientAPI tra client               client_api          \r\n",
      "  cyclic_pt            server-controlled cyclic workflow with PyTorch ClientAPI tra server               client_api          \r\n",
      "  psi_csv              private-set intersection for csv data                        server               Executor            \r\n",
      "  sag_cross_np         scatter & gather and cross-site validation using numpy       server               client executor     \r\n",
      "  sag_cse_pt           scatter & gather workflow and cross-site evaluation with PyT server               client_api          \r\n",
      "  sag_gnn              scatter & gather workflow for gnn learning                   server               client_api          \r\n",
      "  sag_nemo             Scatter and Gather Workflow for NeMo                         server               client_api          \r\n",
      "  sag_np               scatter & gather workflow using numpy                        server               client_api          \r\n",
      "  sag_pt               scatter & gather workflow using pytorch                      server               client_api          \r\n",
      "  sag_pt_deploy_map    SAG workflow with pytorch, deploy_map, site-specific configs server               client_api          \r\n",
      "  sag_pt_executor      scatter & gather workflow and cross-site evaluation with PyT server               Executor            \r\n",
      "  sag_pt_model_learner scatter & gather workflow and cross-site evaluation with PyT server               ModelLearner        \r\n",
      "  sag_tf               scatter & gather workflow using TensorFlow                   server               client_api          \r\n",
      "  stats_df             FedStats: tabular data with pandas                           server               stats executor      \r\n",
      "  stats_image          FedStats: image intensity histogram                          server               stats executor      \r\n",
      "  swarm_cse_pt         Swarm Learning with Cross-Site Evaluation with PyTorch       client               client_api          \r\n",
      "  swarm_cse_pt_model_l Swarm Learning with Cross-Site Evaluation with PyTorch Model client               ModelLearner        \r\n",
      "  vertical_xgb         vertical federated xgboost                                   server               Executor            \r\n",
      "------------------------------------------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "! nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10720b0b-af4c-4d71-a751-2d5c301eb05a",
   "metadata": {
    "tags": []
   },
   "source": [
    "With a job template that fits your needs, you can use the job template name to create a new job folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd0cc7-f410-457e-a6bd-d4c999182850",
   "metadata": {},
   "source": [
    "### Create a job folder\n",
    "\n",
    "Since the code for our example is written in pytorch and we would like to try the FedAvg algorithm using the Scatter & Gather (SAG) workflow, the job template **\"sag_pt\"** is what we are looking for. We will use this template to create our job folder. \n",
    "\n",
    "Create a job folder that contains the base job configuration from the template, which can then be modified as desired. First, create a job folder with the intent for it to be modified, without specifying any code.\n",
    "\n",
    "\n",
    "#### First try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3c9750-070f-4655-9128-757ab136b30d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "The following are the variables you can change in the template\r\n",
      "\r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "                                                                                                                                       \r\n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \r\n",
      "                                                                                                                                       \r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "  file_name                      var_name                       value                               component                          \r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "  meta.conf                      app                            ['@ALL']                                                               \r\n",
      "  meta.conf                      mandatory_clients              []                                                                     \r\n",
      "  meta.conf                      min_clients                    2                                                                      \r\n",
      "\r\n",
      "  config_fed_client.conf         app_config                                                                                            \r\n",
      "  config_fed_client.conf         app_script                     cifar10.py                                                             \r\n",
      "  config_fed_client.conf         evaluate_task_name             evaluate                                                               \r\n",
      "  config_fed_client.conf         file_check_interval            0.1                                 FilePipe                           \r\n",
      "  config_fed_client.conf         heartbeat_interval             5.0                                                                    \r\n",
      "  config_fed_client.conf         heartbeat_timeout              60                                                                     \r\n",
      "  config_fed_client.conf         last_result_transfer_timeout   5.0                                                                    \r\n",
      "  config_fed_client.conf         launch_once                    True                                                                   \r\n",
      "  config_fed_client.conf         mode                           PASSIVE                             FilePipe                           \r\n",
      "  config_fed_client.conf         params_exchange_format         pytorch                                                                \r\n",
      "  config_fed_client.conf         params_transfer_type           DIFF                                                                   \r\n",
      "  config_fed_client.conf         read_interval                  0.001                                                                  \r\n",
      "  config_fed_client.conf         result_poll_interval           0.001                                                                  \r\n",
      "  config_fed_client.conf         root_path                                                          FilePipe                           \r\n",
      "  config_fed_client.conf         script                         python3 custom/{app_script}  {app_c SubprocessLauncher                 \r\n",
      "  config_fed_client.conf         train_with_evaluation          True                                                                   \r\n",
      "  config_fed_client.conf         workers                        4                                                                      \r\n",
      "\r\n",
      "  config_fed_server.conf         allow_empty_global_weights     False                               ScatterAndGather                   \r\n",
      "  config_fed_server.conf         best_global_model_file_name    best_FL_global_model.pt             PTFileModelPersistor               \r\n",
      "  config_fed_server.conf         expected_data_kind             WEIGHT_DIFF                         InTimeAccumulateWeightedAggregator \r\n",
      "  config_fed_server.conf         global_model_file_name         FL_global_model.pt                  PTFileModelPersistor               \r\n",
      "  config_fed_server.conf         ignore_result_error            False                               ScatterAndGather                   \r\n",
      "  config_fed_server.conf         key_metric                     accuracy                            IntimeModelSelector                \r\n",
      "  config_fed_server.conf         min_clients                    2                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         model_class_path               net.Net                                                                \r\n",
      "  config_fed_server.conf         negate_key_metric              False                               IntimeModelSelector                \r\n",
      "  config_fed_server.conf         num_rounds                     2                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         persist_every_n_rounds         1                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         snapshot_every_n_rounds        1                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         start_round                    0                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         task_check_period              0.5                                 ScatterAndGather                   \r\n",
      "  config_fed_server.conf         train_timeout                  0                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         validation_metric_name         initial_metrics                     IntimeModelSelector                \r\n",
      "  config_fed_server.conf         wait_time_after_min_received   0                                   ScatterAndGather                   \r\n",
      "  config_fed_server.conf         weigh_by_local_iter            False                               IntimeModelSelector                \r\n",
      "\r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -w sag_pt -force\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf08b1e-ca7c-4902-b8d0-01968c3801be",
   "metadata": {
    "tags": []
   },
   "source": [
    "The above command creates a job folder at ```/tmp/nvflare/my_job``` with job template ```sag_pt```. \n",
    "You can see that a few configuration files are created. Some of the configurations are open for you to overwrite.\n",
    "\n",
    "If you have the ```tree``` command installed ( ```python -m pip install``` on linux), you can use the ```tree``` command, otherwise, you can use \"ls -al\" to look at the job_folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87410e3-c498-44ae-b7f7-2a51af237e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/nvflare/my_job\u001b[0m\r\n",
      "├── \u001b[01;34mapp\u001b[0m\r\n",
      "│   ├── \u001b[01;34mconfig\u001b[0m\r\n",
      "│   │   ├── config_fed_client.conf\r\n",
      "│   │   └── config_fed_server.conf\r\n",
      "│   └── \u001b[01;34mcustom\u001b[0m\r\n",
      "└── meta.conf\r\n",
      "\r\n",
      "3 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "! tree /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393ae90b-640b-4dd7-a325-e2b026e7703b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = \"my_job\"\r\n",
      "resource_spec {}\r\n",
      "deploy_map {\r\n",
      "  app = [\r\n",
      "    \"@ALL\"\r\n",
      "  ]\r\n",
      "}\r\n",
      "min_clients = 2\r\n",
      "mandatory_clients = []\r\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/nvflare/my_job/meta.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba16495-eaa3-431c-84da-432635ec8e29",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notice the app_name is \"my_job\". In `config_fed_client.conf` we can specify the data exchange path, the exchange format, and the way to transfer the model. Let's look at the server side configuration. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c4f50f-b715-42de-a217-f2feced182ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  # version of the configuration\r\n",
      "  format_version = 2\r\n",
      "\r\n",
      "  # task data filter: if filters are provided, the filter will filter the data flow out of server to client.\r\n",
      "  task_data_filters =[]\r\n",
      "\r\n",
      "  # task result filter: if filters are provided, the filter will filter the result flow out of client to server.\r\n",
      "  task_result_filters = []\r\n",
      "\r\n",
      "  # This assumes that there will be a \"net.py\" file with class name \"Net\".\r\n",
      "  # If your model code is not in \"net.py\" and class name is not \"Net\", please modify here\r\n",
      "  model_class_path = \"net.Net\"\r\n",
      "\r\n",
      "  # workflows: Array of workflows the control the Federated Learning workflow lifecycle.\r\n",
      "  # One can specify multiple workflows. The NVFLARE will run them in the order specified.\r\n",
      "  workflows = [\r\n",
      "      {\r\n",
      "        # 1st workflow\"\r\n",
      "        id = \"scatter_and_gather\"\r\n",
      "\r\n",
      "        # name = ScatterAndGather, path is the class path of the ScatterAndGather controller.\r\n",
      "        path = \"nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather\"\r\n",
      "        args {\r\n",
      "            # argument of the ScatterAndGather class.\r\n",
      "            # min number of clients required for ScatterAndGather controller to move to the next round\r\n",
      "            # during the workflow cycle. The controller will wait until the min_clients returned from clients\r\n",
      "            # before move to the next step.\r\n",
      "            min_clients = 2\r\n",
      "\r\n",
      "            # number of global round of the training.\r\n",
      "            num_rounds = 2\r\n",
      "\r\n",
      "            # starting round is 0-based\r\n",
      "            start_round = 0\r\n",
      "\r\n",
      "            # after received min number of clients' result,\r\n",
      "            # how much time should we wait further before move to the next step\r\n",
      "            wait_time_after_min_received = 0\r\n",
      "\r\n",
      "            # For ScatterAndGather, the server will aggregate the weights based on the client's result.\r\n",
      "            # the aggregator component id is named here. One can use the this ID to find the corresponding\r\n",
      "            # aggregator component listed below\r\n",
      "            aggregator_id = \"aggregator\"\r\n",
      "\r\n",
      "            # The Scatter and Gather controller use an persistor to load the model and save the model.\r\n",
      "            # The persistent component can be identified by component ID specified here.\r\n",
      "            persistor_id = \"persistor\"\r\n",
      "\r\n",
      "            # Shareable to a communication message, i.e. shared between clients and server.\r\n",
      "            # Shareable generator is a component that responsible to take the model convert to/from this communication message: Shareable.\r\n",
      "            # The component can be identified via \"shareable_generator_id\"\r\n",
      "            shareable_generator_id =  \"shareable_generator\"\r\n",
      "\r\n",
      "            # train task name: Client will start training once received such task.\r\n",
      "            train_task_name =  \"train\"\r\n",
      "\r\n",
      "            # train timeout in second. If zero, meaning no timeout.\r\n",
      "            train_timeout =  0\r\n",
      "        }\r\n",
      "      }\r\n",
      "  ]\r\n",
      "\r\n",
      "  # List of components used in the server side workflow.\r\n",
      "  components = [\r\n",
      "    {\r\n",
      "      # This is the persistence component used in above workflow.\r\n",
      "      # PTFileModelPersistor is a Pytorch persistor which save/read the model to/from file.\r\n",
      "\r\n",
      "      id = \"persistor\"\r\n",
      "      path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\r\n",
      "\r\n",
      "      # the persitor class take model class as argument\r\n",
      "      # This imply that the model is initialized from the server-side.\r\n",
      "      # The initialized model will be broadcast to all the clients to start the training.\r\n",
      "      args.model.path = \"{model_class_path}\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "      # This is the generator that convert the model to shareable communication message structure used in workflow\r\n",
      "      id = \"shareable_generator\"\r\n",
      "      path = \"nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator\"\r\n",
      "      args = {}\r\n",
      "    },\r\n",
      "    {\r\n",
      "      # This is the aggregator that perform the weighted average aggregation.\r\n",
      "      # the aggregation is \"in-time\", so it doesn't wait for client results, but aggregates as soon as it received the data.\r\n",
      "      id = \"aggregator\"\r\n",
      "      path = \"nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator\"\r\n",
      "      args.expected_data_kind = \"WEIGHT_DIFF\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "      # This component is not directly used in Workflow.\r\n",
      "      # it select the best model based on the incoming global validation metrics.\r\n",
      "      id = \"model_selector\"\r\n",
      "      path =  \"nvflare.app_common.widgets.intime_model_selector.IntimeModelSelector\"\r\n",
      "      # need to make sure this \"key_metric\" match what server side received\r\n",
      "      args.key_metric = \"accuracy\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/nvflare/my_job/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bebc20-5351-40a7-af7b-0a3c9bb271ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  # version of the configuration\r\n",
      "  format_version = 2\r\n",
      "\r\n",
      "  # This is the application script which will be invoked. Client can replace this script with user's own training script.\r\n",
      "  app_script = \"cifar10.py\"\r\n",
      "\r\n",
      "  # Additional arguments needed by the training code. For example, in lightning, these can be --trainer.batch_size=xxx.\r\n",
      "  app_config = \"\"\r\n",
      "\r\n",
      "  # Client Computing Executors.\r\n",
      "  executors = [\r\n",
      "    {\r\n",
      "      # tasks the executors are defined to handle\r\n",
      "      tasks = [\"train\"]\r\n",
      "\r\n",
      "      # This particular executor\r\n",
      "      executor {\r\n",
      "\r\n",
      "        # Executor name : PTClientAPILauncherExecutor\r\n",
      "        # This is an executor for pytorch + Client API. The underline data exchange is using Pipe.\r\n",
      "        path = \"nvflare.app_opt.pt.client_api_launcher_executor.PTClientAPILauncherExecutor\"\r\n",
      "\r\n",
      "        args {\r\n",
      "          # launcher_id is used to locate the Launcher object in \"components\"\r\n",
      "          launcher_id = \"launcher\"\r\n",
      "\r\n",
      "          # pipe_id is used to locate the Pipe object in \"components\"\r\n",
      "          pipe_id = \"pipe\"\r\n",
      "\r\n",
      "          # Timeout in seconds for waiting for a heartbeat from the training script. Defaults to 30 seconds.\r\n",
      "          # Please refer to the class docstring for all available arguments\r\n",
      "          heartbeat_timeout = 60\r\n",
      "\r\n",
      "          # format of the exchange parameters\r\n",
      "          params_exchange_format =  \"pytorch\"\r\n",
      "\r\n",
      "          # if the transfer_type is FULL, then it will be sent directly\r\n",
      "          # if the transfer_type is DIFF, then we will calculate the\r\n",
      "          # difference VS received parameters and send the difference\r\n",
      "          params_transfer_type = \"DIFF\"\r\n",
      "\r\n",
      "          # if train_with_evaluation is true, the executor will expect\r\n",
      "          # the custom code need to send back both the trained parameters and the evaluation metric\r\n",
      "          # otherwise only trained parameters are expected\r\n",
      "          train_with_evaluation = true\r\n",
      "\r\n",
      "          # if launch_once is true, the executor will only call launcher.launch_task once\r\n",
      "          # for the whole job, if launch_once is false, the executor will call launcher.launch_task\r\n",
      "          # everytime it receives a task from server\r\n",
      "          launch_once = true\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "  ],\r\n",
      "\r\n",
      "  # this defined an array of task data filters. If provided, it will control the data from server controller to client executor\r\n",
      "  task_data_filters =  []\r\n",
      "\r\n",
      "  # this defined an array of task result filters. If provided, it will control the result from client executor to server controller\r\n",
      "  task_result_filters = []\r\n",
      "\r\n",
      "  components =  [\r\n",
      "    {\r\n",
      "      # This \"launcher\" component\r\n",
      "      id = \"launcher\"\r\n",
      "\r\n",
      "      # the class path of the component\r\n",
      "      path = \"nvflare.app_common.launchers.subprocess_launcher.SubprocessLauncher\"\r\n",
      "\r\n",
      "      # the launcher will invoke the script\r\n",
      "      args.script = \"python3 custom/{app_script}  {app_config} \"\r\n",
      "    }\r\n",
      "    {\r\n",
      "      id = \"pipe\"\r\n",
      "\r\n",
      "      path = \"nvflare.fuel.utils.pipe.file_pipe.FilePipe\"\r\n",
      "\r\n",
      "      args {\r\n",
      "        # Mode of the endpoint. A pipe has two endpoints.\r\n",
      "        # An endpoint can be either the one that initiates communication or the one listening.\r\n",
      "        # PASSIVE is the one listening.\r\n",
      "        mode = \"PASSIVE\"\r\n",
      "\r\n",
      "        # root_path: is the directory location of the data exchange.\r\n",
      "        # If empty string, it will be set to the app_dir of the running job.\r\n",
      "        # You can also set it to an absolute path in your system.\r\n",
      "        root_path = \"\"\r\n",
      "      }\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! ! cat /tmp/nvflare/my_job/app/config/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11767829-65e5-47e1-bae1-6c587c315100",
   "metadata": {},
   "source": [
    "> Note that both client and server configurations are nicely commented with explainations. \n",
    "> If you create the job with customizations such as using -f or configurations, the configuration files will be overwritten. As result, the comments in the configuration will be lost in the final files. \n",
    "\n",
    "### Show variables\n",
    "\n",
    "Now, you can see the job folder is auto-created with pre-defined configurations. To make sure this template works for your code and the variables can be updated. Let's check the variables again with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74adcc28-9f52-4f2b-b4b2-1bd9b053dd80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "The following are the variables you can change in the template\r\n",
      "\r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "                                                                                                                                       \r\n",
      "  job folder: /tmp/nvflare/my_job                                                                                                        \r\n",
      "                                                                                                                                       \r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "  file_name                      var_name                       value                               component                          \r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n",
      "  meta.conf                      app                            ['@ALL']                                                               \r\n",
      "  meta.conf                      mandatory_clients              []                                                                     \r\n",
      "  meta.conf                      min_clients                    2                                                                      \r\n",
      "\r\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "! nvflare job show_variables -j /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ede943-4c76-42b2-81ad-8d9364637cfb",
   "metadata": {},
   "source": [
    "You can see there are many variables you might want to change:\n",
    "\n",
    "* Change num_rounds to 1 to test out a fast run first.\n",
    "* Use custom cifar10 code which was already written based on Flare 2.4.0 Client API.\n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "the job template name: such as ```sag_pt```, you can also use directory path for the job template. You can try yourself.\n",
    "\n",
    "```\n",
    "! nvflare job create -j /tmp/nvflare/my_job -w ../../job_templates/sag_pt -force\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e991379-78e1-4e86-88fb-ab9a69d6822c",
   "metadata": {},
   "source": [
    "\n",
    "Let's do a second try, \n",
    "\n",
    "#### The second try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d32eb0-1384-4d49-9b6e-a369c53e7163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -force -w sag_pt  \\\n",
    "-f config_fed_server.conf num_rounds=1 \\\n",
    "-f config_fed_client.conf app_script=train.py \\\n",
    "-sd ../hello-world/step-by-step/cifar10/code/fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aae893-0371-488e-9883-aa2d736a6807",
   "metadata": {},
   "source": [
    "The above command creates a job folder at ```/tmp/nvflare/my_job``` with job template ```sag_pt``` again (`-force` to replace the existing job folder). \n",
    "Now, `num_rounds` is set to 1 and `{app_script}` is \"train.py\": the python script will invoke ```python custom/{app_script}```, so the provided `train.py` will be called.\n",
    "Now, take a look the code structure again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09239cb-39cb-4ccf-858e-619d2b1072a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree /tmp/nvflare/my_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103b02a-1ada-4201-b848-811d237be3fd",
   "metadata": {},
   "source": [
    "Notice that the code we had written is copied to the job directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fa61b-2c30-4421-a74c-75f0725a86f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "In config_fed_server.conf, we have ```PTFileModelPersistor```, a file-based persistor for pytorch. It requires the `net.Net` class for model initialization and also for saving the final model.\n",
    "The \"net.py\" file matches the configuration.  If your model file name and class name does not match `net.Net`, you will need to update your configuration to match. \n",
    "\n",
    "We will leave the rest of values as default and try to run the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97e7a0-38ae-4af7-b8be-73879a69a55f",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "Download the data first to avoid repeated downloading. You can use the download script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c829fa-099c-4f40-9571-7e7ca8f026d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python ../../examples/hello-world/step-by-step/cifar10/data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9308ba5-ad4d-4f3f-9377-76fd6a253687",
   "metadata": {},
   "source": [
    "### Run the Job in simulator \n",
    "\n",
    "You can first run the job with `nvflare simulator` to see if there are any issues:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451ab27-68cf-4ab3-ae7f-f276f21185a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare simulator /tmp/nvflare/my_job -w /tmp/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041e784-d81e-4d7f-a497-4e3dbe050068",
   "metadata": {},
   "source": [
    "If this does not work for you, you may need to make additional changes based on the error messages.\n",
    "\n",
    "Assuming `nvflare simulator` works, you can try running locally with POC mode. For more realistic training, you can first recreate the job configuration with a larger number of rounds (num_rounds=100):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbca437-a0be-45da-a438-c387266998a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -force -w sag_pt \\\n",
    "-f config_fed_server.conf num_rounds=100 \\\n",
    "-f config_fed_client.conf app_script=train.py \\\n",
    "-sd ../hello-world/step-by-step/cifar10/code/fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a878d-5518-4e41-9c3c-2f5098e7d018",
   "metadata": {},
   "source": [
    "\n",
    "### Set up and start POC mode\n",
    "\n",
    "From a terminal, run:\n",
    "\n",
    "```\n",
    "   nvflare poc prepare -n 2\n",
    "   nvflare poc start -ex admin@nvidia.com\n",
    "```\n",
    "This will prepare a workspace for POC with n = 2 clients. The second command starts the POC clients and server except for the FLARE Admin Console (user name = 'admin@nvidia.com'). Since we are going to the Job CLI for submit job, we don't need the admin console for now. Once the system has started, we are ready to move to the next step: submit job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839570e-7522-4732-8034-d05a520fa4eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit Job from CLI\n",
    "\n",
    "You can use the following command to directly submit job from the command line. \n",
    "\n",
    "Even through in `config_fed_server.conf`, num_rounds = 100, to start with a smaller number of rounds, you can set `num_rounds` in the `nvflare job submit` command without changing the value in the config. \n",
    "\n",
    "Also, to change the `train_timeout` to 300 seconds instead of 0 (which means no timeout), this arg is also in `config_fed_server.conf`, so you can include it with `num_rounds` after `-f config_fed_server.conf`.\n",
    "\n",
    "Finally, instead of relying on the default `dataset_path`, you can specify the `dataset_path` in the `nvflare job submit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5012082-5904-4a24-9211-0e46bc75d6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job \\\n",
    "-f config_fed_server.conf num_rounds=1 train_timeout=300 \\\n",
    "-f config_fed_client.conf app_config=\"--dataset_path /tmp/nvflare/data/cifar10\" \\\n",
    "-debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e34ddc-7f4c-4c14-b287-bedad1b603b3",
   "metadata": {},
   "source": [
    "You can go to the terminal to monitor the output log. \n",
    "\n",
    "> the CLI argument\n",
    "> ```\n",
    ">   app_config=\"--dataset_path /tmp/nvflare/data/cifar10\"\n",
    "> ```\n",
    "> will be translated into \n",
    "\n",
    "> ```\n",
    ">    python custom/train.py --dataset_path \"/tmp/nvflare/data/cifar10\"\n",
    "> ```\n",
    "> in our case, `train.py` takes `--dataset_path` as an argument. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5522b5-38a8-4f95-98bf-0cd15c336f16",
   "metadata": {},
   "source": [
    "### Submit Job from CLI in production\n",
    "\n",
    "Before you try to submit to production, the Job CLI will need to know the location of the admin console startup kit directory. \n",
    "In POC mode, this is set for the user automatically. In prodcuction, the user will need to set the path to the startup kit for the Job CLI. \n",
    "\n",
    "The startup kit path is stored in the `config.conf` file in the nvflare hidden directory at the user's home directory. First you can take a look at this file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52788f23-9e78-4396-ad84-c74ae9ef7937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cat ~/.nvflare/config.conf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0dcc33-ff07-4554-8d6f-34b327b4ef44",
   "metadata": {},
   "source": [
    "You can directly edit the path in the file:\n",
    "```\n",
    "    startup_kit {\n",
    "        path = /tmp/nvflare/poc/example_project/prod_00\n",
    "    }\n",
    "```\n",
    "Alternatively, you can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a57527-ee4e-4fc8-bfdf-e48fa6466527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config --startup_kit_dir /tmp/nvflare/poc/example_project/prod_00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24105a-a80c-4c4c-b98f-f354ae5baaa1",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca3eca-2779-440d-86bc-9a23e1420e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -d /tmp/nvflare/poc/example_project/prod_00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf52c39-cea7-4764-91b3-e061356089cc",
   "metadata": {},
   "source": [
    "Once the startup kit directory path is set, you can do the job submit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106a7b0-371e-4504-aa26-a45a55a6347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job \\\n",
    "-f config_fed_server.conf num_rounds=1 \\\n",
    "-f config_fed_client.conf app_config=\"--dataset_path /tmp/nvflare/data/cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c668def-55e3-477e-8e0a-f76c003b5c31",
   "metadata": {},
   "source": [
    "## Troubleshooting with the `-debug` flag\n",
    "\n",
    "Since the ```nvflare job submit``` command does not overwrite the job folder configuration during submission, it has to use a temp job folder. \n",
    "If you want to check the final configs submited to the server or simply want to see the stack trace of the exception, you can use the `-debug` flag. \n",
    "\n",
    "With the `-debug` flag, the ``` nvflare job submit ``` command will not delete the temp job folder once it has finished job submission, and it will also print the exception stack trace in case of failure. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676d8ab-6d35-4713-b551-8f5a40927a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job submit -j /tmp/nvflare/my_job \\\n",
    "-f config_fed_server.conf num_rounds=1 train_timeout=300 \\\n",
    "-f config_fed_client.conf app_config=\"--dataset_path /tmp/nvflare/data/cifar10\" \\\n",
    "-debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3640447-52d8-47f5-80f6-98702efc5b35",
   "metadata": {},
   "source": [
    "You should see a statement like the following after the message that the job was submitted (the actual random folder name will vary): \n",
    "\n",
    "```\n",
    "in debug mode, job configurations can be examined in temp job directory '/tmp/tmpdnusoyzj'\n",
    "```\n",
    "\n",
    "You can check the job folder with `tree` or `ls -al` \n",
    "> note:  the temp folder name can be different on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a796f30-e99e-49e0-96ce-ad8809c27ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree '/tmp/tmpdnusoyzj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446bcda-f77a-4c2e-a548-c16822d28796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat '/tmp/tmpdnusoyzj/app/config/config_fed_client.conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ed5d4-1cb2-426d-8efa-03ed2c3464e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat '/tmp/tmpdnusoyzj/app/config/config_fed_server.conf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493538a7-fe6d-4fc2-a65e-873bf26a09ee",
   "metadata": {},
   "source": [
    "You can see if the configs for server and clients are indeed the values specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaaa444-1f39-4832-ac1b-2d9b3710dbba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Troubleshooting - Client API timeout\n",
    "\n",
    "If the client API has not received training in 60 seconds, the job will be considered failed with a message like the following:\n",
    "```\n",
    "PTFilePipeLauncherExecutor - ERROR - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=db7940f1-d7b4-44e5-b509-dfed4adeb2ec]: received _PEER_GONE_ while waiting for result for train\n",
    "```\n",
    "\n",
    "If you need to, you can increase the value for the timeout: \n",
    "\n",
    "```\n",
    "heartbeat_timeout = 120\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9103e-9f45-4987-be8c-907ab86dfa1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Make sure you shut down the POC system when you are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80086770-7a84-42aa-b981-5b9eabb22b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvflare poc stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c4fa4-9695-4013-a08d-36a3ab2d7e13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced Section\n",
    "\n",
    "With above sections, you should have understood how to create job with the job template, modify the configuration as needed (either via CLI or manually) and submit job. \n",
    "Now, what if you would like to have \n",
    "\n",
    "* Different configurations on different clients\n",
    "  You could have different datasets on different sites, therefore, the epoches, batch size, learning rate, etc. can be different. \n",
    "\n",
    "* Deploy different code pieces to different sites \n",
    "  You don't need to deploy all the code to all places, only certain code is needed at certain locations. \n",
    "  \n",
    "* add new arguments not in the job templates, modify specific config key using path\n",
    "\n",
    "In this section, we will discuss how to do this. So far, we assumed all sites (server and client sites) had the same code and configuration, we deploy all the code + configs to all sites with the following meta.conf\n",
    "\n",
    "```\n",
    "name = \"my_job\"\n",
    "resource_spec {}\n",
    "deploy_map {\n",
    "  app = [\n",
    "    \"@ALL\"\n",
    "  ]\n",
    "}\n",
    "min_clients = 2\n",
    "mandatory_clients = []\n",
    "\n",
    "```\n",
    "\n",
    "Notice the **deploy_map** \n",
    "```\n",
    "deploy_map {\n",
    "  app = [\n",
    "    \"@ALL\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n",
    "### Set up job with different site-specific configurations \n",
    "\n",
    "We are saying that there is \"app\" is deployed to \"ALL\" sites. Let's look at a different example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1942b9-f189-4726-b1e8-1ccb3a9ece1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create \\\n",
    "-j /tmp/nvflare/my_job -w sag_pt_deploy_map "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a5466-fcc9-426e-b311-363087727eea",
   "metadata": {},
   "source": [
    "Here we have three different apps : \"app_server\", \"app_1\" and \"app_2\". \n",
    "We would like to change the following: \n",
    "\n",
    "* change number of training rounds to 2\n",
    "* change default app_script from \"cifar10.py\" to \"train.py\" for both app_1 and app_2\n",
    "* change the app_1 batch_size to 4, app_2 batch_size to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2b701-99e6-4aa0-bfac-ab2054635b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create \\\n",
    "-j /tmp/nvflare/my_job -w sag_pt_deploy_map \\\n",
    "-f app_server/config_fed_server.conf num_rounds=2 \\\n",
    "-f app_1/config_fed_client.conf app_script=train.py app_config=\"--batch_size 4\" \\\n",
    "-f app_2/config_fed_client.conf app_script=train.py app_config=\"--batch_size 6\" \\\n",
    "-sd ../hello-world/step-by-step/cifar10/code/fl \\\n",
    "-force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb01d8-71da-4ab3-a6a6-d66563bd6c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's look at the job folder structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270bdfe-a3ab-4c54-92d9-f67ecc59d210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree /tmp/nvflare/my_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a88ce-084d-4da4-b160-69ac8918b7a8",
   "metadata": {},
   "source": [
    "The job folder consists of three sub-folders, each representing one application: app_server, app_1, app_2. Now look at the meta.conf's deploy_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaf60e-254d-4490-970b-fd530b09b84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/my_job/meta.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821cde68-38cc-48a0-8448-835693b2a131",
   "metadata": {},
   "source": [
    "Notice, app_server is deployed to \"server\", \"app_1\" and \"app_2\" respectively.  The app_1 and app_2 only need client configurations and app_server only need server configuration. Since the server is not doing the training job. we could **remove** ther train.py from the app_server app. and look at again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c56d0-a3f6-452e-8b77-c9693c8edd79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm /tmp/nvflare/my_job/app_server/custom/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3d9f1-40df-44b8-8fb7-52ab820358ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fe596-5abc-4e4b-9f83-67102ddca6cb",
   "metadata": {},
   "source": [
    "Look at the job configuration variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161dc09-804e-4fa8-a3ca-ad4b9efeccf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job show_variables -j /tmp/nvflare/my_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7408ce-fb16-49dc-8df8-fb9d38ad881e",
   "metadata": {},
   "source": [
    "This shows the same information we previously seen. Except it shows each app's configuration. Lets explain a bit mroe about the commnand syntax\n",
    "\n",
    "```\n",
    " nvflare job create \\\n",
    "-j /tmp/nvflare/my_job -w sag_pt_deploy_map \\\n",
    "-f app_server/config_fed_server.conf num_rounds=2 \\\n",
    "-f app_1/config_fed_client.conf app_script=train.py app_config=\"--batch_size 4\" \\\n",
    "-f app_2/config_fed_client.conf app_script=train.py app_config=\"--batch_size 6\" \\\n",
    "-sd ../hello-world/step-by-step/cifar10/code/fl \\\n",
    "-force\n",
    "\n",
    "```\n",
    "\n",
    "to specify app specific configuration, you use\n",
    "\n",
    "```-f app_server/config_fed_server.conf num_rounds=2 ```\n",
    "\n",
    "instead \n",
    "\n",
    "```\n",
    "-f config_fed_server.conf num_rounds=2 \n",
    "\n",
    "```\n",
    "\n",
    "Here it tells the command that that only change the config for \"app_server\" app, without \"app_server/\" the command is considered to use the default \"app\" configuration. \n",
    "\n",
    "if the \"app_name\" is not previously defined in the job templates, the command will show error.  For example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dfee7-5f6d-431c-bf69-6003e220909f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create \\\n",
    "-j /tmp/nvflare/my_job -w sag_pt_deploy_map \\\n",
    "-f fl_server/config_fed_server.conf num_rounds=2 \\\n",
    "-force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695d5e3-3dde-456a-a2db-54ad8c2ccb7d",
   "metadata": {},
   "source": [
    "Once you have the the job folder. You should be able to run the job as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49deee6f-eb9a-4086-80ff-2e96ab94ede6",
   "metadata": {},
   "source": [
    "### Add arguments not originally specified in Job Template\n",
    "\n",
    "In some cases, we need add additional arguments not defined in the job templates, and we would like to the add to a specific args of certain component. This requires we specify the path to the component. \n",
    "\n",
    "We use the following notations to indicate the path\n",
    "* for single component, we can use dot notation. such as ```model.args.number_classes=2```\n",
    "* for component list, we use index notation. such as ```components[1].model.args.number_classes=2```\n",
    "\n",
    "In the 2nd case, ```components[1]``` indicates the 2nd component of the component list. The first component will be ```component[0]```\n",
    "\n",
    "Let's look at how do we use this to add or modify the job template. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544e5dc-74e5-46de-9efd-8c1b441a4efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -w sag_pt -force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d616c49-9a50-46d6-bd78-113cd5ca63ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cat /tmp/nvflare/my_job/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317cfbd-1126-4e4c-b5e0-5ebe9b905713",
   "metadata": {},
   "source": [
    "Here, we would like to modify the peristor component configuration from \n",
    "```\n",
    "  components = [\n",
    "    {\n",
    "      # This is the persistence component used in above workflow.\n",
    "      # PTFileModelPersistor is a Pytorch persistor which save/read the model to/from file.\n",
    "\n",
    "      id = \"persistor\"\n",
    "      path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\n",
    "\n",
    "      # the persitor class take model class as argument\n",
    "      # This imply that the model is initialized from the server-side.\n",
    "      # The initialized model will be broadcast to all the clients to start the training.\n",
    "      args.model.path = \"{model_class_path}\"\n",
    "    },\n",
    "```\n",
    "to: \n",
    "\n",
    "```\n",
    "  components = [\n",
    "    {\n",
    "      id = \"persistor\"\n",
    "      path = \"nvflare.app_opt.pt.file_model_persistor.PTFileModelPersistor\"\n",
    "      args {\n",
    "          model { \n",
    "              path = \"{model_class_path}\"\n",
    "              args {\n",
    "                in_channels = 165\n",
    "                hidden_channels = 256\n",
    "                num_classes = 2\n",
    "                num_layers = 3\n",
    "            }\n",
    "          }\n",
    "      }\n",
    "    },\n",
    "```\n",
    "Notice, that new models.args are new keys and values. This is Model Persistor is the 1st component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca2e1a-093b-4c9d-b6b8-9d0ab9382b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/my_job -w sag_pt -force \\\n",
    "-f config_fed_server.conf \\\n",
    "components[0].args.model.args.in_channels=165 \\\n",
    "components[0].args.model.args.hidden_channels=256 \\\n",
    "components[0].args.model.args.num_classes=2 \\\n",
    "components[0].args.model.args.num_layers=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603dfb03-740d-4df4-afa1-4074405702cd",
   "metadata": {},
   "source": [
    "Now, look at the modified configuration again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d135b5-ceea-44bd-b9e1-04d9967defa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cat /tmp/nvflare/my_job/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e237c0-c039-4cbb-8b89-4194fb00a354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
