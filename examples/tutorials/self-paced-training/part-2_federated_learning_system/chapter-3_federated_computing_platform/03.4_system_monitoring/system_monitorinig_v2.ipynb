{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343838f7",
   "metadata": {},
   "source": [
    "# Monitoring the NVIDIA FLARE System\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Monitoring is a critical aspect of any distributed system, and federated learning is no exception. As federated learning systems operate across multiple sites and organizations, having visibility into system performance, job progress, and resource utilization becomes essential for troubleshooting, optimization, and ensuring reliable operation.\n",
    "\n",
    "NVIDIA FLARE provides a comprehensive monitoring solution that focuses on system metrics rather than just machine learning metrics. While machine learning experiment tracking focuses on training metrics (like loss and accuracy), FLARE's monitoring system focuses on the federated learning system itselfâ€”tracking job lifecycle events, communication patterns, and system performance.\n",
    "\n",
    "In this section, we'll explore how to set up and use NVIDIA FLARE's monitoring capabilities to gain insights into your federated learning deployments.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this section, you will be able to:\n",
    "- Understand the importance of system monitoring in federated learning\n",
    "- Identify the different types of metrics collected by NVIDIA FLARE\n",
    "- Configure various monitoring setups based on your deployment needs\n",
    "- Implement monitoring components in your federated learning system\n",
    "- Visualize and analyze system performance using industry-standard tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d42899",
   "metadata": {},
   "source": [
    "## Monitoring Architecture\n",
    "\n",
    "NVIDIA FLARE's monitoring system is built on industry-standard tools and follows a modular architecture:\n",
    "\n",
    "1. **Metrics Collection**: FLARE components collect metrics from various system events\n",
    "2. **Metrics Publishing**: These metrics are published to a metrics service (StatsD)\n",
    "3. **Metrics Storage**: A time-series database (Prometheus) stores the metrics\n",
    "4. **Visualization**: A dashboard tool (Grafana) provides visual representations of the metrics\n",
    "\n",
    "This architecture allows for flexible deployment options and integration with existing monitoring infrastructure.\n",
    "\n",
    "## Monitoring Setup Options\n",
    "\n",
    "Depending on your deployment requirements and organizational constraints, NVIDIA FLARE supports three main monitoring setup options:\n",
    "\n",
    "### 1. Shared Monitoring System\n",
    "\n",
    "In this setup, all sites (server and clients) publish metrics to a central monitoring system. This provides a consolidated view of the entire federated learning system.\n",
    "\n",
    "![setup-1](./figures/setup-1.png)\n",
    "\n",
    "**Key characteristics:**\n",
    "- Single monitoring infrastructure for all sites\n",
    "- Consolidated view of all metrics\n",
    "- Requires network connectivity from all sites to the monitoring system\n",
    "- Simplest to manage and analyze\n",
    "\n",
    "**Implementation steps:**\n",
    "1. Install StatsD Exporter, Prometheus, and Grafana on a central monitoring server\n",
    "2. Configure all FLARE sites to send metrics to the central StatsD Exporter\n",
    "3. Configure Prometheus to scrape metrics from StatsD Exporter\n",
    "4. Set up Grafana dashboards to visualize the metrics\n",
    "\n",
    "> **Note**: Don't confuse StatsD Exporter and StatsD Reporter. StatsD Exporter is a service that receives metrics and exposes them for Prometheus to scrape, while StatsD Reporter is the FLARE component that sends metrics to the StatsD Exporter.\n",
    "\n",
    "### 2. Client-to-Server Metrics Forwarding\n",
    "\n",
    "In this setup, clients forward their metrics to the server, which then publishes all metrics to a monitoring system. This is useful when clients cannot directly access the monitoring system.\n",
    "\n",
    "![setup-2](figures/setup-2.png)\n",
    "\n",
    "**Key characteristics:**\n",
    "- Clients don't need direct access to the monitoring system\n",
    "- Server acts as a metrics aggregator\n",
    "- Consolidated view of all metrics\n",
    "- Requires additional configuration for metrics forwarding\n",
    "\n",
    "**Implementation steps:**\n",
    "1. Install StatsD Exporter, Prometheus, and Grafana on a server accessible to the FL server\n",
    "2. Configure clients to collect metrics and forward them to the server\n",
    "3. Configure the server to receive client metrics and publish them to StatsD Exporter\n",
    "4. Configure Prometheus to scrape metrics from StatsD Exporter\n",
    "5. Set up Grafana dashboards to visualize the metrics\n",
    "\n",
    "### 3. Individual Monitoring Systems\n",
    "\n",
    "In this setup, each site (server and clients) has its own monitoring system. This is useful when organizations want to keep their monitoring data within their own infrastructure.\n",
    "\n",
    "![setup-3](figures/setup-3.png)\n",
    "\n",
    "**Key characteristics:**\n",
    "- Each site maintains its own monitoring infrastructure\n",
    "- No consolidated view of all metrics\n",
    "- Maximum data privacy and security\n",
    "- More complex to manage and analyze\n",
    "\n",
    "**Implementation steps:**\n",
    "1. Install StatsD Exporter, Prometheus, and Grafana at each site\n",
    "2. Configure each FLARE site to send metrics to its local StatsD Exporter\n",
    "3. Configure Prometheus at each site to scrape metrics from its local StatsD Exporter\n",
    "4. Set up Grafana dashboards at each site to visualize the local metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics-section",
   "metadata": {},
   "source": [
    "## NVIDIA FLARE Monitoring Metrics\n",
    "\n",
    "NVIDIA FLARE collects a wide range of metrics that provide insights into different aspects of the federated learning system. \n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "Here's a selection of important metrics collected by NVIDIA FLARE:\n",
    "\n",
    "#### System Lifecycle Metrics\n",
    "- **System Start/End**: Track when the system starts and stops\n",
    "- **Client Connection**: Monitor client connections and disconnections\n",
    "- **Resource Management**: Track resource allocation and availability\n",
    "\n",
    "#### Job Lifecycle Metrics\n",
    "- **Job Deployment**: Track when jobs are deployed to the system\n",
    "- **Job Execution**: Monitor job starts, completions, aborts, and cancellations\n",
    "- **Run Management**: Track the execution of individual runs within jobs\n",
    "\n",
    "#### Federated Learning Metrics\n",
    "- **Task Execution**: Monitor task assignment, execution, and completion\n",
    "- **Data Transfer**: Track data movement between clients and server\n",
    "- **Aggregation**: Monitor model aggregation operations\n",
    "- **Training**: Track local training operations on clients\n",
    "- **Round Management**: Monitor the progress of federated learning rounds\n",
    "\n",
    "\n",
    "### Complete Metrics List\n",
    "\n",
    "The following table shows the complete list of metrics collected by NVIDIA FLARE:\n",
    "\n",
    "| Event | Metric Count | Metric Time Taken |\n",
    "|-------|--------------|-------------------|\n",
    "| SYSTEM_START | _system_start_count | |\n",
    "| SYSTEM_END | _system_end_count | _system_time_taken |\n",
    "| ABOUT_TO_START_RUN | _about_to_start_run_count | |\n",
    "| START_RUN | _start_run_count | |\n",
    "| ABOUT_TO_END_RUN | _about_to_end_run_count | |\n",
    "| END_RUN | _end_run_count | _run_time_taken |\n",
    "| CHECK_END_RUN_READINESS | _check_end_run_readiness_count | |\n",
    "| SWAP_IN | _swap_in_count | |\n",
    "| SWAP_OUT | _swap_out_count | |\n",
    "| START_WORKFLOW | _start_workflow_count | |\n",
    "| END_WORKFLOW | _end_workflow_count | _workflow_time_taken |\n",
    "| ABORT_TASK | _abort_task_count | |\n",
    "| FATAL_SYSTEM_ERROR | _fatal_system_error_count | |\n",
    "| JOB_DEPLOYED | _job_deployed_count | |\n",
    "| JOB_STARTED | _job_started_count | |\n",
    "| JOB_COMPLETED | _job_completed_count | _job_time_taken |\n",
    "| JOB_ABORTED | _job_aborted_count | |\n",
    "| JOB_CANCELLED | _job_cancelled_count | |\n",
    "| CLIENT_DISCONNECTED | _client_disconnected_count | |\n",
    "| CLIENT_RECONNECTED | _client_reconnected_count | |\n",
    "| BEFORE_PULL_TASK | _before_pull_task_count |  |\n",
    "| AFTER_PULL_TASK | _after_pull_task_count | _pull_task_time_taken |\n",
    "| BEFORE_PROCESS_TASK_REQUEST | _before_process_task_request_count | |\n",
    "| AFTER_PROCESS_TASK_REQUEST | _after_process_task_request_count | _process_task_request_time_taken |\n",
    "| BEFORE_PROCESS_SUBMISSION | _before_process_submission_count |  |\n",
    "| AFTER_PROCESS_SUBMISSION | _after_process_submission_count | _process_submission_time_taken |\n",
    "| BEFORE_TASK_DATA_FILTER | _before_task_data_filter_count |  |\n",
    "| AFTER_TASK_DATA_FILTER | _after_task_data_filter_count | _data_filter_time_taken |\n",
    "| BEFORE_TASK_RESULT_FILTER | _before_task_result_filter_count |  |\n",
    "| AFTER_TASK_RESULT_FILTER | _after_task_result_filter_count | _result_filter_time_taken |\n",
    "| BEFORE_TASK_EXECUTION | _before_task_execution_count |  |\n",
    "| AFTER_TASK_EXECUTION | _after_task_execution_count | _task_execution_time_taken |\n",
    "| BEFORE_SEND_TASK_RESULT | _before_send_task_result_count |  |\n",
    "| AFTER_SEND_TASK_RESULT | _after_send_task_result_count | _send_task_result_time_taken |\n",
    "| BEFORE_PROCESS_RESULT_OF_UNKNOWN_TASK | _before_process_result_of_unknown_task_count |  |\n",
    "| AFTER_PROCESS_RESULT_OF_UNKNOWN_TASK | _after_process_result_of_unknown_task_count | _process_result_of_unknown_task_time_taken |\n",
    "| PRE_RUN_RESULT_AVAILABLE | _pre_run_result_available_count | |\n",
    "| BEFORE_CHECK_CLIENT_RESOURCES | _before_check_client_resources_count |  |\n",
    "| AFTER_CHECK_CLIENT_RESOURCES | _after_check_client_resources./ways_to_interact_with_fl_system.ipynb_count | _check_client_resources_time_taken |\n",
    "| SUBMIT_JOB | _submit_job_count | |\n",
    "| DEPLOY_JOB_TO_SERVER | _deploy_job_to_server_count | |\n",
    "| DEPLOY_JOB_TO_CLIENT | _deploy_job_to_client_count | |\n",
    "| BEFORE_CHECK_RESOURCE_MANAGER | _before_check_resource_manager_count | |\n",
    "| BEFORE_SEND_ADMIN_COMMAND | _before_send_admin_command_count | |\n",
    "| BEFORE_CLIENT_REGISTER | _before_client_register_count | |\n",
    "| AFTER_CLIENT_REGISTER | _after_client_register_count | client_register_time_taken |\n",
    "| CLIENT_REGISTER_RECEIVED | _client_register_received_count | |\n",
    "| CLIENT_REGISTER_PROCESSED | _client_register_processed_count | |\n",
    "| CLIENT_QUIT | _client_quit_count | |\n",
    "| SYSTEM_BOOTSTRAP | _system_bootstrap_count | |\n",
    "| BEFORE_AGGREGATION | _before_aggregation_count | |\n",
    "| END_AGGREGATION | _end_aggregation_count | _aggregation_time_taken|\n",
    "| RECEIVE_BEST_MODEL | _receive_best_model_count | |\n",
    "| BEFORE_TRAIN | _before_train_count | |\n",
    "| AFTER_TRAIN | _after_train_count |_train_time_taken |\n",
    "| TRAIN_DONE | _train_done_count | |\n",
    "| TRAINING_STARTED | _training_count | |\n",
    "| TRAINING_FINISHED | _training_count | _training_time_taken|\n",
    "| ROUND_STARTED | _round_started_count | |\n",
    "| ROUND_DONE | _round_done_count |  _round_time_taken |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "components-section",
   "metadata": {},
   "source": [
    "## NVIDIA FLARE Monitoring Components\n",
    "\n",
    "NVIDIA FLARE provides several components for collecting and publishing metrics. Understanding these components is essential for configuring your monitoring setup.\n",
    "\n",
    "### Key Monitoring Components\n",
    "\n",
    "1. **StatsDReporter**: Publishes collected metrics to a StatsD Exporter service\n",
    "2. **JobMetricsCollector**: Collects job-level metrics and publishes them to the databus\n",
    "3. **SysMetricsCollector**: Collects system-level metrics from the parent processes\n",
    "4. **RemoteMetricsReceiver**: Receives metrics streamed from clients and publishes them\n",
    "\n",
    "### Component Configuration\n",
    "\n",
    "Let's look at how to configure these components for different monitoring setups.\n",
    "\n",
    "> **Note**: NVIDIA FLARE uses a simple JSON format for component configuration:\n",
    "```json\n",
    "{ \n",
    "   \"id\": \"<component_identifier>\",\n",
    "   \"path\": \"<component_class_path>\",\n",
    "   \"args\": {\n",
    "       \"<arg_name>\": \"<arg_value>\"\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Setup 1: Shared Monitoring System\n",
    "\n",
    "In this setup, all sites post metrics to a common StatsD Exporter service. Each site needs both JobMetricsCollector and SysMetricsCollector components.\n",
    "\n",
    "**Client Configuration (`fed_config_client.json`):**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"job_metrics_collector\",\n",
    "    \"path\": \"nvflare.metrics.job_metrics_collector.JobMetricsCollector\",\n",
    "    \"args\": {\n",
    "        \"tags\": {\n",
    "            \"site\": \"site_1\",\n",
    "            \"env\": \"dev\"\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"statsd_reporter\",\n",
    "    \"path\": \"nvflare.fuel_opt.statsd.statsd_reporter.StatsDReporter\",\n",
    "    \"args\": {\n",
    "        \"host\": \"<statsd_exporter_host>\",\n",
    "        \"port\": <statsd_exporter_port>\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Server Configuration (`fed_config_server.json`):**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"job_metrics_collector\",\n",
    "    \"path\": \"nvflare.metrics.job_metrics_collector.JobMetricsCollector\",\n",
    "    \"args\": {\n",
    "        \"tags\": {\n",
    "            \"site\": \"server\",\n",
    "            \"env\": \"dev\"\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"statsd_reporter\",\n",
    "    \"path\": \"nvflare.fuel_opt.statsd.statsd_reporter.StatsDReporter\",\n",
    "    \"args\": {\n",
    "        \"host\": \"<statsd_exporter_host>\",\n",
    "        \"port\": <statsd_exporter_port>\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**System Metrics Configuration (`resources.json`):**\n",
    "\n",
    "For system-level metrics, you need to configure the SysMetricsCollector in the local resources configuration file for each site. This is done by creating or modifying the `resources.json` file in the site's local directory.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"sys_metrics_collector\",\n",
    "    \"path\": \"nvflare.metrics.sys_metrics_collector.SysMetricsCollector\",\n",
    "    \"args\": {\n",
    "        \"tags\": {\n",
    "            \"site\": \"<site_name>\",\n",
    "            \"env\": \"dev\"\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"statsd_reporter\",\n",
    "    \"path\": \"nvflare.fuel_opt.statsd.statsd_reporter.StatsDReporter\",\n",
    "    \"args\": {\n",
    "        \"host\": \"<statsd_exporter_host>\",\n",
    "        \"port\": <statsd_exporter_port>\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Setup 2: Client-to-Server Metrics Forwarding\n",
    "\n",
    "In this setup, clients forward their metrics to the server, which then publishes all metrics to a monitoring system.\n",
    "\n",
    "**Client Configuration (`fed_config_client.json`):**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"job_metrics_collector\",\n",
    "    \"path\": \"nvflare.metrics.job_metrics_collector.JobMetricsCollector\",\n",
    "    \"args\": {\n",
    "        \"tags\": {\n",
    "            \"site\": \"site_1\",\n",
    "            \"env\": \"dev\"\n",
    "        }, \n",
    "        \"streaming_to_server\": true\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"event_convertor\",\n",
    "    \"path\": \"nvflare.app_common.widgets.convert_to_fed_event.ConvertToFedEvent\",\n",
    "    \"args\": {\n",
    "      \"events_to_convert\": [\"metrics_event\"]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Server Configuration (`fed_config_server.json`):**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"job_metrics_collector\",\n",
    "    \"path\": \"nvflare.metrics.job_metrics_collector.JobMetricsCollector\",\n",
    "    \"args\": {\n",
    "        \"tags\": {\n",
    "            \"site\": \"server\",\n",
    "            \"env\": \"dev\"\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"statsd_reporter\",\n",
    "    \"path\": \"nvflare.fuel_opt.statsd.statsd_reporter.StatsDReporter\",\n",
    "    \"args\": {\n",
    "        \"host\": \"<statsd_exporter_host>\",\n",
    "        \"port\": <statsd_exporter_port>\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"id\": \"remote_metrics_receiver\",\n",
    "    \"path\": \"nvflare.metrics.remote_metrics_reciever.RemoteMetricsReceiver\",\n",
    "     \"args\": {\n",
    "         \"events\": [\"fed.metrics_event\"]\n",
    "     }\n",
    "} \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**System Metrics Configuration:**\n",
    "\n",
    "This is similar to Setup 1, but clients don't need the StatsDReporter in their resources.json, while the server does.\n",
    "\n",
    "#### Setup 3: Individual Monitoring Systems for Each Site\n",
    "\n",
    "In this setup, each site (server and clients) has its own dedicated monitoring infrastructure.\n",
    "\n",
    "The configuration is similar to Setup 1, but with each site pointing to its own StatsD Exporter instance:\n",
    "\n",
    "- Each site uses the same components (JobMetricsCollector, StatsDReporter, etc.)\n",
    "- The `host` and `port` parameters in the StatsDReporter configuration are unique for each site\n",
    "- This allows for independent monitoring and potentially better isolation between sites\n",
    "\n",
    "This approach is useful when sites are in different network environments or when you need separate monitoring dashboards for each participant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## Practical Example: Monitoring a Federated Learning Job\n",
    "\n",
    "To see how monitoring works in practice, see the [job example notebook](job_example.ipynb).\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this section, we've explored NVIDIA FLARE's monitoring capabilities, including:\n",
    "\n",
    "- Different monitoring setup options based on deployment needs\n",
    "- The wide range of metrics collected by NVIDIA FLARE\n",
    "- How to configure monitoring components for different setups\n",
    "\n",
    "Effective monitoring is essential for maintaining reliable federated learning systems, optimizing performance, and troubleshooting issues. By implementing the monitoring approaches described in this section, you can gain valuable insights into your federated learning deployments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
