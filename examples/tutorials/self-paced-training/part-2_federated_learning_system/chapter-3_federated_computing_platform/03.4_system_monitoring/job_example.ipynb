{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLARE Monitoring\n",
    "FLARE Monitoring provides a initial solution for tracking system metrics of your federated learning jobs.\n",
    "Different from Machine learning experiment tracking, where it focused on the training metrics, the monitoring here focused on the FL system: i.e. job and system lifecycle metrics. \n",
    "\n",
    "This guide will walk you through the steps to set up and use the monitoring system effectively.\n",
    "\n",
    "\n",
    "## Start up the monitoring system\n",
    "\n",
    "In this example, we simulate the real setup on the local host. To keep the example simple, we will only set up 1 and 2. You can easily follow the steps to work out step 3.\n",
    "\n",
    "In steps 1 and 2, we only need one monitoring system. Assuming you already have Docker and Docker Compose installed, you can use the provided [`docker-compose.yml`](../setup/docker-compose.yml) file to set up StatsD Exporter, Prometheus, and Grafana.\n",
    "\n",
    ">Note: As of July 2023, docker-compose v1 is no longer supported. Make sure you download and use v2, verify docker compose version\n",
    " ```\n",
    "    docker compose version\n",
    " ```\n",
    " \n",
    "\n",
    "### Steps:\n",
    "\n",
    "From a terminal, not from Notebook cell\n",
    "\n",
    "1. Navigate to the setup directory:\n",
    "    ```bash\n",
    "    cd setup\n",
    "    ```\n",
    "\n",
    "2. Start the services using Docker Compose:\n",
    "    ```bash\n",
    "    docker compose up -d\n",
    "    ```\n",
    "    You should see something similar to the following:\n",
    "\n",
    "    ```\n",
    "    Creating network \"setup_monitoring\" with driver \"bridge\"\n",
    "    Creating statsd-exporter ... done\n",
    "    Creating prometheus      ... done\n",
    "    Creating grafana         ... done\n",
    "    ```\n",
    "\n",
    "3. To stop the services, run:\n",
    "    ```bash\n",
    "    docker compose down\n",
    "    ```\n",
    "\n",
    "**Note:** The StatsD Exporter port is 9125 (not 8125).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd setup\n",
    "\n",
    "!docker compose up -d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose down\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prepare FLARE Metrics Monitoring Configuration\n",
    " \n",
    "### Prepare Configuration for Setup 1: All Sites Share the Same Monitoring System\n",
    "\n",
    "![setup-1](./figures/setup-1.png)\n",
    "\n",
    "As described in the [system monitorinig introduction](./system_monitorinig.ipynb), we will make different component configurations depending on the setups.\n",
    "\n",
    "In this setup, all sites (server and clients) will share the same monitoring system with the same host and port.\n",
    "\n",
    "#### Job Metrics Monitoring Configuration\n",
    "\n",
    "Instead of manually configuring the metrics monitoring, we can directly use the Job API. You can refer to the [jobs/setup-1/code/](./jobs/setup-1/code/fl_job.py).\n",
    "\n",
    "This is done by adding additional components on top of the existing code:\n",
    "\n",
    "```python\n",
    "    \n",
    "    server_tags = {\"site\": \"server\", \"env\": \"dev\"}\n",
    "    metrics_reporter = StatsDReporter(site=\"server\", host=\"localhost\", port=9125)\n",
    "    metrics_collector = JobMetricsCollector(tags=server_tags, streaming_to_server=False)\n",
    "\n",
    "    job.to_server(metrics_collector, id=\"server_job_metrics_collector\")\n",
    "    job.to_server(metrics_reporter, id=\"statsd_reporter\")\n",
    "\n",
    "    # Add clients\n",
    "    for i in range(n_clients):\n",
    "        \n",
    "        <skip code >\n",
    "\n",
    "        # add client side monitoring components\n",
    "        tags = {\"site\": client_site, \"env\": \"dev\"}\n",
    "\n",
    "        metrics_collector = JobMetricsCollector(tags=tags)\n",
    "\n",
    "        job.to(metrics_collector, target=client_site, id=f\"{client_site}_job_metrics_collector\")\n",
    "        job.to(metrics_reporter, target=client_site, id=\"statsd_reporter\")\n",
    "\n",
    "```\n",
    "\n",
    "#### System Metrics Monitoring Configuration\n",
    "\n",
    "We need to manually edit the configuration files for System Metrics collections.\n",
    "\n",
    "For example, we need to add server to include \n",
    "\n",
    "* system metrics collector \n",
    "* statsd reporter\n",
    "\n",
    "In the default POC setup, these components are added to \n",
    "\"/tmp/nvflare/poc/example_project/prod_00/server/local/resources.json\"\n",
    "\n",
    "For Client sides, we need to add \n",
    "\n",
    "* system metrics collector \n",
    "* statsd reporter\n",
    "\n",
    "\"/tmp/nvflare/poc/example_project/prod_00/<site-n>/local/resources.json\"\n",
    "\n",
    "for the default POC setup.\n",
    "\n",
    "\n",
    "Instead of manually, go through each file, we wrote a small python program to do this: \n",
    "\n",
    "```bash\n",
    "cd setup-1\n",
    "./prepare_local_config.sh  false\n",
    "```\n",
    "This will generate the needed system configuration for each site in this setup. \n",
    "\n",
    "\n",
    "## Start up FLARE FL system with POC\n",
    "\n",
    "Now we are ready to start the FLARE FL system.\n",
    "\n",
    "1. Prepare POC:\n",
    "\n",
    "    ```bash\n",
    "    nvflare poc prepare\n",
    "    ```\n",
    "\n",
    "    This will prepare 1 server and 2 clients (\"site-1\", \"site-2\") and one admin console client (admin@nvidia.com). You can examine the output directory: ```/tmp/nvflare/poc/example_project/prod_00```.\n",
    "\n",
    "2. Start POC:\n",
    "    ```bash\n",
    "    nvflare poc start -ex admin@nvidia.com\n",
    "    ```\n",
    "    This will exclude the admin console service.\n",
    "\n",
    "3. Run Job:\n",
    "    See the run job section.\n",
    "\n",
    "4. Stop POC:\n",
    "    After you complete the job run, you can stop the POC by:\n",
    "\n",
    "    ```bash\n",
    "    nvflare poc stop\n",
    "    ```\n",
    "\n",
    "## Run Job via CLI\n",
    "\n",
    "To run the job from the command line, use the following command:\n",
    "\n",
    "```bash\n",
    "# Generate job config folder\n",
    "python3 fl_job.py -j /tmp/nvflare/jobs/job_config\n",
    "\n",
    "# Submit the NVFlare job\n",
    "nvflare job submit -j /tmp/nvflare/jobs/job_config/fedavg\n",
    "```\n",
    "\n",
    "\n",
    "## Monitoring View\n",
    "\n",
    "Once you setup the system, you can view from the followingt website\n",
    "for statsd-exporter, you can look at \n",
    "\n",
    "### Statsd-exporter metrics view\n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "metrics page: \"http://localhost:9102/metrics\" \n",
    "\n",
    "for the metrics published to statsd-export, which can be scraped by prometheus.\n",
    "Here is a screen shot\n",
    "\n",
    "![screen shot](./figures/statsd_export_metrics_view.png)\n",
    "\n",
    "\n",
    "### Prometheus metrics view\n",
    "The same metrics is scraped by Prometheus can be found in this URL\n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "metrics page: \"http://localhost:9090/metrics\"\n",
    "\n",
    "\n",
    "### Grafana Dashboard views\n",
    "\n",
    "We can visualize them better via Grafana. \n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "Visualization: http://localhost:3000\n",
    "\n",
    "Here are two metrics dashboards examples\n",
    "\n",
    "![Client heartbeat (before & after) time taken](./figures/grafana_plot_metrics_heatbeat_time_taken.png)\n",
    "\n",
    "![task processed accumated count](./figures/grafana_plot_metrics_view_task_count.png)\n",
    "\n",
    "\n",
    "\n",
    "## Complete steps\n",
    "\n",
    "Now, lets go to terminal and following all the steps to do the excersize\n",
    "\n",
    "* install dependencies \n",
    "\n",
    " ```\n",
    "    pip install -r jobs/requirements.txt\n",
    "    \n",
    " ```\n",
    "\n",
    "* start monitoring systems (statsD, prometheus and grafana)\n",
    "    \n",
    "    ```\n",
    "    cd setup \n",
    "    \n",
    "    docker compose up -d\n",
    "\n",
    "    cd ..\n",
    "    ```\n",
    "\n",
    "\n",
    "* prepare poc\n",
    "\n",
    "```\n",
    "    nvflare poc prepare -n  5\n",
    "\n",
    "```\n",
    "\n",
    "* prepare local site configurations\n",
    "\n",
    "```\n",
    "    # the argument stream_to_server = false\n",
    "    \n",
    "    jobs/prepare_local_config.sh false\n",
    "```\n",
    "   \n",
    "* start poc \n",
    "\n",
    "```\n",
    "    nvflare poc start -ex admin@nvidia.com \n",
    "\n",
    "```\n",
    "\n",
    "* prepare data\n",
    "\n",
    "```\n",
    "   python jobs/data/download.py\n",
    "\n",
    "```\n",
    "\n",
    "* submit job\n",
    "\n",
    "\n",
    "```bash\n",
    "    cd jobs/setup-1/code\n",
    "\n",
    "    ./submit_job.sh\n",
    "```\n",
    "\n",
    "* Monitoring System performance\n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "statsd metrics page: \"http://localhost:9102/metrics\" \n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "prometheus metrics page: \"http://localhost:9090/metrics\"\n",
    "\n",
    "<!-- markdown-link-check-disable -->\n",
    "grafana visualization: http://localhost:3000\n",
    "\n",
    "\n",
    "* Stop POC\n",
    "\n",
    "```\n",
    "    nvflare poc stop\n",
    "\n",
    "    nvflare poc clean\n",
    "```\n",
    "   \n",
    "* Stop Monitoring Systems\n",
    "\n",
    "```\n",
    "    docker compose down\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Setup 2: Client Metrics streamed to Server\n",
    "\n",
    "In this setup, only the server site is connected to the monitoring system. This allows the server to monitor metrics on all client sites.\n",
    "\n",
    "![setup-2](./figures/setup-2.png)\n",
    "\n",
    "### Prepare Configuration for Setup 2: Client Metrics Streamed to Server\n",
    "\n",
    "Similar to setup 1, we need to consider both job and system level configurations\n",
    "\n",
    "\n",
    "#### Job Metrics Monitoring Configuration\n",
    "\n",
    "We will configure the job to stream client metrics to the server. You can refer to the [jobs/setup-2/coode/fl_job.py](jobs/setup-2/code/fl_job.py).\n",
    "\n",
    "Here is the configuration:\n",
    "\n",
    "```python\n",
    " job_name = \"fedavg\"\n",
    "\n",
    "\n",
    "# add server side monitoring components\n",
    "\n",
    "server_tags = {\"site\": \"server\", \"env\": \"dev\"}\n",
    "\n",
    "metrics_reporter = StatsDReporter(site=\"server\", host=\"localhost\", port=9125)\n",
    "metrics_collector = JobMetricsCollector(tags=server_tags, streaming_to_server=False)\n",
    "remote_metrics_receiver = RemoteMetricsReceiver(events=[METRICS_EVENT_TYPE])\n",
    "\n",
    "job.to_server(metrics_collector, id=\"server_job_metrics_collector\")\n",
    "job.to_server(metrics_reporter, id=\"statsd_reporter\")\n",
    "job.to_server(remote_metrics_receiver, id=\"remote_metrics_receiver\")\n",
    "\n",
    "fed_event_converter = ConvertToFedEvent(events_to_convert=[METRICS_EVENT_TYPE])\n",
    "\n",
    "\n",
    "# clients\n",
    "   ....<skip code> ...\n",
    "\n",
    "   client_site = f\"site-{i + 1}\"\n",
    "   job.to(executor, client_site)\n",
    "\n",
    "   # add client side monitoring components\n",
    "   tags = {\"site\": client_site, \"env\": \"dev\"}\n",
    "\n",
    "   metrics_collector = JobMetricsCollector(tags=tags)\n",
    "\n",
    "   job.to(metrics_collector, target=client_site, id=f\"{client_site}_job_metrics_collector\")\n",
    "   job.to(fed_event_converter, target= client_site, id=f\"event_converter\")\n",
    "```\n",
    "\n",
    "#### System Metrics Monitoring Configuration\n",
    "\n",
    "We need to manually edit the configuration files for System Metrics collections.\n",
    "\n",
    "We can use the same code in step is pretty the same except the followings\n",
    "\n",
    "* prepare local configs\n",
    "\n",
    "```bash\n",
    "   # stream_to_server = true\n",
    "   \n",
    "   jobs/prepare_local_config.sh true\n",
    "   \n",
    "```\n",
    "\n",
    "* submit job\n",
    "\n",
    "\n",
    "```bash\n",
    "    cd jobs/setup-2/code\n",
    "\n",
    "    ./submit_job.sh\n",
    "```\n",
    "\n",
    "\n",
    "### Complete with rest of the steps \n",
    "\n",
    "  * start monitoring system\n",
    "  * start the POC\n",
    "  * submit job\n",
    "  * review the metrics and visualization\n",
    "  * stop the POC \n",
    "  * stop monitoring system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
