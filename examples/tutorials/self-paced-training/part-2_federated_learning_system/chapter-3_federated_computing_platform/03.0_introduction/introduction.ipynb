{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397e8d18-2aab-4aa4-b186-68e8acbfc71a",
   "metadata": {},
   "source": [
    "# NVIDIA FLARE's Federated Computing Platform\n",
    "\n",
    "\n",
    "In this chapter, we will overview the NVIDIA FLARE (NVFlare)'s core concept and system architecture. Explore different aspects of the NVFlare's system. Simulate the deployment locally and see how to interact with the system. \n",
    "\n",
    "## Federated Learning vs. Federated Computing\n",
    "\n",
    "At its core, FLARE serves as a federated computing framework, with applications such as Federated Learning and Federated Analytics built upon this foundation. Notably, it is agnostic to datasets, workloads, and domains. In contrast to centralized data lake solutions that necessitate copying data to a central location, FLARE brings computing capabilities directly to distributed datasets. This approach ensures that data remains within the compute node, with only pre-approved, selected results shared among collaborators. Moreover, FLARE is system agnostic, offering easy integration with various data processing frameworks through the implementation of the FLARE client. This client facilitates deployment in sub-processes, Docker containers, Kubernetes pods, HPC, or specialized systems.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e73876",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "In NVIDIA FLARE (NVFlare), therea are few core concepts: \n",
    "\n",
    "* Server side component: Controller\n",
    "* Client side compoenet: Executor\n",
    "* Communication message: Sharable \n",
    "* Filtering mechanism\n",
    "* Building Block: FLComponent \n",
    "* Job\n",
    "* \n",
    "\n",
    "In Part 1, we only encountered Job, we will discuss the rest in this section\n",
    "\n",
    "### Controller\n",
    "\n",
    "The controller is the object that define the logics for the clients to follows. The controller API makes it possible to create any client coordination logic in an federated learning workflow. \n",
    "\n",
    "In other works, the controller defines the workflow: i.e. how the federated execution will be carry out, for example, the execution is in round-robin style or scatter & gather style, is defined by controller. \n",
    "\n",
    "The controller, in the most cases, in exceuted on the FL server. Some refers this as server stratedy.  The controller can also be executed in client side ( refer as client-side-controller). This can be used for define peer-to-peer style of workflow such as swarm learning. \n",
    "\n",
    "\n",
    " ### Executor\n",
    "\n",
    "The Exectuor is the object that defines the logics to execute on the client side. It handles the task defined by Controller and response back the task requests. \n",
    "\n",
    "The interaction between the Controller and Executor can be found the following picture \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8109c",
   "metadata": {},
   "source": [
    "### Shareable \n",
    "\n",
    "A [Shareable](https://nvflare.readthedocs.io/en/main/programming_guide/shareable.html) object represents a communication between server and client. Technically a Shareable object is implemented as a Python dict. This dict contains two kinds of information:\n",
    "* Header \n",
    "    * Peer Properties\n",
    "    * Cookie \n",
    "    * return code\n",
    "* Content\n",
    "\n",
    "In other words, Shareaable is nothing but a dictionary with some metadata information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9e4fa",
   "metadata": {},
   "source": [
    "The Controller and Executor exchange Shareable\n",
    "\n",
    "<img src=\"controller_executor_no_filter.png\" alt=\"Controller and executor\" width=\"700\" height=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ed5ee",
   "metadata": {},
   "source": [
    "### Filters\n",
    "\n",
    "NVIDIA FLARE also introduce the filtering mechanism to allow user to limit the input & outputs. Filters in NVIDIA FLARE is way to transform the Shareable object between the communicating parties. A [Filter](https://nvflare.readthedocs.io/en/main/programming_guide/filters.html) can be used to provide additional processing to shareable data before sending or after receiving from the peer.\n",
    "\n",
    "<img src=\"controller_worker_flow.png\" alt=\"Controller and executor with filters\" width=\"700\" height=\"400\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c8200",
   "metadata": {},
   "source": [
    "### FLComponent\n",
    "\n",
    "The NVIDIA FLARE is built with components. FLComponent is the build block of all component (Base Class). Controller, Executor, Fitler and Shareable are all type of FLComponent\n",
    "\n",
    "The core property of FLCompoent is event-suport. FLComponent is able to fire and receive events, this enable the FLARE system event-driven, pluggable system. \n",
    "\n",
    "\n",
    "### Events\n",
    "\n",
    "NVIDIA Flare fires and manages events in the lifecycle of the system. There are two categories of event types: Local Event and Fed Event. \n",
    "\n",
    "Both client and server has local events for the respective system activities. The client's local can also converted to be \"Fed Event\" which means the event will be propergate and fired on the server side. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afae41d",
   "metadata": {},
   "source": [
    "## High-Level Concepts\n",
    "\n",
    "Although understand these core concepts will enable FLARE users to build power federated computing algorithms, but to some data scientists, higher level construct is preferred. \n",
    "\n",
    "NVFLARE also introduced the few concepts to reduce the learning curve. \n",
    "\n",
    " * FLModel -- higher level communication data structure\n",
    "\n",
    "\n",
    "###  FLModel\n",
    "\n",
    "FLModel structure is an higher level data structure that designed for data scientists. This structure may not be general for the common federated computing messaging communication, but it is suitable for the federated learning applications\n",
    "\n",
    "We define a standard data structure FLModel that captures the common attributes needed for exchanging learning results. This is particularly useful when NVFlare system needs to exchange learning information with external training scripts/systems. The external training script/system only need to extract the required information from received FLModel, run local training, and put the results in a new FLModel to be sent back.\n",
    "\n",
    "Behinds the scence, we will convert the FLModel structure to and from Sharable. \n",
    "\n",
    "\n",
    "**FLModel** \n",
    "\n",
    "a standardize data structure for NVFlare to communicate with external systems.\n",
    "\n",
    "**Parameters:**\n",
    "* params_type – type of the parameters. It only describes the “params”. If params_type is None, params need to be None. If params is provided but params_type is not provided, then it will be treated as FULL.\n",
    "* params – model parameters, for example: model weights for deep learning.\n",
    "\n",
    "* optimizer_params – optimizer parameters. For many cases, the optimizer parameters don’t need to be transferred during FL training.\n",
    "\n",
    "* metrics – evaluation metrics such as loss and scores.\n",
    "\n",
    "* start_round – the start FL rounds. A round means round trip between client/server during training. None for inference.\n",
    "\n",
    "* current_round – the current FL rounds. A round means round trip between client/server during training. None for inference.\n",
    "\n",
    "* total_rounds – total number of FL rounds. A round means round trip between client/server during training. None for inference.\n",
    "\n",
    "* meta – metadata dictionary used to contain any key-value pairs to facilitate the process.\n",
    "\n",
    "\n",
    "\n",
    "Now with a few concepts, lets take a look at the [system architecture](../03.1_federated_computing_architecture/system_architecture.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3e92a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
