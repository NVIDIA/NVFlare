{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397e8d18-2aab-4aa4-b186-68e8acbfc71a",
   "metadata": {},
   "source": [
    "# NVIDIA FLARE's Federated Computing Platform\n",
    "\n",
    "## Introduction\n",
    "Welcome to Chapter 3 of our self-paced training course on NVIDIA FLARE! In this chapter, we'll explore the core concepts and system architecture that make NVIDIA FLARE (NVFlare) a powerful platform for federated computing. We'll examine different aspects of the NVFlare system, learn how to simulate deployments, and discover various ways to interact with the system.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this chapter, you will be able to:\n",
    "- Distinguish between federated computing and federated learning, and understand where NVIDIA FLARE fits in\n",
    "- Identify and explain the core components of NVIDIA FLARE's architecture\n",
    "- Understand how these components interact to enable federated workflows\n",
    "\n",
    "## Federated Learning vs. Federated Computing: Understanding the Distinction\n",
    "\n",
    "Before diving into the technical details, let's clarify an important distinction:\n",
    "\n",
    "**Federated Learning** is a specific application of distributed machine learning where models are trained across multiple decentralized devices or servers holding local data samples, without exchanging the data itself.\n",
    "\n",
    "**Federated Computing** is the broader paradigm that enables computation to be performed across distributed systems while maintaining data privacy and security. Federated learning is just one application built on this foundation.\n",
    "\n",
    "NVIDIA FLARE serves as a federated computing framework, with applications such as Federated Learning and Federated Analytics built upon this foundation. Key characteristics include:\n",
    "\n",
    "- **Data Domain Agnostic**: Works with any type of dataset, workload, or domain\n",
    "- **Computation at the Data**: Instead of centralizing data (as in data lake solutions), FLARE brings computing capabilities directly to where data resides\n",
    "- **Privacy-Preserving**: Data remains within its original compute node, with only pre-approved, selected results shared among collaborators\n",
    "- **System Agnostic**: Easily integrates with various data processing frameworks through the FLARE client\n",
    "- **Deployment Flexibility**: Can be deployed in sub-processes, Docker containers, Kubernetes pods, HPC, or specialized systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e73876",
   "metadata": {},
   "source": [
    "## Core Concepts of NVIDIA FLARE\n",
    "\n",
    "To understand how NVIDIA FLARE works, we need to familiarize ourselves with several key concepts that form the foundation of its architecture. Let's explore each one in detail:\n",
    "\n",
    "### 1. Controller: The Orchestrator\n",
    "\n",
    "**What is it?** The Controller defines the logic for clients to follow and orchestrates the entire federated workflow.\n",
    "\n",
    "**Key responsibilities:**\n",
    "- Determines how federated execution will be carried out\n",
    "- Defines the coordination pattern (e.g., round-robin, scatter & gather)\n",
    "- Manages the flow of tasks to clients\n",
    "- Processes responses from clients\n",
    "\n",
    "**Where does it run?** In most cases, the Controller runs on the FL server (sometimes called the \"server strategy\"). However, it can also run on the client side (\"client-side-controller\") to enable peer-to-peer workflows like swarm learning.\n",
    "\n",
    "**Why is it important?** The Controller is the brain of the federated system, making decisions about which clients participate, what tasks they perform, and how results are aggregated.\n",
    "\n",
    "### 2. Executor: The Worker\n",
    "\n",
    "**What is it?** The Executor defines the logic that runs on the client side.\n",
    "\n",
    "**Key responsibilities:**\n",
    "- Receives tasks from the Controller\n",
    "- Executes the requested operations (e.g., model training, evaluation)\n",
    "- Sends results back to the Controller\n",
    "- Manages local resources and data access\n",
    "\n",
    "**Why is it important?** Executors perform the actual computational work in the federated system, operating on local data without sharing the raw data itself.\n",
    "\n",
    "The relationship between Controllers and Executors forms the backbone of NVIDIA FLARE's federated computing architecture. Let's visualize this interaction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9e4fa",
   "metadata": {},
   "source": [
    "**Controller-Executor Interaction:**\n",
    "\n",
    "<img src=\"controller_executor_no_filter.png\" alt=\"Controller and executor\" width=\"700\" height=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8109c",
   "metadata": {},
   "source": [
    "### 3. Shareable: The Communication Medium\n",
    "\n",
    "**What is it?** A [Shareable](https://nvflare.readthedocs.io/en/2.6/programming_guide/shareable.html) is the standardized object that facilitates communication between the server and clients.\n",
    "\n",
    "**Technical implementation:** At its core, a Shareable is a Python dictionary with two main sections:\n",
    "\n",
    "**Header information:**\n",
    "- **Peer Properties**: Information about the sender\n",
    "- **Cookie**: Stateful information that can be passed back and forth\n",
    "- **Return Code**: Status of the operation\n",
    "\n",
    "**Content:**\n",
    "- The actual payload data being transferred (e.g., model weights, evaluation metrics)\n",
    "\n",
    "**Why is it important?** Shareables provide a standardized format for all communication in the federated system, making it easier to implement security measures, track provenance, and ensure compatibility.\n",
    "\n",
    "**Example:** When a server sends a model to a client for training, the model parameters are packaged in a Shareable. When the client completes training, it packages the updated model in a Shareable to send back to the server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ed5ee",
   "metadata": {},
   "source": [
    "### 4. Filters: The Gatekeepers\n",
    "\n",
    "**What are they?** [Filters](https://nvflare.readthedocs.io/en/2.6/programming_guide/filters.html) transform Shareable objects as they pass between communicating parties.\n",
    "\n",
    "**Key capabilities:**\n",
    "- Inspect and modify data before sending or after receiving\n",
    "- Implement privacy-preserving techniques (e.g., differential privacy)\n",
    "- Perform compression or encryption\n",
    "- Validate data against security policies\n",
    "- Log or monitor communication\n",
    "\n",
    "**Why are they important?** Filters provide a modular way to add security, privacy, and efficiency features without changing the core communication logic.\n",
    "\n",
    "**Example use cases:**\n",
    "- Adding noise to model updates for differential privacy\n",
    "- Compressing model weights to reduce bandwidth usage\n",
    "- Encrypting sensitive information\n",
    "- Validating that shared data complies with privacy policies\n",
    "\n",
    "Here's how Filters fit into the Controller-Executor interaction:\n",
    "\n",
    "<img src=\"controller_worker_flow.png\" alt=\"Controller and executor with filters\" width=\"700\" height=\"400\">\n",
    "\n",
    "As shown in the diagram, Filters can be applied on both the sending and receiving sides, creating a flexible pipeline for data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c8200",
   "metadata": {},
   "source": [
    "### 5. FLComponent: The Building Block\n",
    "\n",
    "**What is it?** FLComponent is the fundamental building block of all components in NVIDIA FLARE.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Base class for Controllers, Executors, Filters, and other system components\n",
    "- Provides event support (can fire and receive events)\n",
    "- Enables the event-driven, pluggable architecture of FLARE\n",
    "\n",
    "**Why is it important?** The component-based design allows for modular system construction, where components can be mixed and matched to create different federated workflows.\n",
    "\n",
    "### 6. FLContext: The Information Carrier\n",
    "\n",
    "**What is it?** FLContext is a mechanism for passing data between FL components.\n",
    "\n",
    "**Key capabilities:**\n",
    "- Available to every method of all FLComponent types\n",
    "- Allows components to access services provided by the infrastructure\n",
    "- Enables data sharing between components, even across endpoints\n",
    "\n",
    "**Technical implementation:** FLContext functions like a Python dictionary storing key-value pairs (called \"properties\" or \"props\"). These properties have two important attributes:\n",
    "- **Visibility**: Controls which components can see the property\n",
    "- **Stickiness**: Determines how long the property persists\n",
    "\n",
    "**Why is it important?** FLContext provides a standardized way for components to communicate and share state, making it easier to build complex workflows.\n",
    "\n",
    "### 7. Events: The Communication Mechanism\n",
    "\n",
    "**What are they?** Events are signals that components can fire and respond to during the system's lifecycle.\n",
    "\n",
    "**Types of events:**\n",
    "- **Local Events**: Occur within a single system (client or server)\n",
    "- **Fed Events**: Propagate from client to server\n",
    "\n",
    "**Why are they important?** The event system enables loose coupling between components, allowing for more flexible and extensible system design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afae41d",
   "metadata": {},
   "source": [
    "## Higher-Level Abstractions\n",
    "\n",
    "While understanding the core concepts provides a solid foundation, NVIDIA FLARE also offers higher-level abstractions to simplify development for data scientists and ML practitioners.\n",
    "\n",
    "### FLModel: A Data Scientist-Friendly Structure\n",
    "\n",
    "**What is it?** FLModel is a standardized data structure designed specifically for federated learning applications.\n",
    "\n",
    "**Key components:**\n",
    "- **params_type**: Describes the type of parameters (e.g., FULL, DIFF)\n",
    "- **params**: The actual model parameters (e.g., neural network weights)\n",
    "- **optimizer_params**: Parameters for the optimization algorithm\n",
    "- **metrics**: Evaluation metrics such as loss and scores\n",
    "- **round information**: start_round, current_round, total_rounds\n",
    "- **meta**: A metadata dictionary for any additional key-value pairs\n",
    "\n",
    "**Behind the scenes:** FLModel is converted to and from Shareable objects automatically, abstracting away the lower-level details.\n",
    "\n",
    "**Why is it important?** FLModel simplifies the interface between NVIDIA FLARE and external training systems, allowing data scientists to focus on their models rather than communication details.\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "Now that we've explored the core concepts of NVIDIA FLARE's federated computing platform, let's summarize how they work together:\n",
    "\n",
    "1. The **Controller** (typically on the server) orchestrates the federated workflow\n",
    "2. It communicates with **Executors** (on clients) by sending and receiving **Shareable** objects\n",
    "3. **Filters** can transform these Shareables to implement privacy, security, or efficiency features\n",
    "4. All of these components are built on the **FLComponent** base class, enabling an event-driven architecture\n",
    "5. Components communicate with each other through **FLContext** and **Events**\n",
    "6. Higher-level abstractions like **FLModel** simplify development for specific use cases\n",
    "\n",
    "In the next section, we'll explore the [system architecture](../03.1_federated_computing_architecture/system_architecture.ipynb) in more detail, seeing how these concepts are implemented in practice.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- NVIDIA FLARE is a federated computing platform that brings computation to data, rather than centralizing data\n",
    "- The Controller-Executor interaction forms the backbone of federated workflows\n",
    "- Shareables standardize communication between components\n",
    "- Filters provide a modular way to implement privacy, security, and efficiency features\n",
    "- The component-based, event-driven architecture enables flexible system design\n",
    "- Higher-level abstractions simplify development for specific use cases\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
