{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d1aff5",
   "metadata": {},
   "source": [
    "# NVIDIA FLARE System Architecture\n",
    "\n",
    "## Introduction\n",
    "In the previous section, we explored the core concepts of NVIDIA FLARE. Now, we'll dive deeper into the system architecture that brings these concepts to life. Understanding this architecture will help you appreciate how NVIDIA FLARE enables secure, scalable, and flexible federated computing.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this section, you will be able to:\n",
    "- Describe the layered architecture of NVIDIA FLARE\n",
    "- Explain the FLARE Communication Interface (FCI) and its capabilities\n",
    "- Understand the federated job processing architecture\n",
    "- Identify the different types of APIs available in NVIDIA FLARE\n",
    "- Navigate the configuration system and job templates\n",
    "\n",
    "## NVIDIA FLARE: Key Characteristics\n",
    "\n",
    "Before examining the technical architecture, let's understand what makes NVIDIA FLARE unique as a federated computing platform:\n",
    "\n",
    "* **Open Source**: Released under Apache License 2.0 to foster research and development in federated learning\n",
    "  \n",
    "* **Production-Ready**: Designed with enterprise requirements in mind, including security, scalability, and reliability\n",
    "   \n",
    "* **Hardware Flexibility**: Capable of running on CPU, GPU, and Multi-GPU environments\n",
    "\n",
    "* **Global Collaboration**: Enables cross-country, distributed, multi-party collaborative learning\n",
    "\n",
    "* **Enterprise Scalability**: Offers high availability and multi-task execution capabilities\n",
    "\n",
    "* **Universal Applicability**: Framework, model, domain, and task agnostic design\n",
    "\n",
    "* **Extensible Architecture**: Layered, pluggable, customizable federated compute architecture\n",
    "\n",
    "## The Layered Architecture\n",
    "\n",
    "NVIDIA FLARE is built using a layered architecture, where each layer provides specific functionality and builds upon the layers below it. This design enables modularity, extensibility, and separation of concerns.\n",
    "\n",
    "<img src=\"./flare_overview.png\" alt=\"FLARE Architecture\" width=\"700\" height=\"400\">\n",
    "\n",
    "Let's explore each layer from bottom to top:\n",
    "\n",
    "### 1. Network Communication Layer\n",
    "\n",
    "At the foundation of NVIDIA FLARE is the network communication layer, which handles all data exchange between participants in the federated system.\n",
    "\n",
    "**Key components:**\n",
    "- **Communication drivers**: gRPC, HTTP + WebSocket, TCP, and plugin drivers\n",
    "- **CellNet**: Logical end-to-end (cell to cell) network\n",
    "- **Message handling**: Reliable streaming message capabilities\n",
    "\n",
    "### 2. Federated Computing Layer\n",
    "\n",
    "Built on top of the communication layer, the federated computing layer manages the execution of federated workflows.\n",
    "\n",
    "**Key capabilities:**\n",
    "- **Job management**: Resource-based scheduling, monitoring, concurrent lifecycle management\n",
    "- **High availability**: Ensuring system reliability even when components fail\n",
    "- **Component management**: Handling plugin components\n",
    "- **Configuration**: Managing system and job configurations\n",
    "- **Event handling**: Processing both local and federated events\n",
    "\n",
    "### 3. Privacy & Security Layer\n",
    "\n",
    "This critical layer ensures that federated learning workflows maintain data privacy and system security.\n",
    "\n",
    "**Key capabilities:**\n",
    "- **Authentication**: Verifying the identity of participants using certificates\n",
    "- **Authorization**: Controlling access to system resources based on roles\n",
    "- **Secure communication**: Encrypting data in transit between participants\n",
    "- **Privacy-preserving techniques**: Differential privacy, homomorphic encryption, secure aggregation\n",
    "- **Audit logging**: Recording system activities for compliance and security analysis\n",
    "- **Data governance**: Enforcing policies on what data can be shared\n",
    "\n",
    "### 4. Federated Workflow Layer\n",
    "\n",
    "This layer implements specific patterns for federated execution.\n",
    "\n",
    "**Some of the supported workflows:**\n",
    "- **Scatter and Gather (SAG)**: The classic federated learning pattern\n",
    "- **Cyclic**: Sequential training across clients\n",
    "- **Cross-site Evaluation**: Evaluating models across different sites\n",
    "- **Swarm Learning**: Peer-to-peer federated learning\n",
    "- **Federated Analytics**: Analyzing distributed data without sharing raw data\n",
    "\n",
    "### 5. Programming APIs Layer\n",
    "\n",
    "This layer provides interfaces for developers to interact with the NVIDIA FLARE system at different levels of abstraction.\n",
    "\n",
    "**Key APIs:**\n",
    "- **Low-level APIs**: Controller and Executor APIs for custom workflow development\n",
    "- **High-level APIs**: ModelController and Client APIs for simplified ML workflows\n",
    "- **Job APIs**: For job configuration and management\n",
    "- **Admin APIs**: For system administration and monitoring\n",
    "- **Integration APIs**: For connecting with external ML frameworks (PyTorch, TensorFlow, etc.)\n",
    "\n",
    "### 6. Federated Learning Algorithms Layer\n",
    "\n",
    "At this layer, specific federated learning algorithms are implemented using the capabilities provided by the lower layers.\n",
    "\n",
    "**Examples include:**\n",
    "- FedAvg (Federated Averaging)\n",
    "- FedOpt (Federated Optimization)\n",
    "- FedProx (Federated Proximal)\n",
    "- Scaffold\n",
    "- And many more specialized algorithms\n",
    "\n",
    "### 7. Tools Layer\n",
    "\n",
    "The top layer provides tools for both development and production environments.\n",
    "\n",
    "#### Development Tools\n",
    "- **Simulator**: For testing federated learning workflows in a simulated environment\n",
    "- **POC Mode**: For creating proof-of-concept deployments on a single machine\n",
    "- **Debugging utilities**: For troubleshooting federated learning applications\n",
    "- **Visualization tools**: For analyzing results and system performance\n",
    "- **Job templates**: Pre-configured job templates for common scenarios\n",
    "\n",
    "#### Production Tools\n",
    "- **Provisioning system**: For creating secure startup kits for participants\n",
    "- **Admin console**: For managing the federated learning system\n",
    "- **Monitoring dashboard**: For tracking system health and job progress\n",
    "- **Deployment utilities**: For managing system deployment across organizations\n",
    "- **Security management**: For handling certificates, keys, and access control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6ad61",
   "metadata": {},
   "source": [
    "## FLARE Communication Interface (FCI)\n",
    "\n",
    "The FLARE Communication Interface (FCI) is a critical component that deserves special attention. It provides the foundation for all communication in the federated system.\n",
    "\n",
    "### What is FCI?\n",
    "\n",
    "FCI is a logical network framework that supports asynchronous, two-way communication through multiple transport mechanisms. It's designed to be flexible, efficient, and secure.\n",
    "\n",
    "### Key Capabilities of FCI\n",
    "\n",
    "* **Pluggable Architecture**: Supports different messaging patterns (request-response, broadcast, pub/sub) and transport mechanisms (TCP, Pipe, HTTP/WS, gRPC) through drivers\n",
    "\n",
    "* **Efficient Streaming**: Large binary data can be streamed in small chunks to minimize memory usage\n",
    "\n",
    "* **Full-duplex Communication**: Both sides can send messages to each other without polling (if the transport supports it)\n",
    "\n",
    "* **Multiplexing**: Multiple conversations can occur over the same connection simultaneously using stream IDs\n",
    "\n",
    "* **Asynchronous Messaging**: Can send/receive messages asynchronously (fire-and-forget, message listening)\n",
    "\n",
    "* **Client-Initiated Connections**: All TCP-based connections can be initiated from clients, eliminating the need for clients to expose ports\n",
    "\n",
    "* **Inter-Process Communication**: Works with communications through pipes or sockets between processes\n",
    "\n",
    "* **Built-in Heartbeats**: Maintains connection health through heartbeat mechanisms\n",
    "\n",
    "### FCI Architecture\n",
    "\n",
    "FCI itself has a layered architecture:\n",
    "\n",
    "<img src=\"./fci.png\" alt=\"FLARE Communication Interface\" width=\"300\" height=\"400\">\n",
    "\n",
    "* **API Layer**: Exposes interfaces like Communicator and Cellnet to application developers\n",
    "\n",
    "* **Streamable Framed Message (SFM)**: The core of FCI that provides abstraction over different communication protocols and manages endpoints and connections\n",
    "\n",
    "* **Transport Drivers**: Responsible for sending frames to other endpoints, treating frames as opaque bytes\n",
    "\n",
    "**Why is this important?** The pluggable nature of FCI means you can switch transport drivers without affecting the application layers. This provides flexibility in deployment and allows for adaptation to different network environments and security requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federated-job",
   "metadata": {},
   "source": [
    "## Federated Job Processing Architecture\n",
    "\n",
    "NVIDIA FLARE uses a job-based architecture to manage federated workflows. This design enables concurrent execution of multiple federated tasks and provides isolation between different workflows.\n",
    "\n",
    "<img src=\"./system_architecture.png\" alt=\"FLARE System Architecture\" width=\"700\" height=\"400\">\n",
    "\n",
    "### Key Components\n",
    "\n",
    "* **Parent Control Processes**: Each site (server and clients) has a parent control process that manages job execution\n",
    "\n",
    "* **Job Processes**: Individual jobs run in separate processes, providing isolation and resource management\n",
    "\n",
    "* **Job Scheduler**: Allocates resources and manages job execution based on priorities and resource availability\n",
    "\n",
    "* **Job Monitor**: Tracks job status and performance metrics\n",
    "\n",
    "### Benefits of the Job Architecture\n",
    "\n",
    "* **Concurrency**: Multiple jobs can run simultaneously\n",
    "* **Isolation**: Jobs are isolated from each other, preventing interference\n",
    "* **Resource Management**: Resources can be allocated based on job requirements\n",
    "* **Fault Tolerance**: Failures in one job don't affect others\n",
    "* **Lifecycle Management**: Jobs can be started, paused, resumed, and terminated independently\n",
    "\n",
    "## Event-Based System\n",
    "\n",
    "NVIDIA FLARE uses an event-driven architecture, where components communicate through events rather than direct method calls. This design enables loose coupling and extensibility.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "* All NVIDIA FLARE components (derived from FLComponent) can handle and fire events via the runtime engine\n",
    "* Components can register to listen for specific events\n",
    "* When an event occurs, all registered listeners are notified\n",
    "\n",
    "### Benefits\n",
    "\n",
    "* **Extensibility**: New functionality can be added by creating components that listen for existing events\n",
    "* **Loose Coupling**: Components don't need direct knowledge of each other\n",
    "* **Customization**: Users can write custom FLComponents as plugins to listen for events and implement specialized logic at any layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federated-learning-framework",
   "metadata": {},
   "source": [
    "## Federated Learning Framework\n",
    "\n",
    "Building on the core architecture, NVIDIA FLARE provides implementations of various federated learning algorithms and workflows.\n",
    "\n",
    "### Available Algorithms\n",
    "\n",
    "* **FedAvg**: The classic federated averaging algorithm\n",
    "* **FedOpt**: Federated optimization with server-side optimization\n",
    "* **FedProx**: Federated learning with proximal terms for stability\n",
    "* **Scaffold**: Stochastic Controlled Averaging for variance reduction\n",
    "* **Cyclic Learning**: Sequential training across clients\n",
    "* **Swarm Learning**: Peer-to-peer federated learning\n",
    "* **Split Learning**: Splitting model layers between client and server\n",
    "\n",
    "### Resources\n",
    "\n",
    "You can find examples and tutorials for these algorithms on the [NVIDIA FLARE website](https://nvidia.github.io/NVFlare/) and in the [tutorial catalog](https://nvidia.github.io/NVFlare/catalog/).\n",
    "\n",
    "## Enterprise Security and Privacy\n",
    "\n",
    "NVIDIA FLARE includes features to support enterprise security requirements and privacy-enhancing technologies (PETs). These topics are covered in detail in [Part-3 Security and Privacy](../../../part-3_security_and_privacy/part-3_introduction.ipynb).\n",
    "\n",
    "## Simulation Capabilities\n",
    "\n",
    "NVIDIA FLARE provides tools for simulating federated learning workflows, which is essential for development and testing.\n",
    "\n",
    "### Simulation Tools\n",
    "\n",
    "* **Python API**: Programmatic control of simulations\n",
    "* **Command-Line Interface (CLI)**: Running simulations from the command line\n",
    "\n",
    "You've already seen the Job API and simulator CLI in [Chapter-1](../../../part-1_federated_learning_introduction/Chapter-1_running_federated_learning_applications/01.0_introduction/introduction.ipynb). In [Section 3.2](../03.2_deployment_simulation/simulate_real_world_deployment.ipynb), we'll explore how to simulate deployment on a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-deployment",
   "metadata": {},
   "source": [
    "## Setup and Deployment\n",
    "\n",
    "Setting up a federated computing system involves multiple steps and considerations. NVIDIA FLARE provides tools to simplify this process, which we'll discuss in [Chapter 4](../../chapter-4_setup_federated_system/04.0_introduction/introduction.ipynb).\n",
    "\n",
    "## NVIDIA FLARE APIs\n",
    "\n",
    "NVIDIA FLARE provides multiple APIs at different levels of abstraction, allowing developers to choose the right level for their needs.\n",
    "\n",
    "### Python APIs\n",
    "\n",
    "#### 1. Controller and Executor API\n",
    "* Low-level APIs that provide full control over federated computing\n",
    "* Enable custom federated workflows and algorithms\n",
    "* Offer maximum flexibility but require more detailed implementation\n",
    "\n",
    "#### 2. ModelController and Client API\n",
    "* Higher-level APIs based on the FLModel data structure\n",
    "* Simplify common machine learning and deep learning workflows\n",
    "* The FLModel structure captures model parameters, metrics, and metadata:\n",
    "\n",
    "```python\n",
    "class FLModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        params_type: Union[None, str, ParamsType] = None,\n",
    "        params: Any = None,\n",
    "        optimizer_params: Any = None,\n",
    "        metrics: Optional[Dict] = None,\n",
    "        start_round: Optional[int] = 0,\n",
    "        current_round: Optional[int] = None,\n",
    "        total_rounds: Optional[int] = None,\n",
    "        meta: Optional[Dict] = None,\n",
    "    ):\n",
    "        ...\n",
    "```\n",
    "\n",
    "* On the server side, ModelController consumes and produces FLModel objects\n",
    "* On the client side, the Client API receives and sends model updates via FLModel\n",
    "\n",
    "#### 3. Job API\n",
    "* Helps generate job configurations programmatically\n",
    "* Allows construction of needed components and generation of job configurations\n",
    "* Supports simulation through the `job.simulate_run()` method\n",
    "\n",
    "#### 4. Simulator API\n",
    "* Enables direct invocation of simulations through the `simulator_run()` method\n",
    "\n",
    "#### 5. FLARE API\n",
    "* Python equivalent of FLARE Console commands\n",
    "* Allows programmatic interaction with the FL system\n",
    "* Supports operations like connecting to servers, checking status, monitoring jobs, and submitting jobs\n",
    "\n",
    "### Command Line Interface (CLI)\n",
    "\n",
    "NVIDIA FLARE provides several command-line tools under the `nvflare` command:\n",
    "\n",
    "* `nvflare --version`: Display version information\n",
    "* `nvflare poc`: Create and manage proof-of-concept deployments\n",
    "* `nvflare preflight_check`: Verify FL system setup and diagnose issues\n",
    "* `nvflare provision`: Generate secure startup kits for participants\n",
    "* `nvflare simulator`: Run simulations\n",
    "* `nvflare dashboard`: Start the NVFLARE dashboard for distributing provisioned startup kits\n",
    "* `nvflare authz_preview`: View different user roles and permissions\n",
    "* `nvflare job`: Create job configurations, list templates, and submit jobs\n",
    "* `nvflare config`: Configure default directories for startup, POC workspace, and job templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configuration-section",
   "metadata": {},
   "source": [
    "## Configuration System\n",
    "\n",
    "NVIDIA FLARE uses a flexible configuration system that supports multiple formats and provides templates for common scenarios.\n",
    "\n",
    "### Configuration Formats\n",
    "\n",
    "NVIDIA FLARE supports several configuration formats:\n",
    "* JSON\n",
    "* PYHOCON (Python HOCON)\n",
    "* YAML\n",
    "\n",
    "For details, see the [Configuration Files documentation](https://nvflare.readthedocs.io/en/main/user_guide/configurations.html).\n",
    "\n",
    "### Job Templates\n",
    "\n",
    "Job templates provide predefined configurations that can be customized for specific needs. They simplify the process of creating job configurations by providing starting points for common scenarios. You can leverage existing [job templates](https://github.com/NVIDIA/NVFlare/tree/main/job_templates) which are a set of predefined configurations and use the [job CLI](https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/job_cli.ipynb) to customize to your needs. \n",
    "\n",
    "#### Template Structure\n",
    "\n",
    "A typical job template includes:\n",
    "\n",
    "```\n",
    "├── config_fed_client.conf  # Client configuration\n",
    "├── config_fed_server.conf  # Server configuration\n",
    "├── info.conf               # Template information\n",
    "├── info.md                 # Template documentation\n",
    "└── meta.conf               # Template metadata\n",
    "```\n",
    "\n",
    "Let's examine a sample client configuration from the `sag_pt` template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat  ../../../../../../job_templates/sag_pt/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "job-cli-section",
   "metadata": {},
   "source": [
    "### Using Job Templates\n",
    "\n",
    "You can use the NVIDIA FLARE job CLI to view and modify templates when creating job configurations. This provides a user-friendly way to customize templates for your specific needs.\n",
    "\n",
    "For more information, see the [job CLI tutorial](../../../../job_cli.ipynb).\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this section, we've explored the architecture of NVIDIA FLARE, including:\n",
    "\n",
    "* The layered design that provides modularity and extensibility\n",
    "* The FLARE Communication Interface (FCI) that enables secure, efficient communication\n",
    "* The job-based processing architecture that supports concurrent execution\n",
    "* The event-driven system that enables loose coupling and customization\n",
    "* The various APIs available at different levels of abstraction\n",
    "* The configuration system and job templates that simplify deployment\n",
    "\n",
    "This architectural understanding will help you leverage NVIDIA FLARE effectively for your federated computing needs.\n",
    "\n",
    "In the next section, we'll explore how to [simulate real-world deployment](../03.2_deployment_simulation/simulate_real_world_deployment.ipynb) of NVIDIA FLARE on a local machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
