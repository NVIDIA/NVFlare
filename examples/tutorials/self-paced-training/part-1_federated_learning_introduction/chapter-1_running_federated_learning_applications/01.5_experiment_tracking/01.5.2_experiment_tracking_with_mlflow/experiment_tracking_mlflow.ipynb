{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# Experiment Tracking with MLflow\n",
    "\n",
    "If you would like to use MLflow for experiment tracking, NVFlare has `MLflowReceiver` available for use on the FL server to log to a MLflow tracking server.\n",
    "\n",
    "In the [previous example](../01.5.1_experiment_tracking_with_tensorboard/experiment_tracking_tensorboard.ipynb), we introduced a server-side approach for aggregated experiment tracking with the default `TBAnalyticsReceiver` for TensorBoard. In this example, we will explore distributed experiment tracking with MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d819b",
   "metadata": {},
   "source": [
    "#### Install requirements\n",
    "Make sure to install the required packages for MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67458a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e2a04",
   "metadata": {},
   "source": [
    "## Configuring MLflowReceiver\n",
    "\n",
    "To use MLflow as the back end for experiment tracking, the `MLflowReceiver` can be added to a job with the Job API with the following as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9732f6-6bbb-406a-889d-bda8d7a31378",
   "metadata": {},
   "source": [
    "```python\n",
    "receiver = MLflowReceiver(\n",
    "            tracking_uri=\"file:///tmp/nvflare/jobs/workdir/server/simulate_job/mlruns\",\n",
    "            kw_args={\n",
    "                \"experiment_name\": \"nvflare-fedavg-experiment\",\n",
    "                \"run_name\": \"nvflare-fedavg-with-mlflow\",\n",
    "                \"experiment_tags\": {\"mlflow.note.content\": \"## **NVFlare FedAvg experiment with MLflow**\"},\n",
    "                \"run_tags\": {\"mlflow.note.content\": \"## Federated Experiment tracking with MLflow.\\n\"},\n",
    "            },\n",
    "        )\n",
    "job.to_server(receiver)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49755e94",
   "metadata": {},
   "source": [
    "The full code for the example job with `MLflowReceiver` can be found in [job_mlflow.py](code/fl_job_mlflow.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db032",
   "metadata": {},
   "source": [
    "## MLflowWriter and logging metrics\n",
    "\n",
    "The existing `SummaryWriter` used in the [client code](code/src/client.py) for the [previous example](../01.5.1_default_experiment_tracking/experiment_tracking.ipynb) with the default `TBAnalyticsReceiver` should also work for the `MLflowReceiver`.\n",
    "\n",
    "### MLflowWriter\n",
    "\n",
    "For convenience and for training code that is already using MLflow, `MLflowWriter` can be imported as an alternative to `SummaryWriter` for logging in the client code:\n",
    "\n",
    "```python\n",
    "from nvflare.client.tracking import MLflowWriter\n",
    "```\n",
    "\n",
    "After that, we need to add the following line after `flare.init()`:\n",
    "\n",
    "```python\n",
    "mlflow_writer = MLflowWriter()\n",
    "```\n",
    "\n",
    "We can then use mlflow_writer to log. In this case, we have a running_loss available already, so we can use `log_metric()` to log this:\n",
    "\n",
    "```python\n",
    "mlflow_writer.log_metric(key=\"local_accuracy\", value=local_accuracy, step=global_step)\n",
    "```\n",
    "\n",
    "For the step we use the same calculation for it on the previous line as in the previous example:\n",
    "\n",
    "```python\n",
    "global_step = input_model.current_round * n_loaders + i\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03003",
   "metadata": {},
   "source": [
    "You can see the full contents of the updated training code in [client_mlflow.py](code/src/client_mlflow.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat code/src/client_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec950ee",
   "metadata": {},
   "source": [
    "Let's run this example by executing the following command. The num_rounds for this job is also 20 for more data for a better looking graph. Note that even though [this job](code/src/client_mlflow.py) uses `MLflowWriter`, if we used the [client code](code/src/client.py) with `SummaryWriter`, the resulting data logged to MLflow would be the same since, behind the scene, there is a conversion that occurs to translate the event with the log with SummaryWriter to be the equivalent for MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534d96f-adb4-49d0-8b24-75fa8b47c5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd code && python fl_job_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a364ce1",
   "metadata": {},
   "source": [
    "## View MLflow results\n",
    "\n",
    "In order to see the results, you can use the following command directed to the location of the mlruns directory:\n",
    "\n",
    "```\n",
    "mlflow ui --backend-store-uri=/tmp/nvflare/jobs/workdir/server/simulate_job/mlruns --host 0.0.0.0\n",
    "```\n",
    "\n",
    "Then open this URL in browser: http://localhost:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0eb76",
   "metadata": {},
   "source": [
    "Now we know how experiment tracking can be achieved through metric logging and how different types of `AnalyticsReceiver` can be configured to work in a job. With this mechanism, we can stream various types of metric data.\n",
    "\n",
    "To continue, please see [Understanding FLARE federated learning Job structure](../../01.6_job_structure_and_configuration/understanding_fl_job.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
