{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# Experiment Tracking with MLflow\n",
    "\n",
    "If you would like to use MLflow for experiment tracking, NVFlare has `MLflowReceiver` available for use on the FL server to log to a MLflow tracking server.\n",
    "\n",
    "## Introduction to distributed experiment tracking\n",
    "\n",
    "In the [previous example](../01.5.1_default_experiment_tracking/experiment_tracking.ipynb), we introduced a server-side approach for aggregated experiment tracking with the default `TBAnalyticsReceiver` for TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d819b",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "Make sure to install the required packages for MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67458a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r code/requirements_mlflow.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e2a04",
   "metadata": {},
   "source": [
    "## Configuring MLflowReceiver\n",
    "\n",
    "To use MLflow as the back end for experiment tracking, the `MLflowReceiver` can be added to a job with the Job API with the following as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce262905",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver = MLflowReceiver(\n",
    "            tracking_uri=\"file:///tmp/nvflare/jobs/workdir/server/simulate_job/mlruns\",\n",
    "            kw_args={\n",
    "                \"experiment_name\": \"nvflare-fedavg-experiment\",\n",
    "                \"run_name\": \"nvflare-fedavg-with-mlflow\",\n",
    "                \"experiment_tags\": {\"mlflow.note.content\": \"## **NVFlare FedAvg experiment with MLflow**\"},\n",
    "                \"run_tags\": {\"mlflow.note.content\": \"## Federated Experiment tracking with MLflow.\\n\"},\n",
    "            },\n",
    "        )\n",
    "job.to_server(receiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49755e94",
   "metadata": {},
   "source": [
    "The full code for the example job with `MLflowReceiver` can be found [here](code/fl_job_mlflow.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db032",
   "metadata": {},
   "source": [
    "## SummaryWriter and logging metrics\n",
    "\n",
    "The existing `SummaryWriter` used in the [client code](code/src/client.py) for the [previous example](../01.5.1_default_experiment_tracking/experiment_tracking.ipynb) with the default `TBAnalyticsReceiver` should also work for the `MLflowReceiver`.\n",
    "\n",
    "### MLflowWriter\n",
    "\n",
    "For convenience and for training code that is already using MLflow, `MLflowWriter` can be imported as an alternative to `SummaryWriter` for logging in the client code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74bcbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.client.tracking import MLflowWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3052e9c",
   "metadata": {},
   "source": [
    "After that, we need to add the following line after `flare.init()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26146142",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_writer = MLflowWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f460079",
   "metadata": {},
   "source": [
    "We can then use mlflow_writer to log. In this case, we have a running_loss available already, so we can use `log_metric()` to log this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a846954",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_writer.log_metric(key=\"local_accuracy\", value=local_accuracy, step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6840044",
   "metadata": {},
   "source": [
    "For the step we use the same calculation for it on the previous line as in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = input_model.current_round * n_loaders + i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03003",
   "metadata": {},
   "source": [
    "You can see the full contents of the updated training code in client_mlflow.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client_mlflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec950ee",
   "metadata": {},
   "source": [
    "The num_rounds for this job also 20 for more data for a better looking graph. Note that even though [this job](code/src/client_mlflow.py) uses `MLflowWriter`, if we used the [client code](code/src/client.py) with `SummaryWriter`, the resulting data logged to MLflow would be the same since behind the scenes, there is conversion that occurs to translate the event with the log with SummaryWriter to be the equivalent for MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a364ce1",
   "metadata": {},
   "source": [
    "## View MLflow results\n",
    "\n",
    "In order to see the results, you can use the following command directed to the location of the mlruns directory:\n",
    "\n",
    "```\n",
    "mlflow ui --backend-store-uri=/tmp/nvflare/jobs/workdir/server/simulate_job/mlruns\n",
    "```\n",
    "\n",
    "Then look at the URL in browser: http://localhost:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0eb76",
   "metadata": {},
   "source": [
    "Now, we know how experiment tracking can be achieved through metric logging and can different types of `AnalyticsReceiver` can be configured to work in a job. With this mechanism, we can stream various types of metric data.\n",
    "\n",
    "To continue, please see [Understanding FLARE federated learning Job structure](../../01.6_job_structure_and_configuration/01.1.6.1_understanding_fl_job.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
