{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# Experiment tracking with TensorBoard\n",
    "\n",
    "NVFlare uses `TBAnalyticsReceiver` for experiment tracking on the FL server by default, enabling experiment tracking.\n",
    "\n",
    "## Default in FedAvgJob\n",
    "\n",
    "The FedJob API makes it easy to create job configurations, and by default the `TBAnalyticsReceiver` for TensorBoard streaming is included. You can specify your own analytics_receiver of type `AnalyticsReceiver` as a parameter if you want, but if left unspecified, `TBAnalyticsReceiver` is configured to be set up in `BaseFedJob` (nvflare/app_opt/pt/job_config/base_fed_job.py).\n",
    "\n",
    "\n",
    "The `TBAnalyticsReceiver` for TensorBoard streaming receives and records the logs during the experiment by saving them to Tensoboard event files on the FL server. See [this link](https://nvflare.readthedocs.io/en/main/programming_guide/experiment_tracking/experiment_tracking_log_writer.html#tools-sender-logwriter-and-receivers) for more details on the other available AnalyticsReceivers in NVFlare: MLflowReceiver and WandBReceiver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db032",
   "metadata": {},
   "source": [
    "## Add SummaryWriter and add_scalar for logging metrics\n",
    "\n",
    "To keep things simple, we start from the state of the code we had in section 1.3 earlier this chapter and make the few modifications needed to implement adding metrics for experiment tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95f820",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "Make sure to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fe4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b1ace",
   "metadata": {},
   "source": [
    "### Add import from Client API \n",
    "\n",
    "In order to add SummaryWriter to the client training code, we need to import it with the following line (at the top of [client.py](code/src/client.py)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74bcbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.client.tracking import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3052e9c",
   "metadata": {},
   "source": [
    "After that, we need to add the following line after `flare.init()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26146142",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f460079",
   "metadata": {},
   "source": [
    "We can then use summary_writer to log. In this case, we have a local_accuracy available already, so we can use `add_scalar()` to log this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a846954",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer.add_scalar(tag=\"local_accuracy\", scalar=local_accuracy, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6840044",
   "metadata": {},
   "source": [
    "Note that the global_step is included here, which we calculate on the previous line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = input_model.current_round * n_loaders + i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03003",
   "metadata": {},
   "source": [
    "You can see the full contents of the updated training code in client.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4c4a0",
   "metadata": {},
   "source": [
    "The num_rounds has been increased to 20 in order to have more data for a better looking graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a364ce1",
   "metadata": {},
   "source": [
    "## View tensorboard results\n",
    "\n",
    "\n",
    "In order to see the results, you can use the following command directed to the location of the TensorBoard event files (by default, the location for the server should be as follows using the default simulator path provided):\n",
    "\n",
    "\n",
    "```commandline\n",
    "tensorboard --logdir=/tmp/nvflare/jobs/workdir/server/simulate_job/tb_events\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0eb76",
   "metadata": {},
   "source": [
    "Now we know how experiment tracking can be achieved through metric logging and can be configured to work in a job with an `AnalyticsReceiver`. With this mechanism, we can stream various types of metric data.\n",
    "\n",
    "\n",
    "For how to use `MLflowReceiver` to set up experiment tracking for MLflow, see [Experiment Tracking with MLflow](../01.5.2_experiment_tracking_with_mlflow/experiment_tracking_mlflow.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
