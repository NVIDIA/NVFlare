{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# Experiment Tracking\n",
    "\n",
    "When you’re conducting machine learning training, especially in distributed settings like federated learning, it’s crucial to monitor training and evaluation metrics closely. \n",
    "\n",
    "NVIDIA FLARE provides built-in integration with experiment tracking systems—MLflow, Weights & Biases, and TensorBoard—to facilitate comprehensive monitoring of these metrics.\n",
    "\n",
    "## Introduction to distributed experiment tracking\n",
    "\n",
    "In a federated computing setting, data is distributed across multiple devices or systems, and training is run on each device independently while preserving each client’s data privacy.\n",
    "\n",
    "Assuming a federated system consisting of one server and many clients and the server coordinating the ML training of clients, we can interact with ML experiment tracking tools in two different ways:\n",
    "\n",
    "![experiment_tracking](img/metrics-streaming-fl-server-clients.png)\n",
    "\n",
    "- Decentralized tracking (client-side experiment tracking): Each client will directly send the log metrics/parameters to the ML experiment tracking server (like MLflow or Weights and Biases) or local file system (like tensorboard)\n",
    "- Centralized tracking (aggregated experiment trackin): Clients will send the log metrics/parameters to the FL server, and the FL server will send the metrics to ML experiment tracking server or local file system\n",
    "\n",
    "The NVIDIA FLARE job configuration enables you to choose the tracking scenario or system that best fits your needs.  When users need to migrate from one experiment tracking system to another, using NVIDIA FLARE, you can modify the job configuration without re-writing the experiment tracking code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47399ea6",
   "metadata": {},
   "source": [
    "The `nvflare.client.tracking` API enables you to flexibly redirect your logging metrics to any destination. The use of MLflow, Weights & Biases, or TensorBoard syntax does not matter here as you can stream the collected metrics to any supported experiment tracking system. Choosing to use MLflowWriter, WandBWriter, or TBWriter is based on your existing code and requirements.\n",
    "\n",
    "- MLflowWriter uses the MLflow API operation log_metric.\n",
    "- TBWriter uses the TensorBoard SummaryWriter operation add_scalar.\n",
    "- WandBWriter uses the API operation log.\n",
    "\n",
    "Depending on your existing code or familiarity with these systems, you can choose any writer. After you’ve modified the training code, you can use the NVIDIA FLARE job configuration to configure the system to stream the logs appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1bc5f",
   "metadata": {},
   "source": [
    "To see how to use experiment tracking with TensorBoard, see [Experiment tracking with TensorBoard](./01.5.1_experiment_tracking_with_tensorboard/experiment_tracking_tensorboard.ipynb).\n",
    "\n",
    "For how to use `MLflowReceiver` to set up experiment tracking for MLflow, see [Experiment Tracking with MLflow](./01.5.2_experiment_tracking_with_mlflow/experiment_tracking_mlflow.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
