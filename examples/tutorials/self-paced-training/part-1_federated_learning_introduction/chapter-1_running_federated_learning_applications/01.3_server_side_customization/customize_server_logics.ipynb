{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64188d2",
   "metadata": {},
   "source": [
    "\n",
    "# Customizing Federated Learning Server logics\n",
    "\n",
    "In previous sections, we were able to run federated PyTorch image classification code with NVIDIA FLARE's built-in FedAvg algorithm.\n",
    "What if we want to build our own algorithms or modify the existing algorithm?\n",
    "\n",
    "In the following, using FedAvg as a starting point, we would like to make a few changes to FedAvg to fit our needs:\n",
    "\n",
    "* Add early stopping mechanism so that the training could stop instead of waiting for the total number of rounds if the criteria is satisfied\n",
    "* Instead of relying on the internal best model selection approach, we want to provide our own best model selection\n",
    "* Instead of using built-in persist component PTFileModelPersistor, we would like to have our own save and loading functions\n",
    "\n",
    "In this section, we will go over these changes step-by-step. \n",
    "\n",
    "> Reference:\n",
    "> _[FedAvg with early stopping](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/hello-fedavg/hello-fedavg.ipynb) example_\n",
    "\n",
    "\n",
    "## Customized FedAvg v1\n",
    "\n",
    "There are several factors to consider:\n",
    "\n",
    "* **How to write a Federated Avg Algorithms** \n",
    "\n",
    "* **How to express and apply the early stop condition** \n",
    "\n",
    "\n",
    "### Write a FedAvg Algorithm\n",
    "\n",
    "FedAvg can be written as very simple for-loop. There are several other factors to consider \n",
    "\n",
    "* How to send the model to clients?\n",
    "* How to receive the responses\n",
    "* For the model and responses, what's the format?\n",
    "* The model and responses and corresponding objects must be serialized, how to serialize them?\n",
    "\n",
    "\n",
    "Let's dive into these questions.\n",
    "\n",
    "\n",
    "#### Transfer Structure: FLModel\n",
    "\n",
    "FLARE defined a high-level data structure \"FLModel\" that holds the model parameters, metrics and metadata\n",
    "\n",
    "```python\n",
    "\n",
    "class ParamsType(str, Enum):\n",
    "    FULL = \"FULL\"\n",
    "    DIFF = \"DIFF\"\n",
    "\n",
    "\n",
    "class FLModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        params_type: Union[None, str, ParamsType] = None,\n",
    "        params: Any = None,\n",
    "        optimizer_params: Any = None,\n",
    "        metrics: Optional[Dict] = None,\n",
    "        start_round: Optional[int] = 0,\n",
    "        current_round: Optional[int] = None,\n",
    "        total_rounds: Optional[int] = None,\n",
    "        meta: Optional[Dict] = None,\n",
    "    ):\n",
    "\n",
    "```\n",
    "the data can be packaged into FLModel transfer between clients and server as well as among clients. \n",
    "\n",
    "\n",
    "#### Serialization \n",
    "\n",
    "Many of the deep learning machine frameworks using python pickle as default serialization mechanism. There are enough security concerns that FLARE is not using Pickle. NVIDIA FLARE Object Serializer (FOBS) used a [messagePack](https://msgpack.org/index.html)-based serialization approach. \n",
    "User needs to register a component ( \"Decomposer\") to serialize/de-serialize certain project to fobs. \n",
    "\n",
    "To PyTorch Tensor, we need to register [TensorDecompressor](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/pt/decomposers.py) component at FOBS. \n",
    "\n",
    "```python\n",
    "\n",
    "            # Use FOBS for serializing/deserializing PyTorch tensors\n",
    "            fobs.register(TensorDecomposer)\n",
    "```\n",
    "\n",
    "#### Send and Recieve Object\n",
    "\n",
    "For high-level API, we can use the followings\n",
    "\n",
    "```python\n",
    "\n",
    "   results = self.send_model_and_wait(targets=clients, data=model)\n",
    "```\n",
    "the function send the FLModel to targeted clients and recieve result. This is synchronized method like scatter and gather. We broadcast the model to all targeted clients and receive results when required clients send back the results. \n",
    "\n",
    "The BasedFedAvg is derived from ModelController which has the communication component, which allows the component to send the model and wait for result. \n",
    "\n",
    "\n",
    "Now we are covered these few factors, lets write a class and see how it will look\n",
    "\n",
    "We will start with BaseFedAvg class. ```class BaseFedAvg``` provided a core based class for the customize FedAvg, it define a run() methods that capture all the running logs\n",
    "as well as some utiliies. We can look at the initial version of the code\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat code/src/fedavg_v0.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85e1f1",
   "metadata": {},
   "source": [
    "Now, we have our own FedAvg version, we now look into how to stop the training\n",
    "\n",
    "### Express and apply the early stop condition\n",
    "\n",
    "#### Stop Condition\n",
    "\n",
    "```stop_cond``` is a string to represent the stop condition, its string literal in the format of \"<key> <op> <value>\" (e.g. \"accuracy >= 80\")\n",
    "\n",
    "we need to parse this condition so we can compare. To parse this, we leverage FLARE's math_utils\n",
    "\n",
    "```python\n",
    "\n",
    "math_utils.parse_compare_criteria(compare_expr: Optional[str] = None) -> Tuple[str, float, Callable]\n",
    "\n",
    "```\n",
    "\n",
    "the return will be\n",
    "* key,\n",
    "* target_value,\n",
    "* callable op_fn\n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7871717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.app_common.utils.math_utils import parse_compare_criteria\n",
    "key, target_value, fn= parse_compare_criteria(\"accuracy > 80\")\n",
    "print (key, target_value, fn)\n",
    "accuracy = 90\n",
    "fn (accuracy, target_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d4de5",
   "metadata": {},
   "source": [
    "#### Integrate the early stop condition\n",
    "\n",
    "This should simple, if the condition is satisfied and simply break out the for-loop\n",
    "\n",
    "```python\n",
    "            if self.should_stop(model.metrics, self.stop_condition):\n",
    "                break\n",
    "```\n",
    "\n",
    "and the ```should_stop``` function is defined as followings\n",
    "\n",
    "```python\n",
    "\n",
    "def should_stop(self, metrics: Optional[Dict] = None, stop_condition: Optional[str] = None):\n",
    "        key, target, op_fn = stop_condition\n",
    "        value = metrics.get(key, None)\n",
    "        return op_fn(value, target)\n",
    "```\n",
    "\n",
    "the code can be found in [fedavg_v1.py](code/src/fedavg_v1.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beac00b",
   "metadata": {},
   "source": [
    "## Customized FedAvg v2\n",
    "\n",
    "We have successfully modify the FedAvg logics and allow user to specify early stop conditions. \n",
    "Now, we want to make additional changes\n",
    "\n",
    "* We like to implements our own best model selection\n",
    "* we like to have our own model save and loading instead of using the FLARE's persistor. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f0d14",
   "metadata": {},
   "source": [
    "### Select best model \n",
    "\n",
    "we simply write the following two functions and put into previous code\n",
    "\n",
    "```python\n",
    "\n",
    "    def select_best_model(self, curr_model: FLModel):\n",
    "        if self.best_model is None:\n",
    "            self.best_model = curr_model\n",
    "            return\n",
    "\n",
    "        if self.stop_condition:\n",
    "            metric, _, op_fn = self.stop_condition\n",
    "            if self.is_curr_model_better(self.best_model, curr_model, metric, op_fn):\n",
    "                self.info(\"Current model is new best model.\")\n",
    "                self.best_model = curr_model\n",
    "        else:\n",
    "            self.best_model = curr_model\n",
    "\n",
    "    def is_curr_model_better(\n",
    "        self, best_model: FLModel, curr_model: FLModel, target_metric: str, op_fn: Callable\n",
    "    ) -> bool:\n",
    "        curr_metrics = curr_model.metrics\n",
    "        if curr_metrics is None:\n",
    "            return False\n",
    "        if target_metric not in curr_metrics:\n",
    "            return False\n",
    "\n",
    "        best_metrics = best_model.metrics\n",
    "        return op_fn(curr_metrics.get(target_metric), best_metrics.get(target_metric))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b319c6",
   "metadata": {},
   "source": [
    "### Customized save and load model functions\n",
    "     \n",
    "The ```BaseFedAvg``` class defined ```save_model()``` and ```load_model()``` functions for user to override. \n",
    "We use torch save and load functions, and save the FLModel metadata separately with the fobs.dumpf and fobs.loadf serialization utilities.\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model, filepath=\"\"):\n",
    "        params = model.params\n",
    "        # PyTorch save\n",
    "        torch.save(params, filepath)\n",
    "\n",
    "        # save FLModel metadata\n",
    "        model.params = {}\n",
    "        fobs.dumpf(model, filepath + \".metadata\")\n",
    "        model.params = params\n",
    "\n",
    "    def load_model(self, filepath=\"\"):\n",
    "        # PyTorch load\n",
    "        params = torch.load(filepath)\n",
    "\n",
    "        # load FLModel metadata\n",
    "        model = fobs.loadf(filepath + \".metadata\")\n",
    "        model.params = params\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40eb84",
   "metadata": {},
   "source": [
    "## Add Evaluation to the training code\n",
    "\n",
    "We need to add the evaluation code to the training code to compute accuracy. We then use accuracy to select best model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a83a06",
   "metadata": {},
   "source": [
    "## Running Customized FedAvg\n",
    "\n",
    "Now, put everything together in [fedavg_v2](code/src/fedavg_v2.py), we can take a look at the server code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/fedavg_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3b848",
   "metadata": {},
   "source": [
    "Lets create Job with our newly modified FedAvgV2. \n",
    "\n",
    "### Create Fed Job\n",
    "\n",
    "```python\n",
    "\n",
    "    n_clients = 5\n",
    "    num_rounds = 2\n",
    "\n",
    "    train_script = \"src/client.py\"\n",
    "\n",
    "    job = FedJob(name=\"fedavg_v2\", n_clients=n_clients)\n",
    "\n",
    "    controller = FedAvgV2(\n",
    "            num_clients=n_clients,\n",
    "            num_rounds=num_rounds,\n",
    "            stop_cond = None,\n",
    "            save_filename = \"global_model.pt\",\n",
    "            initial_model=SimpleNetwork())\n",
    "        \n",
    "    job.to_server(controller)\n",
    "\n",
    "    # Add clients\n",
    "    for i in range(n_clients):\n",
    "        executor = ScriptRunner(\n",
    "            script=train_script, script_args=\"\"\n",
    "        )\n",
    "        job.to(executor, f\"site-{i + 1}\")\n",
    "\n",
    "    job.simulator_run(\"/tmp/nvflare/jobs/workdir\")\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Run job with simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ae30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nvflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 code/data/download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465add19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 fl_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63108356",
   "metadata": {},
   "source": [
    "Next step, we are going to see how to customize the cilent side logics: [customize client side logics](../01.4_client_side_customization/customize_client_training.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99daa93c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
