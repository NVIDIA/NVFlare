{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64188d2",
   "metadata": {},
   "source": [
    "\n",
    "# Customizing Federated Learning Server Logics\n",
    "\n",
    "In the [previous section](../01.2_convert_deep_learning_to_federated_learning/convert_dl_to_fl.ipynb), we were able to run federated PyTorch image classification code with NVIDIA FLARE's built-in FedAvg algorithm.\n",
    "\n",
    "What if we want to build our own algorithm or modify the existing one?\n",
    "\n",
    "In the following, using FedAvg as a starting point, we would like to make a few changes to FedAvg to fit our needs:\n",
    "\n",
    "* Add early stopping mechanism so that the training could stop instead of waiting for the total number of rounds if the criteria is satisfied\n",
    "* Instead of relying on the internal best model selection approach, we want to provide our own best model selection\n",
    "* Instead of using built-in persist component PTFileModelPersistor, we would like to have our own save and loading functions\n",
    "\n",
    "In this section, we will go over these changes step-by-step. \n",
    "\n",
    "> Reference:\n",
    "> _[FedAvg with early stopping](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/hello-fedavg/hello-fedavg.ipynb) example_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79ea52-109a-44a2-90c6-6bbb2449cf14",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "We will start with the [`BaseFedAvg`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/base_fedavg.py#L29) class. This class provides a core basic class to customize FedAvg. It is derived from the [`ModelController`](https://nvflare.readthedocs.io/en/2.6/programming_guide/controllers/model_controller.html) class which exposes a `run()` method that orchestrates the overall federated workflow. The `ModelController` class also contains the communication component, that is capable to send the model to clients, and wait for result. \n",
    "\n",
    "In the following sections, we will show various incremental implementations of `FedAvg` that will essentially override the `run()` method in `BaseFedAvg` / `ModelController` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2644eae-dfc1-49e1-a873-b372575ec90f",
   "metadata": {},
   "source": [
    "## Version 0: writting a basic FedAvg algorithm\n",
    "\n",
    "In this version, we will look at how the basic `FedAvg` algorithm is implemented.\n",
    "\n",
    "Using the `BaseFedAvg` class, `FedAvg` can be written as very simple for-loop inside the [`run()`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/fedavg.py#L34) function. \n",
    "\n",
    "There are several other factors to consider \n",
    "* How to send the model to clients?\n",
    "* How to receive the responses?\n",
    "* For the model and responses, what's the format?\n",
    "* The model and responses and corresponding objects must be serialized, how to serialize them?\n",
    "\n",
    "Let's dive into these questions.\n",
    "\n",
    "### Transfer format: `FLModel`\n",
    "\n",
    "FLARE defined a high-level data structure [`FLModel`](https://nvflare.readthedocs.io/en/2.6/programming_guide/fl_model.html) that holds the model parameters, metrics and metadata\n",
    "\n",
    "```python\n",
    "\n",
    "class ParamsType(str, Enum):\n",
    "    FULL = \"FULL\"\n",
    "    DIFF = \"DIFF\"\n",
    "\n",
    "\n",
    "class FLModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        params_type: Union[None, str, ParamsType] = None,\n",
    "        params: Any = None,\n",
    "        optimizer_params: Any = None,\n",
    "        metrics: Optional[Dict] = None,\n",
    "        start_round: Optional[int] = 0,\n",
    "        current_round: Optional[int] = None,\n",
    "        total_rounds: Optional[int] = None,\n",
    "        meta: Optional[Dict] = None,\n",
    "    ):\n",
    "\n",
    "```\n",
    "Using `FLModel`, model & responses data can be packaged for transfer between clients and server, as well as among clients. \n",
    "\n",
    "### Serialization \n",
    "\n",
    "Many deep learning / machine learning frameworks use python `pickle` as default serialization mechanism. However, there are security concerns, because of which FLARE does not use `pickle` for object serialization. \n",
    "\n",
    "NVIDIA FLARE introduces FLARE Object Serializer (FOBS), which uses a [messagePack](https://msgpack.org/index.html)-based serialization approach. User needs to register a component (\"Decomposer\") to serialize/de-serialize an object to FOBS. \n",
    "\n",
    "For example, for a PyTorch tensor, we need to register the [TensorDecomposer](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/pt/decomposers.py) component to FOBS. \n",
    "\n",
    "```python\n",
    "# Use FOBS for serializing/deserializing PyTorch tensors\n",
    "fobs.register(TensorDecomposer)\n",
    "```\n",
    "\n",
    "### Send and recieve object\n",
    "\n",
    "FLARE's `ModelController` class provides a high-level API allowing you to easily send data to a specific target.\n",
    "\n",
    "```python\n",
    "\n",
    "   results = self.send_model_and_wait(targets=clients, data=model)\n",
    "```\n",
    "\n",
    "The `send_model_and_wait` function send the FLModel to targeted clients and recieve result. This is a synchronized function, executing a \"[Scatter-and-Gather](https://nvflare.readthedocs.io/en/2.6/programming_guide/controllers/scatter_and_gather_workflow.html)\" workflow. We broadcast the model to all targeted clients and receive results when required clients send back the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5984df-e4df-458b-89f0-43598da093bf",
   "metadata": {},
   "source": [
    "Let's look at an initial version of the code in [code/src/fedavg_v0.py](code/src/fedavg_v0.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat code/src/fedavg_v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85e1f1",
   "metadata": {},
   "source": [
    "## Version 1: express and apply the early stop condition\n",
    "\n",
    "Now, we have our initial implementation of FedAvg, let's look into how to add the early stop condition.\n",
    "\n",
    "### Create a stop condition\n",
    "\n",
    "FLARE's `math_utils` provides the `parse_compare_criteria` function that we can leverage to implement custom stop conditions:\n",
    "```python\n",
    "\n",
    "math_utils.parse_compare_criteria(compare_expr: Optional[str] = None) -> Tuple[str, float, Callable]\n",
    "\n",
    "```\n",
    "\n",
    "Here, ```compare_expr``` is a literal string representing the stop condition, in the format of `\"<key> <op> <value>\"`. For example: `\"accuracy >= 80\"`.\n",
    "\n",
    "The returned tuple will contain:\n",
    "* A key, for instance `accuracy`\n",
    "* The target_value, for instance `80`\n",
    "* The callable function `op_fn`, for instance `gt`\n",
    "\n",
    "Execute the following example to generate a stop condition that is based on if the accuracy value is greater than 80 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7871717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.app_common.utils.math_utils import parse_compare_criteria\n",
    "key, target_value, fn= parse_compare_criteria(\"accuracy > 80\")\n",
    "print (key, target_value, fn)\n",
    "accuracy = 90\n",
    "fn (accuracy, target_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d4de5",
   "metadata": {},
   "source": [
    "### Integrate the early stop condition\n",
    "\n",
    "Let's implement a simple `should_stop` function that returns a boolean value indicating if the stop condition is met:\n",
    "\n",
    "```python\n",
    "\n",
    "def should_stop(self, metrics: Optional[Dict] = None, stop_condition: Optional[str] = None):\n",
    "        key, target, op_fn = stop_condition\n",
    "        value = metrics.get(key, None)\n",
    "        return op_fn(value, target)\n",
    "```\n",
    "\n",
    "Then, we can simply break out the execution loop if the condition is met:\n",
    "\n",
    "```python\n",
    "if self.should_stop(model.metrics, self.stop_condition):\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce95622-dc71-4e8d-92c1-f6b4860ba9ee",
   "metadata": {},
   "source": [
    "The complete code with the stop condition integrated can be found in [fedavg_v1.py](code/src/fedavg_v1.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc4bf0-4a09-4d79-be59-24980767aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat code/src/fedavg_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beac00b",
   "metadata": {},
   "source": [
    "## Version 2: further customization\n",
    "\n",
    "We have successfully modified the FedAvg logic and allowed user to specify early stop condition. \n",
    "\n",
    "Now, let's make some additional changes:\n",
    "* Implements our own best model selection\n",
    "* Implement our own model saving and loading functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f0d14",
   "metadata": {},
   "source": [
    "### Select the best model \n",
    "\n",
    "We simply write the following two functions and put into previous code\n",
    "\n",
    "```python\n",
    "\n",
    "    def select_best_model(self, curr_model: FLModel):\n",
    "        if self.best_model is None:\n",
    "            self.best_model = curr_model\n",
    "            return\n",
    "\n",
    "        if self.stop_condition:\n",
    "            metric, _, op_fn = self.stop_condition\n",
    "            if self.is_curr_model_better(self.best_model, curr_model, metric, op_fn):\n",
    "                self.info(\"Current model is new best model.\")\n",
    "                self.best_model = curr_model\n",
    "        else:\n",
    "            self.best_model = curr_model\n",
    "\n",
    "    def is_curr_model_better(\n",
    "        self, best_model: FLModel, curr_model: FLModel, target_metric: str, op_fn: Callable\n",
    "    ) -> bool:\n",
    "        curr_metrics = curr_model.metrics\n",
    "        if curr_metrics is None:\n",
    "            return False\n",
    "        if target_metric not in curr_metrics:\n",
    "            return False\n",
    "\n",
    "        best_metrics = best_model.metrics\n",
    "        return op_fn(curr_metrics.get(target_metric), best_metrics.get(target_metric))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b319c6",
   "metadata": {},
   "source": [
    "### Customize model saving and loading functions\n",
    "     \n",
    "The ```BaseFedAvg``` class defined ```save_model()``` and ```load_model()``` functions for user to override. \n",
    "We use torch save and load functions, and save the FLModel metadata separately with the fobs.dumpf and fobs.loadf serialization utilities.\n",
    "\n",
    "```python\n",
    "    def save_model(self, model, filepath=\"\"):\n",
    "        params = model.params\n",
    "        # PyTorch save\n",
    "        torch.save(params, filepath)\n",
    "\n",
    "        # save FLModel metadata\n",
    "        model.params = {}\n",
    "        fobs.dumpf(model, filepath + \".metadata\")\n",
    "        model.params = params\n",
    "\n",
    "    def load_model(self, filepath=\"\"):\n",
    "        # PyTorch load\n",
    "        params = torch.load(filepath)\n",
    "\n",
    "        # load FLModel metadata\n",
    "        model = fobs.loadf(filepath + \".metadata\")\n",
    "        model.params = params\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836802b-1793-44ce-bf5a-c4b0540cd142",
   "metadata": {},
   "source": [
    "That's it, put everything together in [fedavg_v2](code/src/fedavg_v2.py), let's take a look at the server code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e833c-3b94-491e-b190-84d7221490b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat code/src/fedavg_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a83a06",
   "metadata": {},
   "source": [
    "## Running Customized FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3b848",
   "metadata": {},
   "source": [
    "Let's run our customized `FedAvgV2` with the simulator. Notice that we initialize the `FedAvgV2` class with a stop condition:\n",
    "\n",
    "```python\n",
    "stop_cond=\"accuracy > 25\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ae30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nvflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 code/data/download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620fe19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd code && python3 fl_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63108356",
   "metadata": {},
   "source": [
    "Next, we are going to see how to [customize the cilent-side training](../01.4_client_side_customization/customize_client_training.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
