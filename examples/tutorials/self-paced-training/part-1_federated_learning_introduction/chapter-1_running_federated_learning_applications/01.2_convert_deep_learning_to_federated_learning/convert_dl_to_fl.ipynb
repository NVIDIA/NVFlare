{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# PyTorch Deep Learning to Federated Learning Conversion\n",
    "\n",
    "One common question frequently heard from data scientists is how do I wrote a federated learning ? If I already have training code already for deep learning? how do I write an federated learning training code for the same problem?\n",
    "\n",
    "In this section, we will look at the classification training code we ran earlier and see how to convert the existing the pytorch training script to federated Learning client training code\n",
    "\n",
    "\n",
    "## Orginal Deep learning Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78422d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 src/client_origin.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db032",
   "metadata": {},
   "source": [
    "## Convert the Deep learning Training Script\n",
    "\n",
    "Now let's convert it to federated learning training code with NVIDIA FLARE's Client API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0ce53",
   "metadata": {},
   "source": [
    "**Step-1** import\n",
    "\n",
    "```\n",
    "import nvflare.client as flare\n",
    "\n",
    "```\n",
    "\n",
    "**Step-2** init\n",
    "\n",
    "we call \n",
    "\n",
    "```\n",
    "flare.init()\n",
    "```\n",
    "\n",
    "Once the flare is initialized, we will recieve some system metadata for example\n",
    "```\n",
    "  sys_info = flare.system_info()\n",
    "  client_name = sys_info[\"site_name\"]\n",
    "\n",
    "```\n",
    "We can get current client's \"identity\". \n",
    "\n",
    "Next we need to extends the trainig beyond local iterations.  Image the Federated Learning is like the following for-loop: \n",
    "\n",
    "```\n",
    "rounds = 5\n",
    "for current_round in ranage (rounds):\n",
    "     \n",
    "    <at each site local_training()>\n",
    "\n",
    "```\n",
    "\n",
    "Therefore we need to additional loop for the Federated Learning training. This can be expressed \n",
    "\n",
    "**Step 3** global round loop \n",
    "\n",
    "    while flare.is_running():\n",
    "        <local training>\n",
    "\n",
    "\n",
    "For each round: we need to receive and evaluate the global model. \n",
    "\n",
    "\n",
    "**Step-4** Recive global model \n",
    "\n",
    "```\n",
    "        input_model = flare.receive()\n",
    "        round=input_model.current_round\n",
    "\n",
    "        # update model based on global model\n",
    "        model.load_state_dict(input_model.params)\n",
    "```\n",
    "\n",
    "**Step-5** Eveluate Global Model\n",
    "\n",
    "    Since the local model is being updated with global model, the training procedue caclate the loss which evaluate the model \n",
    "\n",
    "**Step-6** Send the local trained model back to aggregator\n",
    "\n",
    "    we take the newly trained local model parameters as well as metadata, sned it back to aggregator. \n",
    "\n",
    "```\n",
    "\n",
    "        output_model = flare.FLModel( params=model.cpu().state_dict(), meta={\"NUM_STEPS_CURRENT_ROUND\": steps},)\n",
    "\n",
    "        flare.send(output_model)\n",
    "```\n",
    "\n",
    "\n",
    "With above steps, just a few lines of code changes, no code structural changes, we converted the pytorch deep learning code to federated learning with NVIDIA FLARE\n",
    "\n",
    "The complete code can be found at client.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1824bf",
   "metadata": {},
   "source": [
    "Now, we converted the client pytorch training script to federated learning code. Lets look further to handle multi-task client code\n",
    "\n",
    "\n",
    "## Multi-Task Client Scripts\n",
    "\n",
    "So far, the client only handles traing, regardless what tasks the server issues to the clients. What if there are many tasks ? Client should take different actions based on the different tasks. Also, in previous version, we did not evaluate the global model. We are also to handle all these in this section. \n",
    "\n",
    "\n",
    "In Flare's Client API, by detault, we will issue three different tasks: \"train\", \"evaluate\" and \"submit_model\"\n",
    "\n",
    "These three tasks can be checked by \n",
    "\n",
    "```\n",
    "\n",
    "flare.is_train()\n",
    "\n",
    "flare.is_evaluate()\n",
    "\n",
    "flare.is_submit_model()\n",
    "\n",
    "```\n",
    "\n",
    "So we need to motify our existing training code to have both training and evaluation logics\n",
    "\n",
    "### Training logics changes\n",
    "\n",
    "Besides the training logics we have seen before. We also need to evaluate and obtain the accuracy of the trainiing. \n",
    "here we perform two evaluates \n",
    "\n",
    "evaluate the local model: \n",
    "\n",
    "```\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "evalute the global model received \n",
    "\n",
    "```\n",
    "     # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "```\n",
    "\n",
    "Then add the global model accuracy into the metrics parameter of the FLModel before send it back to server. \n",
    "\n",
    "```\n",
    " output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "```\n",
    "\n",
    "\n",
    "The newly added training logics is like this. \n",
    "\n",
    ">Note: the evaluate() function will discussed next\n",
    "\n",
    "\n",
    "```\n",
    " \n",
    "\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "            print(f\"({client_id}) Evaluating local trained model. Accuracy on the 10000 test images: {local_accuracy}\")\n",
    "            if local_accuracy > best_accuracy:\n",
    "                best_accuracy = local_accuracy\n",
    "                torch.save(net.state_dict(), model_path)\n",
    "\n",
    "            # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "            print(\n",
    "                f\"({client_id}) Evaluating received model for model selection. Accuracy on the 10000 test images: {accuracy}\"\n",
    "            )\n",
    "\n",
    "            # (5.4) construct trained FL model\n",
    "            output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "\n",
    "            # (5.5) send model back to NVFlare\n",
    "            flare.send(output_model)\n",
    "\n",
    "```\n",
    "\n",
    "### Evaluate functions\n",
    "\n",
    "The evaluate() functions requires test data, it is a nested inner evaluation that can directly use the testloader. \n",
    "The return value is accuracy percentage. \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "    # wraps evaluation logic into a method to re-use for\n",
    "    #       evaluation on both trained and received model\n",
    "    def evaluate(input_weights):\n",
    "        net = Net()\n",
    "        net.load_state_dict(input_weights)\n",
    "        # (optional) use GPU to speed things up\n",
    "        net.to(DEVICE)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "\n",
    "                # (optional) use GPU to speed things up\n",
    "                images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return 100 * correct // total\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The overall logics becomes\n",
    "\n",
    "```\n",
    "if flare.is_training(): \n",
    "    traing and evaluate metrics\n",
    "    send model and merics back\n",
    "\n",
    "elif flare.is_evaluate():\n",
    "    # evaluate only, this can be used for cross-site evaluation\n",
    "    evaluate()\n",
    "    send the model and metrics back \n",
    "\n",
    "elif flare.is_submit_model()\n",
    "    \n",
    "    # expecting client submit best model \n",
    "    load and set best model \n",
    "\n",
    "```\n",
    "\n",
    "Please take a look at the [client.py](./code/src/client.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b024c86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0eb76",
   "metadata": {},
   "source": [
    "Now, we know how to convert an existing Deep Learning code to Federated Learning training script. We can now explore how to customize the training logics. \n",
    "\n",
    "Please checkout [customize server logics](../01.1.3_customize_server_logics/customize_server_logics.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3876f78",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
