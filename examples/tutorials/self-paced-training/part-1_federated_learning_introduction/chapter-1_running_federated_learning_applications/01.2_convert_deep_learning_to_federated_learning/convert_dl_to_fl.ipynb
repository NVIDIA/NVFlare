{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b2253-cba8-4579-907b-09311e0da587",
   "metadata": {},
   "source": [
    "# PyTorch Deep Learning to Federated Learning Conversion\n",
    "\n",
    "One common question frequently heard from data scientists is: \"how do I write federated learning code?\" Or, \"if I already have training code for deep learning, how do I write federated learning training code for the same problem?\"\n",
    "\n",
    "In this section, we will look at the classification training code we ran earlier and see how to convert the existing PyTorch training script to federated learning client training code.\n",
    "\n",
    "## Orginal Deep learning Training Script\n",
    "\n",
    "We will start with the [code/src/client_origin.py](code/src/client_origin.py) script, which is a typical Pytorch training code, and convert it to federated learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924c5b7-0941-4450-b0c7-868c33f75c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cat code/src/client_origin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 code/src/client_origin.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db032",
   "metadata": {},
   "source": [
    "## Convert the Deep learning Training Script to Federated\n",
    "\n",
    "NVIDIA FLARE introduces the [Client API](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type/client_api.html), allowing developers to convert any centralized code to federated with a few steps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0ce53",
   "metadata": {},
   "source": [
    "**Step-1** import\n",
    "\n",
    "```\n",
    "import nvflare.client as flare\n",
    "\n",
    "```\n",
    "\n",
    "**Step-2** init\n",
    "\n",
    "we call \n",
    "\n",
    "```python\n",
    "flare.init()\n",
    "```\n",
    "\n",
    "Once the flare is initialized, we can recieve some system metadata for example\n",
    "\n",
    "```python\n",
    "\n",
    "  sys_info = flare.system_info()\n",
    "  client_name = sys_info[\"site_name\"]\n",
    "\n",
    "```\n",
    "For instance, we can get current client's \"identity\" with `sys_info[\"site_name\"]`. \n",
    "\n",
    "Next we need to extend the training beyond local iterations. Imagine that Federated Learning is like the following for-loop:\n",
    "\n",
    "```python\n",
    "\n",
    "rounds = 5\n",
    "for current_round in ranage (rounds):\n",
    "     \n",
    "    <at each site local_training()>\n",
    "\n",
    "```\n",
    "\n",
    "Therefore we need to add an additional loop for federated client training. This can be done with: \n",
    "\n",
    "**Step 3** global round loop \n",
    "\n",
    "    while flare.is_running():\n",
    "        <local training>\n",
    "\n",
    "\n",
    "For each round, we need to receive and evaluate the global model. \n",
    "\n",
    "\n",
    "**Step-4** Receive global model\n",
    "\n",
    "```python\n",
    "\n",
    "        input_model = flare.receive()\n",
    "        round=input_model.current_round\n",
    "\n",
    "        # update model based on global model\n",
    "        model.load_state_dict(input_model.params)\n",
    "```\n",
    "\n",
    "**Step-5** Evaluate Global Model\n",
    "\n",
    "Since the local model is being updated with global model, the local training procedure typically calculates the loss and evaluates the performance of current global model for each round.\n",
    "\n",
    "**Step-6** Send the local trained model back to aggregator\n",
    "\n",
    "We take the newly trained local model parameters as well as metadata, send it back to aggregator, using the [FLModel](https://nvflare.readthedocs.io/en/main/programming_guide/fl_model.html) format.\n",
    "\n",
    "```python\n",
    "\n",
    "        output_model = flare.FLModel( params=model.cpu().state_dict(), meta={\"NUM_STEPS_CURRENT_ROUND\": steps},)\n",
    "\n",
    "        flare.send(output_model)\n",
    "```\n",
    "\n",
    "With the above steps, just a few lines of code changes, and no code structural changes, we converted the PyTorch deep learning code to federated learning with NVIDIA FLARE's Client API.\n",
    "\n",
    "The complete code can be found in [code/src/client_v1.py](code/src/client_v1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1824bf",
   "metadata": {},
   "source": [
    "That's it, we converted the client PyTorch training script to federated learning code. \n",
    "\n",
    "Let's look further to handle multi-task client code.\n",
    "\n",
    "## Multi-Task Client Scripts\n",
    "\n",
    "So far, the client only handles training, regardless of what tasks the server issues to the clients. What if there are many tasks? Client should take different actions based on the different tasks. Also, in the previous version, we did not evaluate the global model. We are going to handle all these in this section.\n",
    "\n",
    "\n",
    "In Flare's Client API, by default, we will issue three different tasks: \"train\", \"evaluate\" and \"submit_model\"\n",
    "\n",
    "These three tasks can be identified on the client side using the following APIs: \n",
    "\n",
    "```python\n",
    "\n",
    "flare.is_train()\n",
    "\n",
    "flare.is_evaluate()\n",
    "\n",
    "flare.is_submit_model()\n",
    "\n",
    "```\n",
    "\n",
    "Therefore, the overall client training logic becomes the following:\n",
    "\n",
    "```python\n",
    "\n",
    "if flare.is_training(): \n",
    "    traing and evaluate metrics\n",
    "    send model and merics back\n",
    "\n",
    "elif flare.is_evaluate():\n",
    "    # evaluate only, this can be used for cross-site evaluation\n",
    "    evaluate()\n",
    "    send the model and metrics back \n",
    "\n",
    "elif flare.is_submit_model()\n",
    "    \n",
    "    # expecting client submit best model \n",
    "    load and set best model \n",
    "\n",
    "```\n",
    "\n",
    "Let's modify our existing training code to have both training and evaluation logics.\n",
    "\n",
    "### The `evaluate()` function\n",
    "\n",
    "The evaluate() functions takes the `testloader` as input, and returns the accuracy percentage. \n",
    "\n",
    "```python\n",
    "\n",
    "    # wraps evaluation logic into a method to re-use for\n",
    "    #       evaluation on both trained and received model\n",
    "    def evaluate(input_weights):\n",
    "        net = Net()\n",
    "        net.load_state_dict(input_weights)\n",
    "        # (optional) use GPU to speed things up\n",
    "        net.to(DEVICE)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "\n",
    "                # (optional) use GPU to speed things up\n",
    "                images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return 100 * correct // total\n",
    "\n",
    "```\n",
    "\n",
    "### Adding evaluations to training logic\n",
    "\n",
    "We will add two evaluations to the original training logic, to evaluate and obtain the accuracy of both the local and the global models for each round.\n",
    "\n",
    "1. Evaluate the local model: \n",
    "\n",
    "```python\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "2. Evaluate the global model received:\n",
    "\n",
    "```python\n",
    "\n",
    "     # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "```\n",
    "\n",
    "Then, we add the global model accuracy into the metrics parameter of the FLModel before send it back to server. \n",
    "\n",
    "```python\n",
    "\n",
    " output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "```\n",
    "\n",
    "The newly modified training logic looks like this: \n",
    "\n",
    "```python\n",
    " \n",
    "\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "            print(f\"({client_id}) Evaluating local trained model. Accuracy on the 10000 test images: {local_accuracy}\")\n",
    "            if local_accuracy > best_accuracy:\n",
    "                best_accuracy = local_accuracy\n",
    "                torch.save(net.state_dict(), model_path)\n",
    "\n",
    "            # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "            print(\n",
    "                f\"({client_id}) Evaluating received model for model selection. Accuracy on the 10000 test images: {accuracy}\"\n",
    "            )\n",
    "\n",
    "            # (5.4) construct trained FL model\n",
    "            output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "\n",
    "            # (5.5) send model back to NVFlare\n",
    "            flare.send(output_model)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b024c86",
   "metadata": {},
   "source": [
    "The complete code can be found in [client.py](./code/src/client.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat code/src/client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0eb76",
   "metadata": {},
   "source": [
    "Now, we know how to convert an existing Deep Learning code to client-side Federated Learning training script. We can now explore how to customize the server-side logics.\n",
    "\n",
    "Let's jump to [server-side customization](../01.3_server_side_customization/customize_server_logics.ipynb).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
