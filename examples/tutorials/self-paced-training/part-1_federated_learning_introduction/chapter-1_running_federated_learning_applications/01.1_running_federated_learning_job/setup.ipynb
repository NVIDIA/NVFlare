{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c3d67-a6ea-4f59-84d2-effc3ef016e1",
   "metadata": {},
   "source": [
    "# Setup and Prepare Data\n",
    "\n",
    "This example of using [NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html) to train an image classifier using federated averaging ([FedAvg](https://arxiv.org/abs/1602.05629))\n",
    "and [PyTorch](https://pytorch.org/) as the deep learning training framework.\n",
    "\n",
    "We will use the train script [cifar10_fl.py](src/cifar10_fl.py) and network [net.py](src/net.py) from the src directory.\n",
    "\n",
    "The dataset will be [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and will load its data within the client train code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f04b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "540e6719",
   "metadata": {},
   "source": [
    "## Install NVIDIA FLARE and dependencies\n",
    "\n",
    "Install nvflare and requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nvflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795c6d",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "The CIFAR10 dataset has the following classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![image](code/img/cifar10.png)\n",
    "\n",
    "\n",
    "Before we start the training, we will first need to prepare the data. \n",
    "\n",
    "### download the data\n",
    "\n",
    "To avoid each job having to download and split the data, we add a step to prepare the data for all the cifar10 jobs. \n",
    "\n",
    "The CIFAR10 data will be downloaded to the common location. To make this process easiler, we wrote an simple download program like the followings\n",
    "\n",
    "```\n",
    "\n",
    "import argparse\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# default dataset path\n",
    "CIFAR10_ROOT = \"/tmp/nvflare/data/cifar10\"\n",
    "\n",
    "def define_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dataset_path\", type=str, default=CIFAR10_ROOT, nargs=\"?\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main(args):\n",
    "    datasets.CIFAR10(root=args.dataset_path, train=True, download=True)\n",
    "    datasets.CIFAR10(root=args.dataset_path, train=False, download=True)\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6293",
   "metadata": {},
   "source": [
    "The program just take a root dataset_path and download the training and test dataset to the given root directory from torchvision dataset. Let run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a13909",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 code/data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fafbe",
   "metadata": {},
   "source": [
    "We can examine the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbe572",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /tmp/nvflare/data/cifar10/cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce815072",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "In real-world scenarios, the data will be distributed among different clients/sides. Since we are simulating the real-world data, we need to split the data into different clients/sites. How to split the data, \n",
    "depending on the type of problem or type of data. For simplicity, in this example we assume all clients will have the same data for horizontal federated learning cases.\n",
    "Thus we do not do a data split, but rather point all clients to the same data location.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bae55",
   "metadata": {},
   "source": [
    "Next Step, we will start to run training using simulation: [run pytorch federated learning job](../01.1_running_federated_learning_job/runing_pytorch_fl_job.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a19f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
