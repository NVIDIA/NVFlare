{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c3d67-a6ea-4f59-84d2-effc3ef016e1",
   "metadata": {},
   "source": [
    "# Set-up and Preparation\n",
    "\n",
    "In this chapter, all our examples will be centered around training an [PyTorch](https://pytorch.org/)-based image classifier on the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n",
    "\n",
    "Our goal is to show case how you can easily convert and run these examples using the Federated Averaging ([FedAvg](https://arxiv.org/abs/1602.05629)) algorithm, with [NVIDIA FLARE](https://nvflare.readthedocs.io/en/2.6/index.html)'s APIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f04b0",
   "metadata": {},
   "source": [
    "Let's first go ahead and set everything up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e6719",
   "metadata": {},
   "source": [
    "## Install NVIDIA FLARE and dependencies\n",
    "\n",
    "Install nvflare and requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nvflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795c6d",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "The CIFAR10 dataset has the following classes: `airplane`, `automobile`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship`, `truck`.\n",
    "\n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![image](code/img/cifar10.png)\n",
    "\n",
    "Before we start the training, we will first need to prepare the data. \n",
    "\n",
    "### Download the data\n",
    "\n",
    "We've added a script in [code/data/download.py](code/data/download.py) that allows for downloading the CIFAR-10 dataset to a common location, so that all federated jobs could access it. The content of the script is displayed below:\n",
    "\n",
    "```python\n",
    "\n",
    "import argparse\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# default dataset path\n",
    "CIFAR10_ROOT = \"/tmp/nvflare/data/cifar10\"\n",
    "\n",
    "def define_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dataset_path\", type=str, default=CIFAR10_ROOT, nargs=\"?\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main(args):\n",
    "    datasets.CIFAR10(root=args.dataset_path, train=True, download=True)\n",
    "    datasets.CIFAR10(root=args.dataset_path, train=False, download=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6293",
   "metadata": {},
   "source": [
    "The script takes a root `dataset_path` and downloads the training and test datasets to the given root directory from the torchvision dataset. \n",
    "\n",
    "Let's run the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a13909",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 code/data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fafbe",
   "metadata": {},
   "source": [
    "We can examine the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbe572",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /tmp/nvflare/data/cifar10/cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce815072",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "In real-world scenarios, the data will be distributed among different clients/sites. Since we are simulating real-world data, we need to split the data into different clients/sites. How to split the data depends on the type of problem or type of data. \n",
    "\n",
    "For simplicity, in this example we assume all clients will have the same data for horizontal federated learning cases.\n",
    "Thus we do not do a data split, but rather point all clients to the same data location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bae55",
   "metadata": {},
   "source": [
    "Next step, we will run our first federated application! Let's jump to: [run pytorch federated learning job](../01.1_running_federated_learning_job/running_pytorch_fl_job.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
