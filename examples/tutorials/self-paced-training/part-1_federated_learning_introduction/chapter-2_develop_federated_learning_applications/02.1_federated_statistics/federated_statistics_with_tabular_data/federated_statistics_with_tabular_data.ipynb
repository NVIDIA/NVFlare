{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cb3afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Frame Federated Statistics \n",
    "\n",
    "In this example, we will show how to generate federated statistics for **tabular** data. The data can be loaded into Pandas DataFrame, and the data can be cached in memory so we can leverage DataFrame and NumPy to calculate the local statistics. The result will be saved to the job workspace in json format, and this can be loaded in Pandas DataFrame and visualized with the provided visualization utility as demonstrated in the linked notebook at the end of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a17f22-5667-4f99-b4f6-d49116db74b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install requirements\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8969bf-d010-42b5-a807-0808922402d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94faaa6b-08fd-485c-87d5-53b4520177fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare data\n",
    "\n",
    "In this example, we are using the UCI (University of California, Irvine) [adult dataset](https://archive.ics.uci.edu/dataset/2/adult)\n",
    "The original dataset already contains \"training\" and \"test\" datasets. Here we simply assume that the \"training\" and \"test\" data set each belong to a client, so we assign the adult.train dataset to site-1 and the adult.test dataset to site-2.\n",
    "\n",
    "Now we use the data utility to download UCI datasets to separate client package directory to /tmp/nvflare/data/ directory.\n",
    "Please note that the UCI's website may experience occasional downtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea959f-7282-4e55-bb26-11524ec47e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from code.df_stats.utils.prepare_data import prepare_data\n",
    "\n",
    "prepare_data(data_root_dir = \"/tmp/nvflare/df_stats/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5444d8f-4938-4759-bd43-831013043c23",
   "metadata": {},
   "source": [
    "#### Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf37d0-7555-4818-9963-ca7342161a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path =\"/tmp/nvflare/df_stats/data/site-1/data.csv\"\n",
    "data_features = [\n",
    "            \"Age\",\n",
    "            \"Workclass\",\n",
    "            \"fnlwgt\",\n",
    "            \"Education\",\n",
    "            \"Education-Num\",\n",
    "            \"Marital Status\",\n",
    "            \"Occupation\",\n",
    "            \"Relationship\",\n",
    "            \"Race\",\n",
    "            \"Sex\",\n",
    "            \"Capital Gain\",\n",
    "            \"Capital Loss\",\n",
    "            \"Hours per week\",\n",
    "            \"Country\",\n",
    "            \"Target\",\n",
    "        ]\n",
    "\n",
    "        # the original dataset has no header,\n",
    "        # we will use the adult.train dataset for site-1, the adult.test dataset for site-2\n",
    "        # the adult.test dataset has incorrect formatted row at 1st line, we will skip it.\n",
    "skip_rows = {\n",
    "            \"site-1\": [],\n",
    "            \"site-2\": [0],\n",
    "        }\n",
    "\n",
    "df= pd.read_csv(data_path, names=data_features, sep=r\"\\s*,\\s*\", skiprows=skip_rows, engine=\"python\", na_values=\"?\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6d572-7dc0-4cec-8382-f25555f52af9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "> Note **We will only calculate the statistics of numerical features, categorical features will be skipped**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c14e12",
   "metadata": {},
   "source": [
    "## Configure Job\n",
    "\n",
    "For this example, we have a file [df_stats_job.py](code/df_stats_job.py) that uses `StatsJob` to generate a job configuration in a Pythonic way.\n",
    "\n",
    "You may notice that `StatsJob` has a `statistic_configs` parameter that we have configured as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_configs = {\n",
    "        \"count\": {},\n",
    "        \"mean\": {},\n",
    "        \"sum\": {},\n",
    "        \"stddev\": {},\n",
    "        \"histogram\": {\"*\": {\"bins\": 20}},\n",
    "        \"Age\": {\"bins\": 20, \"range\": [0, 10]},\n",
    "        \"percentile\": {\"*\": [25, 50, 75], \"Age\": [50, 95]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e45a4",
   "metadata": {},
   "source": [
    "The `statistic_configs` parameter has all of the statistics we are gathering and provide bins and ranges. For histogram, we specified the histogram bins for all features (\"*\") to be 20. For age, we set the bins to 20 as well and also set the range to be [0,10]. The percentiles can be configured for each statistic as well. If the range is not specified, the ranges will be dynamically estimated. For bins, if not specified, the global bin range is dynamically estimated based on local min/max values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4ab4a",
   "metadata": {},
   "source": [
    "For `StatsJob`, the `stats_generator` parameter takes the statistics generator that is used for each client site, and in this example we use [DFStatistics](code/src/df_statistics.py). `DFStatistics` extends `DFStatisticsCore`, which in turn implements the `Statistics` specification from `nvflare.app_common.abstract.statistics_spec.Statistics`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4da328",
   "metadata": {},
   "source": [
    "## Run Job with FL Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d013501",
   "metadata": {},
   "source": [
    "The file [df_stats_job.py](code/df_stats_job.py) will run the job with the FL simulator through the Job API. With the default arguments, the job will be exported to `/tmp/nvflare/jobs/stats_df` and then the job will be run with the FL simulator with the `simulator_run()` command with a work_dir of `/tmp/nvflare/jobs/stats_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361a85e-4187-433c-976c-0dc4021908ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 code/df_stats_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be8a9a-b1b8-413c-abab-5cbd7e191a0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examine the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf6e9a-3265-4e45-8b06-c8e543605f21",
   "metadata": {},
   "source": [
    "With the default parameters, the results are stored in workspace \"/tmp/nvflare/jobs/stats_df/\"\n",
    "```\n",
    "/tmp/nvflare/jobs/stats_df/server/simulate_job/statistics/adults_stats.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a7dd0-45d9-42ea-98b2-f72a3bbccf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat /tmp/nvflare/jobs/stats_df/server/simulate_job/statistics/adults_stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd042db-6ce0-4e37-bcbe-d96051e4d164",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization\n",
    "We can visualize the results easly via the visualizaiton notebook. Before we do that, we need to copy the data to the notebook directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c89693-37b9-450c-85dd-8a2d78fee3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp /tmp/nvflare/jobs/stats_df/server/simulate_job/statistics/adults_stats.json code/df_stats/demo/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6f632-3326-4236-902e-8c0965688d85",
   "metadata": {},
   "source": [
    "now we can visualize the results with the [visualization notebook](code/df_stats/demo/visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda06c0b-798d-480d-9b4c-a62fab95bcf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We are done !\n",
    "Congratulations, you just completed the federated stats calulation with data represented by data frame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
