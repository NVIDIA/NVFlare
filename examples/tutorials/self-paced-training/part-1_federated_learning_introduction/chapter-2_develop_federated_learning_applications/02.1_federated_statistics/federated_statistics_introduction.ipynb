{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Statistics\n",
    "\n",
    "Before training the model, data scientists need to understand the data distribution and data quality of the data at different sites. As we can't access the raw data, we need to perform federated Analytics to get the statistics of the data at global level. That's where Federated Statistics comes in.\n",
    "\n",
    "\n",
    "## Objective\n",
    "NVIDIA FLARE will provide built-in federated statistics operators (controllers and executors) that \n",
    "can generate global statistics based on local client side statistics.\n",
    "\n",
    "At each client site, we could have one or more datasets (such as \"train\" and \"test\" datasets); each dataset may have many \n",
    "features. For each feature in the dataset, we will calculate the statistics and then combine them to produce \n",
    "global statistics for all the numeric features. The output would be complete statistics for all datasets in clients and global.    \n",
    "\n",
    "The statistics here are commonly used statistics: count, sum, mean, std_dev and histogram for the numerical features.\n",
    "The max, min are not included as it might violate the client's data privacy. The mean will be calculated with count and sum. \n",
    "\n",
    "The quantile can also be included, but requires additional dependency to be installed. We are not going to include it in the default installation.\n",
    "\n",
    "\n",
    "A client will only need to implement the selected methods of \"Statistics\" class from statistics_spec.\n",
    "\n",
    "The result will be statistics for all features of all datasets at all sites as well as global aggregates. \n",
    "The result could be visualized via the visualization utility in the notebook. \n",
    "\n",
    "\n",
    "## Assumptions\n",
    " \n",
    "Assume that clients will provide the following: \n",
    "   * users need to provide target statistics such as count, histogram etc. of targeted statistics features\n",
    "   * users need to provide the local statistics for the **target statistics** (by implementing the statistic_spec), not all statistics. For example, if the target statistics does not include histogram, then users will not need to provide the histogram calculation function.\n",
    "   * users need to provide the datasets and dataset features (feature name, data type)\n",
    "   * Note: count is always required as we use count to enforce data privacy policy\n",
    "   \n",
    "We only support **numerical features**, not categorical features. But users can return all types of features;\n",
    "the non-numerical features will be removed.\n",
    "\n",
    "\n",
    "\n",
    "## Statistics\n",
    "\n",
    "  Federated statistics includes numerics statistics measures for \n",
    "  * count\n",
    "  * mean \n",
    "  * sum\n",
    "  * std_dev\n",
    "  * histogram \n",
    "  * quantile\n",
    "    \n",
    "  We did not include min, max value to avoid data privacy concern. \n",
    "\n",
    "\n",
    "#### Quantile\n",
    "\n",
    "Quantile statistics refers to statistical measures that divide a probability distribution or dataset into intervals with equal probabilities or proportions. Quantiles help summarize the distribution of data by providing key points that indicate how values are spread.\n",
    "\n",
    "##### Key Quantiles:\n",
    "1. Median (50th percentile): The middle value of a dataset, dividing it into two equal halves.\n",
    "2. Quartiles (25th, 50th, 75th percentiles): Divide the data into four equal parts:\n",
    "* Q1 (25th percentile): Lower quartile, below which 25% of the data falls.\n",
    "* Q2 (50th percentile): Median.\n",
    "* Q3 (75th percentile): Upper quartile, below which 75% of the data falls.\n",
    "3. Deciles (10th, 20th, ..., 90th percentiles): Divide the data into ten equal parts.\n",
    "4. Percentiles (1st, 2nd, ..., 99th): Divide the data into 100 equal parts.\n",
    "\n",
    "##### Usage of Quantiles:\n",
    "* Descriptive Statistics: Summarizes the spread of data.\n",
    "* Outlier Detection: Helps identify extreme values.\n",
    "* Machine Learning: Used in feature engineering, normalization, and decision tree algorithms.\n",
    "* Risk Analysis: Used in finance (e.g., Value at Risk, VaR).\n",
    "\n",
    " \n",
    "## Privacy Policy and Privacy Filters\n",
    "\n",
    "NVFLARE provide data privacy protection through privacy filters [privacy-management](https://nvflare.readthedocs.io/en/main/user_guide/security/site_policy_management.html#privacy-management)\n",
    "Each site can have its own privacy policy. \n",
    "\n",
    "### Local privacy policy\n",
    "\n",
    "privacy.json provides local site specific privacy policy.\n",
    "The policy is likely setup by the company and implemented by organization admin\n",
    "for the project. For different type of scope or categories, there are might be different types of policies. \n",
    "\n",
    "### Privacy configuration\n",
    "\n",
    "The NVFLARE privacy configuration consists of set of task data filters and task result filters\n",
    "* The task data filter applies before client executor executes;\n",
    "* The task result filter is applied after the client executor executes and before the data is sent to the server;\n",
    "* Both the data filter and result filter are grouped by scope.\n",
    "\n",
    "Each job will need to have a privacy scope. If not specified, the default scope will be used. If default scope is not\n",
    "defined and job doesn't specify the privacy scope, the job deployment will fail, and job will not executed\n",
    "\n",
    "### Privacy Policy Instrumentation \n",
    "\n",
    "There are different ways to set privacy filters depending on the use cases\n",
    "\n",
    "\n",
    "####  Set Privacy Policy as researcher\n",
    "\n",
    "You can specify the \"task_result_filters\" in config_fed_client.json to specify\n",
    "the privacy control.  This is useful when you develop these filters\n",
    "\n",
    "#### Setup site privacy policy as org admin\n",
    "\n",
    "Once the company decides to instrument certain privacy policy independent of individual\n",
    "job, one can copy the local directory privacy.json content to clients' local privacy.json ( merge not overwrite).\n",
    "in this example, since we only has one app, we can simply copy the private.json from local directory to\n",
    "\n",
    "* site-1/local/privacy.json\n",
    "* site-2/local/privacy.json\n",
    "\n",
    "We need to remove the same filters from the job definition in config_fed_client.json\n",
    "by simply set the \"task_result_filters\" to empty list to avoid **double filtering**\n",
    "```\n",
    "\"task_result_filters\": []\n",
    "```\n",
    "#### Job filter vs filters in private.json\n",
    "\n",
    "Privacy filters are defined within a privacy scope.\n",
    "If a job's privacy scope is defined or has default scope, then the scope's filters (if any) are applied\n",
    "before the job-specified filters (if any). This rule is enforced during task execution time.\n",
    "\n",
    "With such rules, if we have both task result filters and privacy scoped filters, we need to understand\n",
    "that the privacy filters will be applied first, then the job filters. The filters will be applied by their specified orders\n",
    "\n",
    "### Statistics Privacy Filters\n",
    "Statistics privacy filters are task result filters. We already built one for Statistics. \n",
    "\n",
    "```\n",
    "StatisticsPrivacyFilter\n",
    "```\n",
    "The StatisticsPrivacyFilter consists of several `StatisticsPrivacyCleanser`s focused on the statistics sent\n",
    "from client to server.\n",
    "\n",
    "`StatisticsPrivacyCleanser` can be considered as an interceptor before the results delivered to server.\n",
    "Currently, we use three `StatisticsPrivacyCleanser`s to guard the data privacy. The reason we built \n",
    "`StatisticsPrivacyCleanser` instead of separate filters is to avoid repeated data de-serialization.\n",
    "\n",
    "#### MinCountCleanser:\n",
    "Check against the number of count returned from client for each dataset and each feature.\n",
    "\n",
    "If the min_count is not satisfied, there is potential risk of reveal client's real data. Then remove that feature's statistics\n",
    "from the result for this client.\n",
    "\n",
    "#### HistogramBinsCleanser:\n",
    "For histogram calculations, number of bins can't be too large compare to count. if the bins = count, then\n",
    "we also reveal the real data. This check to make sure that the number of bins be less than X percent of the count.\n",
    "X = max_bins_percent in percentage, for 10 is for 10%\n",
    "if the number of bins for the histogram is not satisfy this specified condition, the resulting histogram will be removed\n",
    "from statistics before sending to server.\n",
    "\n",
    "#### AddNoiseToMinMax\n",
    "For histogram calculations, if the feature's histogram bin's range is not specified, we will need to use local data's min\n",
    "and max values to calculate the global min/max values, then use the global min, max values as the bin range for histogram\n",
    "calculation. But send the server the local min, max values will reveal client's real data.\n",
    "To protect data privacy, we add noise to the local min/max values.\n",
    "\n",
    "Min/max random is used to generate random noise between (min_noise_level and max_noise_level).\n",
    "for example, the random noise is to be within (0.1 and 0.3),i.e. 10% to 30% level. These noise\n",
    "will make local min values smaller than the true local min values, and max values larger than\n",
    "the true local max values. As result, the estimate global max and min values (i.e. with noise)\n",
    "are still bounded the true global min/max values, in such that\n",
    "```\n",
    "est. global min value <\n",
    "    true global min value <\n",
    "        client's min value <\n",
    "            client's max value <\n",
    "                true global max <\n",
    "                        est. global max value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "We provided federated statistics operators that can easily aggregate and visualize the local statistics for\n",
    "different data site and features. We hope this feature will make it easier to perform federated data analysis.  \n",
    "\n",
    "We provide several examples to demonstrate how should the operators be used. \n",
    "\n",
    "The main steps are \n",
    "* provide server side configuration to specify target statistics and their configurations and output location\n",
    "* implement the local statistics generator (statistics_spec)\n",
    "* provide client side configuration to specify data input location\n",
    " \n",
    "\n",
    "Now lets dive into the examples\n",
    "\n",
    "\n",
    "* [Federated Statistics with tabular data](./federated_statistics_with_tabular_data/federated_statistics_with_tabular_data.ipynb) demonstrates how to create federated statistics for data that can be represented as Pandas DataFrames.\n",
    "* [Federated Statistics with image data](./federated_statistics_with_image_data/federated_statistics_with_image_data.ipynb) shows how to compute local and global image statistics with the consideration that data is private at each of the client sites.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
