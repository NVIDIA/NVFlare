{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Existing Code to FL Easily with the FLARE Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FLARE Client API provides an easy way to convert centralized, local training code into federated learning code with just a few lines of code changes.\n",
    "\n",
    "Most of the previous examples up this point have already been using the Client API, but in this section we focus on the core concepts of the Client API and explain some of the ways it can be configured to help you use the Client API more effectively.\n",
    "\n",
    "You can see the detailed examples with actual integration with deep learing platforms including PyTorch and TensorFlow here: https://github.com/NVIDIA/NVFlare/tree/main/examples/hello-world/ml-to-fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general structure of the popular federated learning (FL) workflow, \"FedAvg\" is as follows:\n",
    "\n",
    "1. **FL server initializes an initial model**\n",
    "2. **For each round (global iteration):**\n",
    "    1. FL server sends the global model to clients\n",
    "    2. Each FL client starts with this global model and trains on their own data\n",
    "    3. Each FL client sends back their trained model\n",
    "    4. FL server aggregates all the models and produces a new global model\n",
    "\n",
    "On the client side, the training workflow is as follows:\n",
    "\n",
    "1. Receive the model from the FL server\n",
    "2. Perform local training on the received global model and/or evaluate the received global model for model selection\n",
    "3. Send the new model back to the FL server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a centralized training code to federated learning, we need to\n",
    "adapt the code to do the following steps:\n",
    "\n",
    "1. Obtain the required information from the received `fl_model`\n",
    "2. Run local training\n",
    "3. Put the results in a new `fl_model` to be sent back\n",
    "\n",
    "For a general use case, there are three essential methods for the Client API:\n",
    "\n",
    "* ``init()``: Initializes NVFlare Client API environment.\n",
    "* ``receive()``: Receives model from NVFlare side.\n",
    "* ``send()``: Sends the model to NVFlare side.\n",
    "\n",
    "You can use the Client API to change centralized training code to\n",
    "federated learning, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvflare.client as flare\n",
    "\n",
    "flare.init() # 1. Initializes NVFlare Client API environment.\n",
    "input_model = flare.receive() # 2. Receives model from NVFlare side.\n",
    "params = input_model.params # 3. Obtain the required information from received FLModel\n",
    "\n",
    "# original local training code begins\n",
    "new_params = local_train(params)\n",
    "# original local training code ends\n",
    "\n",
    "output_model = flare.FLModel(params=new_params) # 4. Put the results in a new FLModel\n",
    "flare.send(output_model) # 5. Sends the model to NVFlare side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 5 lines of code changes, we convert the centralized training code to work in a\n",
    "federated learning setting.\n",
    "\n",
    "After this, we can use the job templates and the Job CLI\n",
    "to generate a job and export it to run on a deployed NVFlare system or directly run the job using FL Simulator.\n",
    "\n",
    "To see a table of the key Client APIs, see the [Client API documentation in the programming guide](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type/client_api.html#id2).\n",
    "\n",
    "Please consult the [Client API Module](https://nvflare.readthedocs.io/en/2.4/apidocs/nvflare.client.api.html) for more in-depth information about all of the Client API functions.\n",
    "\n",
    "If you are using PyTorch Lightning in your training code, you can check the [Lightning API Module](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_opt.lightning.api.html). Also, be sure to look through the [Convert Torch Lightning to FL notebook](../02.2_convert_torch_lightning_to_federated_learning/convert_torch_lightning_to_fl.ipynb) and related code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09d80e",
   "metadata": {},
   "source": [
    "## Advanced User Options: Client API with Different Implementations\n",
    "\n",
    "Within the Client API, we offer multiple implementations tailored to diverse requirements:\n",
    "\n",
    "* In-process Client API: In this setup, the client training script operates within the same process as the NVFlare Client job.\n",
    "This configuration, utilizing the ```InProcessClientAPIExecutor```, offers shared memory usage and is efficient with simple configuration. \n",
    "This is the default for `ScriptRunner` since by default `launch_external_process=False`. Use this configuration for development or single GPU training.\n",
    "\n",
    "* Sub-process Client API: Here, the client training script runs in a separate subprocess.\n",
    "Utilizing the ```ClientAPILauncherExecutor```, this option offers flexibility in communication mechanisms:\n",
    "  * Communication via CellPipe (default)\n",
    "  * Communication via FilePipe (no capability to stream metrics for experiment tracking) \n",
    "This configuration is ideal for scenarios requiring multi-GPU or distributed PyTorch training.\n",
    "\n",
    "Choose the option best suited to your specific requirements and workflow preferences.\n",
    "\n",
    "These implementations can be easily configured using the JobAPI's `ScriptRunner`.\n",
    "By default, the ```InProcessClientAPIExecutor``` is used, however setting `launch_external_process=True` uses the ```ClientAPILauncherExecutor```\n",
    "with pre-configured CellPipes for communication and metrics streaming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
