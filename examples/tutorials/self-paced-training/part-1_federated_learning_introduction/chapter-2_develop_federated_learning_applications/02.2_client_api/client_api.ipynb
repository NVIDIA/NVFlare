{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58149c32",
   "metadata": {},
   "source": [
    "# Transform Existing Code to FL Easily with the FLARE Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06203527",
   "metadata": {},
   "source": [
    "The FLARE Client API offers a straightforward path to transform your existing machine learning or deep learning code into federated learning applications. With just a few lines of code changes, you can adapt your training logic without restructuring your codebase or moving code into different class methods. This flexibility applies to both traditional machine learning and deep learning frameworks. For PyTorch Lightning users, the process is even more streamlined with dedicated Lightning API support.\n",
    "\n",
    "You can see detailed examples with actual integration across different platforms including PyTorch and TensorFlow [here:](https://github.com/NVIDIA/NVFlare/tree/main/examples/hello-world/ml-to-fl)\n",
    "\n",
    "In Chapter 1, you have already seen the Client API in action with pytorch. In this section, we will focus on the core concepts of the Client API and explain some of the ways it can be configured to help you use the Client API more effectively.\n",
    "\n",
    "Then we will see how to use the Client API with PyTorch Lightning, and traditional machine learning algorithms such as Logistic Regression, KMeans and survival analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7efa36",
   "metadata": {},
   "source": [
    "## Core Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76102eac",
   "metadata": {},
   "source": [
    "The general workflow of the popular federated learning (FL) follows the following steps:\n",
    "\n",
    "1. **FL server initializes an initial model**\n",
    "2. **For each round (global iteration):**\n",
    "    * FL server broadcasts the global model to clients\n",
    "    * Each FL client starts with this global model and perform the local training on their own data\n",
    "    * Each FL client, then sends back their newly trained model to the FL server\n",
    "    * FL server aggregates all the local models and produces a new global model\n",
    "\n",
    "On the client side, the training workflow is as follows:\n",
    "\n",
    "1. Receive the model from the FL server\n",
    "2. Perform local training on the received global model and/or evaluate the received global model for model selection\n",
    "3. Send the new model back to the FL server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2b7dd",
   "metadata": {},
   "source": [
    "To convert a centralized training code to federated learning, we need to\n",
    "adapt the code to do the following steps:\n",
    "\n",
    "1. Obtain the required information from the received `fl_model`\n",
    "2. Run local training\n",
    "3. Put the results in a new `fl_model` to be sent back\n",
    "\n",
    "For a general use case, there are three essential methods for the Client API:\n",
    "\n",
    "* ``init()``: Initializes NVFlare Client API environment.\n",
    "* ``receive()``: Receives model from NVFlare side.\n",
    "* ``send()``: Sends the model to NVFlare side.\n",
    "\n",
    "You can use the Client API to change centralized training code to\n",
    "federated learning, for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0044ea",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "import nvflare.client as flare\n",
    "\n",
    "flare.init() # 1. Initializes NVFlare Client API environment.\n",
    "input_model = flare.receive() # 2. Receives model from NVFlare side.\n",
    "params = input_model.params # 3. Obtain the required information from received FLModel\n",
    "\n",
    "# original local training code begins\n",
    "new_params = trainer.fit(params)\n",
    "# original local training code ends\n",
    "\n",
    "output_model = flare.FLModel(params=new_params) # 4. Put the results in a new FLModel\n",
    "flare.send(output_model) # 5. Sends the model to NVFlare side.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e4079",
   "metadata": {},
   "source": [
    "With 5 lines of code changes, we convert the centralized training code to work in a\n",
    "federated learning setting.\n",
    "\n",
    "After this, we can use the job templates and the Job CLI\n",
    "to generate a job and export it to run on a deployed NVFlare system or directly run the job using FL Simulator.\n",
    "\n",
    "To see a table of the key Client APIs, see the [Client API documentation in the programming guide](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type/client_api.html#id2).\n",
    "\n",
    "Please consult the [Client API Module](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.client.api.html) for more in-depth information about all of the Client API functions.\n",
    "\n",
    "If you are using PyTorch Lightning in your training code, you can check the [Lightning API Module](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_opt.lightning.api.html). Also, be sure to look through the [Convert Torch Lightning to FL notebook](../02.2_client_api/convert_torch_lightning_to_federated_learning/convert_torch_lightning_to_fl.ipynb) and related code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09d80e",
   "metadata": {},
   "source": [
    "## Client API with Different Implementations\n",
    "\n",
    "Within the Client API, we offer multiple implementations tailored to diverse requirements:\n",
    "\n",
    "* In-process Client API: efficient for single GPU training\n",
    "* Sub-process Client API: flexible for multi-GPU or distributed PyTorch training\n",
    "\n",
    "\n",
    "\n",
    "### In-process Client API\n",
    "\n",
    "In this setup, the client training script operates within the same process as the NVFlare Client job. This configuration, utilizing the ```InProcessClientAPIExecutor```, offers shared memory usage and is efficient with simple configuration. \n",
    "This is the default for `ScriptRunner` since by default `launch_external_process=False`. Use this configuration for development or single GPU training.\n",
    "\n",
    "### Sub-process Client API: Here, the client training script runs in a separate subprocess.\n",
    "\n",
    "Utilizing the ```ClientAPILauncherExecutor```, this option offers flexibility in communication mechanisms:\n",
    "  * Communication via CellPipe (default)\n",
    "  * Communication via FilePipe (no capability to stream metrics for experiment tracking) \n",
    "\n",
    "This configuration is ideal for scenarios requiring multi-GPU or distributed PyTorch training.\n",
    "\n",
    "Choose the option best suited to your specific requirements and workflow preferences.\n",
    "\n",
    "These implementations can be easily configured using the JobAPI's `ScriptRunner`.\n",
    "By default, the ```InProcessClientAPIExecutor``` is used, however setting `launch_external_process=True` uses the ```ClientAPILauncherExecutor```\n",
    "with pre-configured CellPipes for communication and metrics streaming.\n",
    "\n",
    "Lets look at an example of how to use the Client API with PyTorch Lightning and machine learning algorithms.\n",
    "\n",
    "* [convert pyTorch lightning to federated learning](../02.2_client_api/convert_torch_lightning_to_federated_learning/convert_torch_lightning_to_fl.ipynb)\n",
    "\n",
    "* [converft logistics regression to federatead learning](../02.2_client_api/convert_machine_learning_to_federated_learning/02.3.1_convert_logistic_regression_to_federated_learning/convert_logistic_regression_to_fl.ipynb)\n",
    "\n",
    "* [convert Kmeans to federated learning](../02.2_client_api/convert_machine_learning_to_federated_learning/02.3.2_convert_kmeans_to_federated_learning/convert_kmeans_to_fl.ipynb)\n",
    "\n",
    "* [convert survival analysis to federated learning](../02.2_client_api/convert_machine_learning_to_federated_learning/02.3.3_convert_survival_analysis_to_federated_learning/convert_survival_analysis_to_fl.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcd761",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
