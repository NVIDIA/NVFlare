{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cb3afa",
   "metadata": {},
   "source": [
    "# Federated Statistics with image data\n",
    "\n",
    "## Calculate Image Histogram\n",
    "\n",
    "In this example, we will compute local and global image statistics with the consideration that data is private at each of the client sites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a17f22-5667-4f99-b4f6-d49116db74b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8969bf-d010-42b5-a807-0808922402d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r image_stats/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065b351-baac-4f84-aa15-3d875f86cb93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download data\n",
    "\n",
    "As an example, we use the dataset from the [\"COVID-19 Radiography Database\"](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database).\n",
    "it contains png image files in four different classes: `COVID`, `Lung_Opacity`, `Normal`, and `Viral Pneumonia`.\n",
    "First create a temp directory, then we download and extract to `/tmp/nvflare/image_stats/data/.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e64769-17f1-4805-9399-1c141e050065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# prepare the directory\n",
    "\n",
    "if [ ! -d /tmp/nvflare/image_stats/data ]; then\n",
    "  mkdir -p /tmp/nvflare/image_stats/data\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562f713-5892-43c7-a3d6-d277c337b5ea",
   "metadata": {},
   "source": [
    "Download and unzip the data (you may need to log in to Kaggle or use an API key). Once you have extracted the data from the zip file, you can check the directory to make sure you have the COVID-19_Radiography_Dataset directory at the following location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc68ebf-6071-479d-8cc1-15439bedea02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x@ 12 kevlu  staff  384 Jan 30 21:55 \u001b[34mCOVID-19_Radiography_Dataset\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls -l /tmp/nvflare/image_stats/data/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94faaa6b-08fd-485c-87d5-53b4520177fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare data\n",
    "\n",
    "Next, create the data lists simulating different clients with varying amounts and types of images. \n",
    "The downloaded archive contains subfolders for four different classes: `COVID`, `Lung_Opacity`, `Normal`, and `Viral Pneumonia`.\n",
    "Here we assume each class of image corresponds to a different sites.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ea959f-7282-4e55-bb26-11524ec47e99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 data lists for ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia'].\n",
      "Saved 3616 entries at /tmp/nvflare/image_stats/data/site-1_COVID.json\n",
      "Saved 6012 entries at /tmp/nvflare/image_stats/data/site-2_Lung_Opacity.json\n",
      "Saved 10192 entries at /tmp/nvflare/image_stats/data/site-3_Normal.json\n",
      "Saved 1345 entries at /tmp/nvflare/image_stats/data/site-4_Viral Pneumonia.json\n"
     ]
    }
   ],
   "source": [
    "from image_stats.utils.prepare_data import prepare_data\n",
    "\n",
    "prepare_data(input_dir = \"/tmp/nvflare/image_stats/data\", \n",
    "             input_ext = \".png\",\n",
    "             output_dir =\"/tmp/nvflare/image_stats/data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00de5e4-4360-4fc5-a819-4eb156e56341",
   "metadata": {},
   "source": [
    "## Run Job in FL Simulator\n",
    "\n",
    "**Run Job with Simulator API**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd6f07-468d-4e08-8898-31d3adc78529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nvflare.private.fed.app.simulator.simulator_runner import SimulatorRunner\n",
    "runner = SimulatorRunner(job_folder=\"image_stats/jobs/image_stats\", workspace=\"/tmp/nvflare/workspace/image_stats\", n_clients = 4, threads=4)\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09aed14-5011-4418-8840-5f7c16c97534",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Run Job using Simulator CLI**\n",
    "\n",
    "From a **terminal** one can also the following equivalent CLI\n",
    "\n",
    "```\n",
    "nvflare simulator image_stats/jobs/image_stats -w /tmp/nvflare/workspace/image_stats -n 4 -t 4\n",
    "\n",
    "```\n",
    "\n",
    "assuming the nvflare is installed from a **terminal**. doing pip install from the notebook cell directory with bash command (! or %%bash) may or may not work depending on which python runtime kernel selected. Also %pip install or %pip install from notebook cell doesn't register the console_scripts in the PATH.   \n",
    "\n",
    "\n",
    "## Examine the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf6e9a-3265-4e45-8b06-c8e543605f21",
   "metadata": {},
   "source": [
    "\n",
    "The results are stored in workspace \"/tmp/nvflare/image_stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112a7dd0-45d9-42ea-98b2-f72a3bbccf48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 kevlu  wheel  38015 Jan 30 22:27 /tmp/nvflare/workspace/image_stats/server/simulate_job/statistics/image_statistics.json\n"
     ]
    }
   ],
   "source": [
    "! ls -al /tmp/nvflare/workspace/image_stats/server/simulate_job/statistics/image_statistics.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd042db-6ce0-4e37-bcbe-d96051e4d164",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization\n",
    "We can visualize the results easly via the visualization notebook. Before we do that, we need to copy the data to the notebook directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c89693-37b9-450c-85dd-8a2d78fee3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp /tmp/nvflare/workspace/image_stats/server/simulate_job/statistics/image_statistics.json image_stats/demo/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6f632-3326-4236-902e-8c0965688d85",
   "metadata": {},
   "source": [
    "now we can visualize via the [visualization notebook](image_stats/demo/visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2a52f-8a8d-45ef-8a50-ddbb4ed2f2c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are not quite done yet. What if you prefer to use python API instead CLI to run jobs. Lets do that in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e972070",
   "metadata": {},
   "source": [
    "The file [image_stats_job.py](image_stats/job_api/image_stats_job.py) uses the StatsJob to generate a job configuration in a Pythonic way. With the default arguments, the job will be exported to `/tmp/nvflare/jobs/stats_df` and then the job will be run with a work_dir of `/tmp/nvflare/jobs/stats_df/work_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db7cd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kevlu/workspace/repos/NVFlare/examples/tutorials/self-paced-training/part-1_federated_learning_introduction/Chapter-2_develop_federated_learning_applications/02.1_federated_statistics/federated_statistics_with_image_data/image_stats/job_api/image_stats_job.py\", line 16, in <module>\n",
      "    from image_statistics import ImageStatistics\n",
      "  File \"/Users/kevlu/workspace/repos/NVFlare/examples/tutorials/self-paced-training/part-1_federated_learning_introduction/Chapter-2_develop_federated_learning_applications/02.1_federated_statistics/federated_statistics_with_image_data/image_stats/job_api/image_statistics.py\", line 20, in <module>\n",
      "    from monai.data import ITKReader, load_decathlon_datalist\n",
      "ModuleNotFoundError: No module named 'monai'\n"
     ]
    }
   ],
   "source": [
    "! python3 image_stats/job_api/image_stats_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda06c0b-798d-480d-9b4c-a62fab95bcf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We are done !\n",
    "Congratulations, you just completed the federated stats image histogram calulation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
