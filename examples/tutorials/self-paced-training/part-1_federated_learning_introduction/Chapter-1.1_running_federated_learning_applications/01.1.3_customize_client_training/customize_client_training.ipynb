{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38561a0b-a072-41ea-b027-290402cf4582",
   "metadata": {},
   "source": [
    "# Customize Client training Scripts based on Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f020f8b",
   "metadata": {},
   "source": [
    "In previous section, we converted the client training code to federated learning training. But we simply the process a bit. There we assume we always training, regardless what tasks the server issues to the clients. \n",
    "\n",
    "What if there are many tasks ? Client should take different actions based on the different tasks. \n",
    "\n",
    "In Flare's Client API, by detault, we will issue three different tasks: \"train\", \"evalute\" and \"submit_model\"\n",
    "\n",
    "These three tasks can be checked by \n",
    "\n",
    "```\n",
    "\n",
    "flare.is_train()\n",
    "\n",
    "flare.is_evaluate()\n",
    "\n",
    "flare.is_submit_model()\n",
    "\n",
    "```\n",
    "\n",
    "So we need to motify our existing training code to have both training and evaluation logics\n",
    "\n",
    "## Training logics changes\n",
    "\n",
    "Besides the training logics we have seen before. We also need to evaluate and obtain the accuracy of the trainiing. \n",
    "here we perform two evaluates \n",
    "\n",
    "evaluate the local model: \n",
    "\n",
    "```\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "evalute the global model received \n",
    "\n",
    "```\n",
    "     # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "```\n",
    "\n",
    "Then add the global model accuracy into the metrics parameter of the FLModel before send it back to server. \n",
    "\n",
    "```\n",
    " output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "```\n",
    "\n",
    "\n",
    "The newly added training logics is like this. \n",
    "\n",
    ">Note: the evaluate() function will discussed next\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "            # (5.2) evaluation on local trained model to save best model\n",
    "            local_accuracy = evaluate(net.state_dict())\n",
    "            print(f\"({client_id}) Evaluating local trained model. Accuracy on the 10000 test images: {local_accuracy}\")\n",
    "            if local_accuracy > best_accuracy:\n",
    "                best_accuracy = local_accuracy\n",
    "                torch.save(net.state_dict(), model_path)\n",
    "\n",
    "            # (5.3) evaluate on received model for model selection\n",
    "            accuracy = evaluate(input_model.params)\n",
    "            print(\n",
    "                f\"({client_id}) Evaluating received model for model selection. Accuracy on the 10000 test images: {accuracy}\"\n",
    "            )\n",
    "\n",
    "            # (5.4) construct trained FL model\n",
    "            output_model = flare.FLModel(\n",
    "                params=net.cpu().state_dict(),\n",
    "                metrics={\"accuracy\": accuracy},\n",
    "                meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "            )\n",
    "\n",
    "            # (5.5) send model back to NVFlare\n",
    "            flare.send(output_model)\n",
    "\n",
    "```\n",
    "\n",
    "## Evaluate functions\n",
    "\n",
    "The evaluate() functions requires test data, it is a nested inner evaluation that can directly use the testloader. \n",
    "The return value is accuracy percentage. \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "    # wraps evaluation logic into a method to re-use for\n",
    "    #       evaluation on both trained and received model\n",
    "    def evaluate(input_weights):\n",
    "        net = Net()\n",
    "        net.load_state_dict(input_weights)\n",
    "        # (optional) use GPU to speed things up\n",
    "        net.to(DEVICE)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "\n",
    "                # (optional) use GPU to speed things up\n",
    "                images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return 100 * correct // total\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The overall logics becomes\n",
    "\n",
    "```\n",
    "if flare.is_training(): \n",
    "    traing and evaluate metrics\n",
    "    send model and merics back\n",
    "\n",
    "elif flare.is_evaluate():\n",
    "    # evaluate only, this can be used for cross-site evaluation\n",
    "    evaluate()\n",
    "    send the model and metrics back \n",
    "\n",
    "elif flare.is_submit_model()\n",
    "    \n",
    "    # expecting client submit best model \n",
    "    load and set best model \n",
    "\n",
    "```\n",
    "\n",
    "Please take a look at the [client.py](./code/src/client.py)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
