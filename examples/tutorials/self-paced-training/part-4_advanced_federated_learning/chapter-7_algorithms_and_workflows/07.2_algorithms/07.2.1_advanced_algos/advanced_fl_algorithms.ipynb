{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Advanced FL Algorithms\n",
    "We provide several examples to help you quickly get started with NVFlare.\n",
    "All examples in this folder are based on using [TensorFlow](https://tensorflow.org/) as the model training framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates TensorFlow-based federated learning algorithms,\n",
    "[FedAvg](https://arxiv.org/abs/1602.05629), [FedOpt](https://arxiv.org/abs/2003.00295), and [SCAFFOLD](https://arxiv.org/abs/1910.06378) on the CIFAR-10 dataset.\n",
    "\n",
    "In this example, the latest Client APIs were used to implement\n",
    "client-side training logics (details in file\n",
    "[`cifar10_tf_fl_alpha_split.py`](src/cifar10_tf_fl_alpha_split.py)),\n",
    "and the new\n",
    "[`FedJob`](../../../nvflare/job_config/api.py)\n",
    "APIs were used to programmatically set up an\n",
    "NVFlare job to be exported or ran by simulator (details in file\n",
    "[`tf_fl_script_runner_cifar10.py`](tf_fl_script_runner_cifar10.py)),\n",
    "alleviating the need of writing job config files, simplifying\n",
    "development process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install requirements\n",
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_NOTE:_**  We recommend either using a containerized deployment or virtual environment,\n",
    "> please refer to [getting started](https://nvflare.readthedocs.io/en/latest/getting_started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run experiments\n",
    "\n",
    "The next examples uses simulator to run all experiments. The script\n",
    "[`tf_fl_script_runner_cifar10.py`](tf_fl_script_runner_cifar10.py)\n",
    "is the main script to be used to launch different experiments with\n",
    "different arguments (see sections below for details). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Impact of Data Heterogeneity\n",
    "First, we can run several experiment to simulate different hetereogenous datasplits to see how it impacts the FedAvg algorithm.\n",
    "\n",
    "The CIFAR10 dataset will be downloaded when running any experiment for\n",
    "the first time. TensorBoard summary logs will be generated during\n",
    "any experiment, and you can use TensorBoard to visualize the\n",
    "training and validation process as the experiment runs. Data split\n",
    "files, summary logs and results will be saved in a workspace\n",
    "directory, which defaults to `/tmp` and can be configured by setting\n",
    "`--workspace` argument of the `tf_fl_script_runner_cifar10.py`\n",
    "script.\n",
    "\n",
    "We apply Dirichlet sampling (as implemented in [FedMA](https://github.com/IBM/FedMA)) to\n",
    "CIFAR10 data labels to simulate data heterogeneity among client sites, controlled by an\n",
    "`alpha` value between 0 (exclusive) and 1. A high alpha value indicates less data\n",
    "heterogeneity, i.e., an alpha value equal to 1.0 would result in homogeneous data \n",
    "distribution among different splits.\n",
    "\n",
    "> Note, we use the following environment variables in the training, to prevent\n",
    "> TensorFlow from allocating full GPU memory all at once so we can run the clients in parallel on the same GPU:\n",
    "> `export TF_FORCE_GPU_ALLOW_GROWTH=true && export TF_GPU_ALLOCATOR=cuda_malloc_asyncp`\n",
    ">\n",
    "> You should be able to run the 8 clients in parallel on a GPU with 16GB memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change GPU index if multiple GPUs are available\n",
    "GPU_INDX=0\n",
    "\n",
    "# Run FedAvg with different alpha values\n",
    "for alpha in [1.0, 0.1]:\n",
    "    !python ./tf_fl_script_runner_cifar10.py \\\n",
    "       --algo fedavg \\\n",
    "       --n_clients 8 \\\n",
    "       --num_rounds 50 \\\n",
    "       --batch_size 64 \\\n",
    "       --epochs 4 \\\n",
    "       --alpha $alpha \\\n",
    "       --gpu $GPU_INDX \\\n",
    "       --workspace /tmp # workspace root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the results by running `tensorboard --logdir /tmp/nvflare/jobs` in a different terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice the impact of data heterogeneity by varying the\n",
    "`alpha` value, where lower values cause higher heterogeneity. As can\n",
    "be observed in the table below, performance of the FedAvg decreases\n",
    "as data heterogeneity becomes higher.\n",
    "\n",
    "![Impact of client data\n",
    "heterogeneity](./figs/cifar10_tf_alphas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 How Advanced FL Algorithms Can Help\n",
    "\n",
    "Now, let's see how advanced FL algorithms can significantly improve performance in the presence of data heterogeneity -— a common real-world challenge where clients' local data distributions differ substantially. Techniques like [FedOpt](https://arxiv.org/abs/2003.00295) extend FedAvg by applying server-side optimization methods such as Adam or momentum SGD to better adapt to diverse client updates. [SCAFFOLD](https://arxiv.org/abs/1910.06378) tackles the issue of client drift by using control variates to correct local updates, helping align them more closely with global objectives. These methods can be integrated into the client training script and server-side controllers  to improve convergence and generalization in non-IID settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 FedOpt: Server-Side Optimization\n",
    "*FedOpt* is a family of algorithms that extends FedAvg by replacing the simple averaging step at the server with a more sophisticated server-side optimizer, such as Adam, Adagrad, or momentum SGD. While clients still perform multiple steps of local training, the global model update at the server is treated as an optimization problem in its own right.\n",
    "\n",
    "**Key idea:** Instead of just averaging the client updates, the server accumulates them and applies an optimizer to adjust the global model. This helps the server adapt more effectively to inconsistent or biased updates from clients, which are common in non-IID settings.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Improved convergence speed.\n",
    "- Greater stability across diverse client data distributions.\n",
    "- Flexibility to tune optimizer hyperparameters for different tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NVFlare, *FedOpt* is implmenent on top of the [FedAvg](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.workflows.fedavg.html#module-nvflare.app_common.workflows.fedavg) controller. \n",
    "\n",
    "If you look at the [source code](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/tf/fedopt_ctl.py) for the TensorFlow version of the `FedOpt` controller, you can see that it derives from the `FedAvg` class\n",
    "\n",
    "```python\n",
    "class FedOpt(FedAvg):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        optimizer_args: dict = {\n",
    "            \"path\": \"tensorflow.keras.optimizers.SGD\",\n",
    "            \"args\": {\"learning_rate\": 1.0, \"momentum\": 0.6},\n",
    "        },\n",
    "        lr_scheduler_args: dict = {\n",
    "            \"path\": \"tensorflow.keras.optimizers.schedules.CosineDecay\",\n",
    "            \"args\": {\"initial_learning_rate\": 1.0, \"decay_steps\": None, \"alpha\": 0.9},\n",
    "        },\n",
    "        **kwargs,\n",
    "    ):\n",
    "...\n",
    "```\n",
    "The init arguments of `FedOpt` have `optimizer_args` and `lr_scheduler_args` that allow you to specify the optimizer and learning rate scheduler to be used on the server. The main change to the standard FedAvg algorithm is how the global model is updated. Hence, FedOpt provides its own `update_model()` implementation using the specified TensorFlow optimizer to update the global model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 SCAFFOLD: Correcting Client Drift\n",
    "*SCAFFOLD* addresses a different issue known as client drift, which occurs when clients’ local updates deviate significantly from the direction that would optimize the global objective. This is especially problematic in heterogeneous environments where local optima vary widely.\n",
    "\n",
    "**Key idea:** SCAFFOLD introduces control variates—auxiliary variables maintained at both the client and server—to estimate and correct the drift. During training, each client uses its control variate to adjust its local gradient updates. After training, the server updates its global control variate based on the clients’ contributions.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Reduces variance across client updates.\n",
    "- Encourages local updates to stay aligned with the global optimization direction.\n",
    "- Leads to faster and more stable convergence in non-IID settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement *SCAFFOLD* in NVFlare, we again provide a custom controller, i.e., `Scaffold` derived from `FedAvg` that adds additional computational steps on the server-side. To do this, we simply overwrite the [run()](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/scaffold.py) routine to compute the aggregated global model weights and control weights.\n",
    "\n",
    "On the client side, a custom training script ([cifar10_tf_fl_alpha_split_scaffold.py](./src/cifar10_tf_fl_alpha_split_scaffold.py)) is used that uses the *SCAFFOLD* [formulas](https://arxiv.org/abs/1910.06378) for updating the control weights on the client side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Compare the algorithms\n",
    "Here, we use the `alpha=0.1` setting to compare FedAvg, with FedOpt, and Scaffold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change GPU index if multiple GPUs are available\n",
    "GPU_INDX=0\n",
    "\n",
    "for algo in [\"fedopt\", \"scaffold\"]:\n",
    "    !python ./tf_fl_script_runner_cifar10.py \\\n",
    "       --algo $algo \\\n",
    "       --n_clients 8 \\\n",
    "       --num_rounds 50 \\\n",
    "       --batch_size 64 \\\n",
    "       --epochs 4 \\\n",
    "       --alpha 0.1 \\\n",
    "       --gpu $GPU_INDX \\\n",
    "       --workspace /tmp # workspace root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can visualize the results by running `tensorboard --logdir /tmp/nvflare/jobs` in a different terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared the performance of different FL algorithms, with alpha value fixed to 0.1, i.e., a high client data heterogeneity. We can observe from the figure below that, FedOpt and SCAFFOLD achieve better performance, with better convergence rates compared to FedAvg with the same alpha setting. SCAFFOLD achieves that by adding a correction term when updating the client models, while FedOpt utilizes SGD with momentum to update the global model on the server. Both achieve better performance with the same number of training steps as FedAvg.\n",
    "\n",
    "![Comparison of FL Algorithms](./figs/cifar10_tf_algos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summary\n",
    "This notebook demonstrates advanced federated learning algorithms implemented in NVFlare using TensorFlow. Here's what you learned:\n",
    "    \n",
    "1. **Impact of Data Heterogeneity**:\n",
    "   - How different levels of data heterogeneity (controlled by `alpha` parameter) affect model performance\n",
    "   - Using Dirichlet sampling to simulate non-IID data distributions\n",
    "    \n",
    "2. **Advanced FL Algorithms**:\n",
    "   - **FedOpt**: Server-side optimization techniques to improve convergence\n",
    "   - **SCAFFOLD**: Control variates to correct client drift in heterogeneous settings\n",
    "    \n",
    "3. **Implementation Details**:\n",
    "   - Using NVFlare's Client APIs for client-side training\n",
    "   - Leveraging FedJob APIs for programmatic job configuration\n",
    "   - Running experiments using the simulator\n",
    "    \n",
    "4. **Visualization**:\n",
    "   - Using TensorBoard to monitor training progress\n",
    "   - Comparing performance across different algorithms and data distributions\n",
    "    \n",
    "Next, we'll learn about advanced communication patterns that can be enabled by NVFlare, starting with [Cyclic Weight Trainsfer](../07.2.2_cyclic/cyclic_weight_transfer_example.ipynb).\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
