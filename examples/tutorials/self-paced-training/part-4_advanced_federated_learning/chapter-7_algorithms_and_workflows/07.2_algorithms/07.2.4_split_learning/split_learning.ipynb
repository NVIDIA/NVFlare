{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cb299c-103d-46d3-b19f-82de81bde95f",
   "metadata": {},
   "source": [
    "## Split Learning with CIFAR-10\n",
    "\n",
    "If you haven't already, please follow the steps in the [PSI](./federated_private_set_intersection.ipynb) example to prepare the data.\n",
    "\n",
    "Now, that we have the data intersections, we can start with the actual [split learning](https://arxiv.org/abs/1810.06060).\n",
    "\n",
    "Again, we use the  CIFAR-10 dataset. We assume one client holds the images, and the other client holds the labels to compute losses and accuracy metrics. \n",
    "Activations and corresponding gradients are being exchanged between the clients using NVFlare.\n",
    "\n",
    "<img src=\"./figs/split_learning.svg\" alt=\"Split learning setup\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f6eb9",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "To impliement a \"SplitCNN\" for split learning, we that a standard CNN for CIFAR-10 classification ([ModerateCNN](./src/splitnn/split_nn.py)) and split its forward/backward pass into two parts.\n",
    "\n",
    "1. Convolutional layers\n",
    "2. Fully connected layers\n",
    "\n",
    "The convolutional layers are only optimized on the client holding the images, while the fully connected layers are optimized on the client holding the labels. For details see the [SplitNN](./src/splitnn/split_nn.py) code.\n",
    "\n",
    "```python\n",
    "class SplitNN(ModerateCNN):\n",
    "    def __init__(self, split_id):\n",
    "        ...\n",
    "        if self.split_id == 0:\n",
    "            self.split_forward = self.conv_layer\n",
    "        elif self.split_id == 1:\n",
    "            self.split_forward = self.fc_layer\n",
    "        else:\n",
    "            ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.split_forward(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164c800",
   "metadata": {},
   "source": [
    "### Peer-to-peer Communication\n",
    "\n",
    "To enable direct **peer-to-peer** communication between the clients, we will utilize NVFlare's low-level communication API. The [CIFAR10LearnerSplitNN](./src/splitnn/cifar10_learner_splitnn.py) class handles the execution of the forward & backward pass depending `split_id` specified by the client ID (see the Job API configuration below).\n",
    "\n",
    "In order to proceed the with the split learning, the client holding the images (\"site-1\") needs to send activations to the client holding the corresponding labels (\"site-2\"). We can use [Aux channel](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.private.aux_runner.html#nvflare.private.aux_runner.AuxRunner.send_aux_request), i.e., `engine.send_aux_request()`, to directly pass that information between the clients, i.e., implement a peer-to-peer communication channel. The result of the request will include the gradients computed in the backward pass from \"site-2\" which will allow \"site-1\" one to continue the optimization of ther part of the SplitNN.\n",
    "\n",
    "```python\n",
    "            # send to other side\n",
    "            result = engine.send_aux_request(\n",
    "                targets=self.other_client,\n",
    "                topic=SplitNNConstants.TASK_TRAIN_LABEL_STEP,\n",
    "                request=data_shareable,\n",
    "                timeout=SplitNNConstants.TIMEOUT,\n",
    "                fl_ctx=fl_ctx,\n",
    "            )\n",
    "```\n",
    "\n",
    "Note, each Aux request needs to register and topic handler on the receiving side. See the `initialize()` routine in [CIFAR10LearnerSplitNN](./src/splitnn/cifar10_learner_splitnn.py) for details.\n",
    "\n",
    "```python\n",
    "engine.register_aux_message_handler(\n",
    "                topic=SplitNNConstants.TASK_TRAIN_LABEL_STEP, message_handle_func=self._aux_train_label_side\n",
    "            )\n",
    "```\n",
    "\n",
    "See [Chapter 9: Implementing peer-to-peer (P2P) communication](../../../chapter-9_flare_low_level_apis/09.3_p2p_communication/p2p_communication.ipynb) for more details on using Aux channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e8b73",
   "metadata": {},
   "source": [
    "### Run simulated split-learning experiments\n",
    "Next we use the `intersection.txt` files computed in the previous step to align the datasets on each participating site in order to do split learning.\n",
    "\n",
    "Using the Job API, we can define the previously generated intersection file as input for each site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ad7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.job_config.api import FedJob\n",
    "\n",
    "# nvflare components\n",
    "from nvflare.app_opt.pt.file_model_persistor import PTFileModelPersistor\n",
    "from nvflare.app_common.shareablegenerators.full_model_shareable_generator import FullModelShareableGenerator\n",
    "from nvflare.app_common.widgets.validation_json_generator import ValidationJsonGenerator\n",
    "from nvflare.app_common.workflows.splitnn_workflow import SplitNNController\n",
    "from nvflare.app_common.executors.splitnn_learner_executor import SplitNNLearnerExecutor\n",
    "\n",
    "# custom code for this example\n",
    "from src.splitnn.split_nn import ModerateCNN, SplitNN\n",
    "from src.splitnn.cifar10_learner_splitnn import CIFAR10LearnerSplitNN\n",
    "\n",
    "num_rounds = 200 # 15625 for full training\n",
    "batch_size = 64\n",
    "\n",
    "job = FedJob(name=\"cifar10_splitnn\")\n",
    "\n",
    "# add server components\n",
    "job.to_server(\n",
    "        SplitNNController(\n",
    "            num_rounds=num_rounds,\n",
    "            batch_size=batch_size,\n",
    "            start_round=0,\n",
    "            persistor_id=job.as_id(PTFileModelPersistor(model=ModerateCNN())),\n",
    "            task_timeout=0,\n",
    "            shareable_generator_id=job.as_id(FullModelShareableGenerator())\n",
    "    )\n",
    ")\n",
    "job.to_server(ValidationJsonGenerator(), id=\"json_generator\")\n",
    "\n",
    "# add client components for two sites\n",
    "n_clients = 2\n",
    "for i in range(n_clients):\n",
    "        site_name = f\"site-{i+1}\"\n",
    "\n",
    "        learner_id = job.as_id(\n",
    "                CIFAR10LearnerSplitNN(\n",
    "                        dataset_root=\"/tmp/nvflare/data/cifar10\",\n",
    "                        intersection_file=f\"/tmp/nvflare/cifar10_psi/{site_name}/simulate_job/{site_name}/psi/intersection.txt\",\n",
    "                        lr=0.01,\n",
    "                        model=SplitNN(split_id=i)\n",
    "                )\n",
    "        )\n",
    "\n",
    "        job.to(SplitNNLearnerExecutor(learner_id=learner_id), site_name, tasks=[\"_splitnn_task_init_model_\", \"_splitnn_task_train_\"])\n",
    "\n",
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9fa919",
   "metadata": {},
   "source": [
    "To run the experiment, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ab931",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.simulator_run(\"/tmp/nvflare/cifar10_splitnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69debae6",
   "metadata": {},
   "source": [
    "The site containing the labels can compute accuracy and losses, which can be visualized in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir /tmp/nvflare/cifar10_splitnn --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9e700",
   "metadata": {},
   "source": [
    "The resulting training and validation curves with an overlap of 10,000 samples are shown below. The full training should take about half an hour to complete on an A100 GPU.\n",
    "\n",
    "![Split learning training curves](./figs/sl_training_curve_o10000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244f4ee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This example demonstrates a complete split learning workflow using the CIFAR-10 dataset, consisting of two main parts:\n",
    "\n",
    "### Part 1: Private Set Intersection (PSI)\n",
    "- Implements PSI using ECDH, Bloom Filters, and Golomb Compressed Sets algorithms.\n",
    "- Used to find overlapping data indices between two clients.\n",
    "- Each client holds different parts of the CIFAR-10 dataset (images vs labels).\n",
    "- PSI helps identify the common samples that can be used for training.\n",
    "- Results in `intersection.txt` files containing the overlapping sample indices.\n",
    "\n",
    "### Part 2: Split Learning\n",
    "- Implements split learning where one client holds images and another holds labels.\n",
    "- Uses the intersection indices from PSI to align datasets.\n",
    "- Activations and gradients are exchanged between clients via NVFlare.\n",
    "- Training progress can be monitored through TensorBoard.\n",
    "\n",
    "Now, let's [recap](../../07.3_recap/recap.ipynb) what you learned in this chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
