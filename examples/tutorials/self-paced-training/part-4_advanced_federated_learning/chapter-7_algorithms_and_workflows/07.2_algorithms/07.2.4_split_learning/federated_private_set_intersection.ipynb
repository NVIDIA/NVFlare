{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9d767a-5504-4f76-81f3-3e2478e32b08",
   "metadata": {},
   "source": [
    "## Split Learning with CIFAR-10: Private Set Intersection\n",
    "\n",
    "This example includes instructions on how to run [split learning](https://arxiv.org/abs/1810.06060) (SL) using the \n",
    "CIFAR-10 dataset and the [FL simulator](https://nvflare.readthedocs.io/en/latest/user_guide/nvflare_cli/fl_simulator.html).\n",
    "\n",
    "We assume one client holds the images, and the other client holds the labels to compute losses and accuracy metrics. \n",
    "Activations and corresponding gradients are being exchanged between the clients using NVFlare.\n",
    "\n",
    "<img src=\"./figs/split_learning.svg\" alt=\"Split learning setup\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2991acc",
   "metadata": {},
   "source": [
    "## Private Set Intersection\n",
    "\n",
    "In order to find the overlapping data indices between the different clients participating in split learning, \n",
    "we randomly select an subset of the training indices. For this, we can use a Private Set Intersection (PSI) technique. First of all, let's discuss what PSI is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0627698",
   "metadata": {},
   "source": [
    "### What is PSI?\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Private_set_intersection): \"The Private set intersection is a\n",
    "secure multiparty computation cryptographic technique that allows two parties holding sets to compare encrypted versions \n",
    "of these sets in order to compute the intersection. In this scenario, neither party reveals anything to the counterparty\n",
    "except for the elements in the intersection.\"\n",
    "\n",
    "![psi.png](./figs/psi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea670d2a",
   "metadata": {},
   "source": [
    "### What's the use cases for PSI in federated learning?\n",
    "\n",
    "There are many use cases for PSI, in terms of federated machine learning, we are particularly interested in the \n",
    "following use cases:\n",
    "\n",
    "* **Vertical Learning** -- User IDs matching\n",
    "\n",
    "![user_id_match.png](./figs/user_id_intersect.png)\n",
    "\n",
    "* **Vertical Learning** -- Feature overlapping discovery\n",
    "  - Site-1 : Feature A, B, C, D\n",
    "  - Site-2: Feature E, A, C, F, X, Y, Z\n",
    "  - Overlapping features: A, C\n",
    "\n",
    "* **Federated Statistics** -- Distinct values count of categorical features \n",
    "  - feature = email address -> discover :  how many distinct emails in the email addresses\n",
    "  - feature = country -> discover: how many distinct countries\n",
    "\n",
    "  *Example*\n",
    "    - site-1:   features: country.  total distinct countries = 20\n",
    "    - site-2:   features: country,  total distinct countries = 100\n",
    "    - site-1 and site2 overlapping distinct countries = 10  \n",
    "\n",
    "  => Total distinct countries = 20 + 100 - Overlapping countries  = 120-10 = 110\n",
    "  \n",
    "In federated statistics use case, the PSI will be used inside the Federated Statistics operations.\n",
    "\n",
    "For the example used in this chapter, Vertical FL or Split Learning user ID matching, we can directly do the PSI calculation as a preprocessing step with a separate NVFlare Job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea953a5",
   "metadata": {},
   "source": [
    "## PSI Protocol\n",
    "\n",
    "There are many protocols that can be used for PSI.\n",
    "\n",
    "For our implementation in nvflare/app_opt/psi, the PSI protocol is based on [ECDH](https://en.wikipedia.org/wiki/Elliptic-curve_Diffie%E2%80%93Hellman),\n",
    "Bloom Filters, and Golomb Compressed Sets PSI algorithm.\n",
    "\n",
    "The algorithm is developed by [openmined PSI](https://github.com/OpenMined/PSI) for two-party PSI.\n",
    "\n",
    "We took the two-party direct communication PSI protocol and extended to Federated Computing setting where all exchanges are\n",
    "funneled via a central FL server. We can also support multi-party PSI via a pair-wise approach, reducing the multiple intersection computations to several two-party PSI operation.\n",
    "\n",
    "Please refer to [here](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/psi/README.md) for more details on the PSI protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ed6b5",
   "metadata": {},
   "source": [
    "### Install requirements\n",
    "If you haven't yet, install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19990396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9695ad",
   "metadata": {},
   "source": [
    "### Download and split the CIFAR-10 dataset\n",
    "First, to simulate a vertical split dataset, we first download the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and distribute it between the two clients, assuming an `OVERLAP` of 10,000 samples between the two clients' datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DIR = \"/tmp/cifar10_vert_splits\"\n",
    "OVERLAP = \"10000\"\n",
    "!python ./cifar10_split_data_vertical.py --split_dir $SPLIT_DIR --overlap $OVERLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1bebf",
   "metadata": {},
   "source": [
    "### Run Job API\n",
    "\n",
    "Now that we have prepared the data, let's use the Job API to create a PSI Job.\n",
    "\n",
    "We need to a couple components specific to the PSI computation both on the server and client site, like `DhPSIController` and ``.\n",
    "\n",
    "To start, we use a general `FedJob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.job_config.api import FedJob\n",
    "\n",
    "# nvflare components\n",
    "from nvflare.app_common.psi.dh_psi.dh_psi_controller import DhPSIController\n",
    "from nvflare.app_common.psi.psi_executor import PSIExecutor\n",
    "from nvflare.app_opt.psi.dh_psi.dh_psi_task_handler import DhPSITaskHandler\n",
    "from nvflare.app_common.psi.file_psi_writer import FilePSIWriter\n",
    "\n",
    "# custom code for this example\n",
    "from src.psi.cifar10_local_psi import Cifar10LocalPSI\n",
    "\n",
    "job = FedJob(name=\"cifar10_psi\")\n",
    "\n",
    "# add server component\n",
    "job.to_server(DhPSIController())\n",
    "\n",
    "# add client components for two sites\n",
    "n_clients = 2\n",
    "for i in range(n_clients):\n",
    "        site_name = f\"site-{i+1}\"\n",
    "\n",
    "        # we add the client PSI components as ids to be referenced by other components\n",
    "        psi_writer_id = job.as_id(FilePSIWriter(output_path=\"psi/intersection.txt\"))\n",
    "        local_psi_id = job.as_id(Cifar10LocalPSI(psi_writer_id=psi_writer_id, data_path=f\"/tmp/cifar10_vert_splits/{site_name}.npy\"))\n",
    "        psi_algo_id = job.as_id(DhPSITaskHandler(local_psi_id=local_psi_id))\n",
    "\n",
    "        # now, that we have all ids of requried components, we can add them to the client\n",
    "        job.to(PSIExecutor(psi_algo_id=psi_algo_id), site_name)\n",
    "\n",
    "        print(f\"added components for {site_name}\")\n",
    "\n",
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec309cf",
   "metadata": {},
   "source": [
    "Now, that we created the job, we can run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c67e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.simulator_run(\"/tmp/nvflare/cifar10_psi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8413598",
   "metadata": {},
   "source": [
    "The result will be saved on each client's working directory in `intersection.txt`.\n",
    "\n",
    "We can check the correctness of the result by comparing it to the generated ground truth overlap, saved in `overlap.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b145c1",
   "metadata": {},
   "source": [
    "### Check the PSI result\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in overlap.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "gt_overlap = np.load(os.path.join(SPLIT_DIR, \"overlap.npy\"))\n",
    "\n",
    "psi_overlap_1 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/site-1/simulate_job/site-1/psi/intersection.txt\")\n",
    "psi_overlap_2 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/site-2/simulate_job/site-2/psi/intersection.txt\")\n",
    "                     \n",
    "print(\"gt_overlap\", gt_overlap, f\"n={len(gt_overlap)}\")\n",
    "print(\"psi_overlap_1\", psi_overlap_1, f\"n={len(psi_overlap_1)}\")\n",
    "print(\"psi_overlap_2\", psi_overlap_2, f\"n={len(psi_overlap_2)}\")\n",
    "\n",
    "intersect_1 = np.intersect1d(psi_overlap_1, gt_overlap, assume_unique=True)\n",
    "intersect_2 = np.intersect1d(psi_overlap_2, gt_overlap, assume_unique=True)\n",
    "\n",
    "print(f\"Found {100*len(intersect_1)/len(gt_overlap):.1f}% of the overlapping sample ids for site-1.\")\n",
    "print(f\"Found {100*len(intersect_2)/len(gt_overlap):.1f}% of the overlapping sample ids for site-2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8db6a",
   "metadata": {},
   "source": [
    "Next, we'll use the intersection indices computed by PSI in our [split learning](./split_learning.ipynb) example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
