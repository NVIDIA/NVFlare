{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# Swarm Learning with Cross-Site Evaluation\n",
    "\n",
    "In this chapter, we will demonstrate the [Swarm Learning](https://www.nature.com/articles/s41586-021-03583-3) and **Client-Controlled Cross-Site Evaluation** Workflows using the Client API and the CIFAR10 dataset. \n",
    "Unlike traditional federated learning, which relies on a central server to aggregate model updates, Swarm Learning eliminates the need for a central aggregator. Each participating node trains the model locally and shares only the learned parameters (e.g., weights) with other nodes, which act directly as aggregators.\n",
    "\n",
    "## Swarm Learning\n",
    "\n",
    "<img src=\"figs/swarm_learning.png\" alt=\"swarm ccwf\" width=35% height=35% />\n",
    "\n",
    "Swarm Learning is a decentralized Federated Averaging algorithm where the key difference is that the server is not trusted with any sensitive information. The server is now only responsible for job health and lifecycle management via the `SwarmServerController`, while the clients are now responsible for training and aggregation logic via the swarm client-controlled `SwarmClientController`.\n",
    "Similarly to the `Client-Controlled Cyclic Workflow` described in the previous [chapter](../07.2.2_cyclic/cyclic_weight_transfer_example.ipynb), the server is not involved in the communication of weight updates â€” instead a **peer-to-peer** communication channel is used for implementing swarm learning.\n",
    "\n",
    "- `SwarmServerController`: manages swarm job lifecycle and configurations such as `aggr_clients` and `train_clients`\n",
    "- `SwarmClientController`: sends `learn_task`  to all training clients to invoke their executors for `train` task each round, and sends results to designated `aggr_client` for aggregation.\n",
    "\n",
    "Required tasks: `train`\n",
    "\n",
    "See the full definitions of [SwarmServerController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/swarm_server_ctl.py) and [SwarmClientController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/swarm_client_ctl.py) for all available arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610506a",
   "metadata": {},
   "source": [
    "## Client-Controlled Cross-Site Evaluation\n",
    "\n",
    "<img src=\"figs/client_controlled_cse.png\" alt=\"cse ccwf\" width=35% height=35% />\n",
    "\n",
    "In client-controlled cross-site evaluation, rather than sending client models to the server for distribution, clients instead communicate directly with each other to share their models for validation.\n",
    "\n",
    "\n",
    "- `CrossSiteEvalServerController`: manages evaluation workflow and configurations such as `evaluators` and `evaluatees`\n",
    "- `CrossSiteEvalClientController`: sends `eval` request to evaluators, evaluators send `get_model` task to evaluatees, evaluatees send their model back with `submit_model`, and evaluators perform `validate` on the model and send the results to the server. \n",
    "\n",
    "Required tasks: `validate`, `submit_model`\n",
    "\n",
    "See the full definition of [CrossSiteEvalClientController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/cse_client_ctl.py) for all available arguments.\n",
    "\n",
    "## Converting DL training code to FL training code\n",
    "We will be using the [Client API FL code](../train.py) trainer converted from the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349f24a",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "If you haven't yet, install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90559cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e8bb1",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Make sure the CIFAR10 dataset is downloaded with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4861f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../download_cifar10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e15709",
   "metadata": {},
   "source": [
    "## Run Job API\n",
    "\n",
    "Let's use the Job API to create a CCWF Job.\n",
    "\n",
    "We use the `add_swarm()` function to add our server_config, client_config, and cse_config.\n",
    "\n",
    "First add the `SwarmServerConfig` with the number of rounds for the `SwarmServerController`.\n",
    "\n",
    "We also add `CrossSiteEvalConfig` for the `CrossSiteEvalServerController`.\n",
    "\n",
    "On the client side, we add the `SwarmClientConfig` for the `SwarmClientController` which maps the `learn_task_name` to `train` and add the `CrossSiteEvalClientController` which uses the `validate` and `submit_model` tasks. These task are handled by the `ScriptRunner` with our `train.py` script. Additionally, required components including the persistor with the initial `Net()` model, aggregator, and shareable generator are defined as client-side components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1729c19",
   "metadata": {},
   "source": [
    "Let's first copy the required files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bc41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../train.py train.py\n",
    "! cp ../net.py net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbd053",
   "metadata": {},
   "source": [
    "Then we can use Job API to easily create a job and run in simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import Net\n",
    "\n",
    "from nvflare.apis.dxo import DataKind\n",
    "from nvflare.app_common.aggregators.intime_accumulate_model_aggregator import InTimeAccumulateWeightedAggregator\n",
    "from nvflare.app_common.ccwf.ccwf_job import CCWFJob, CrossSiteEvalConfig, SwarmClientConfig, SwarmServerConfig\n",
    "from nvflare.app_common.ccwf.comps.simple_model_shareable_generator import SimpleModelShareableGenerator\n",
    "from nvflare.app_opt.pt.file_model_persistor import PTFileModelPersistor\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "n_clients = 2\n",
    "num_rounds = 3\n",
    "train_script = \"train.py\"\n",
    "\n",
    "job = CCWFJob(name=\"swarm\")\n",
    "aggregator = InTimeAccumulateWeightedAggregator(expected_data_kind=DataKind.WEIGHTS)\n",
    "job.add_swarm(\n",
    "    server_config=SwarmServerConfig(num_rounds=num_rounds),\n",
    "    client_config=SwarmClientConfig(\n",
    "        executor=ScriptRunner(script=train_script),\n",
    "        aggregator=aggregator,\n",
    "        persistor=PTFileModelPersistor(model=Net()),\n",
    "        shareable_generator=SimpleModelShareableGenerator(),\n",
    "    ),\n",
    "    cse_config=CrossSiteEvalConfig(eval_task_timeout=300),\n",
    ")\n",
    "\n",
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")\n",
    "job.simulator_run(\"/tmp/nvflare/jobs/workdir\", n_clients=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582adfba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored two key concepts in advanced federated learning:\n",
    "\n",
    "1. **Swarm Learning**:\n",
    "- A decentralized approach to federated learning that eliminates the need for a central server\n",
    "- Uses `SwarmServerController` for job lifecycle management\n",
    "- Employs `SwarmClientController` for training and aggregation logic\n",
    "- Clients directly share parameters with each other instead of going through a central server\n",
    "2. **Client-Controlled Cross-Site Evaluation**:\n",
    "- Enables direct client-to-client model sharing for validation\n",
    "- Uses `CrossSiteEvalServerController` for workflow management\n",
    "- Implements `CrossSiteEvalClientController` for evaluation coordination\n",
    "- Supports tasks like \"validate\" and \"submit_model\"\n",
    "\n",
    "This approach provides enhanced privacy and security by keeping sensitive data on client devices while enabling effective model training and evaluation across multiple sites.\n",
    "\n",
    "Next, we'll learn about [Split Learning](https://arxiv.org/abs/1810.06060), another alternative to standard federated learning, suitable for vertical data partitioning among sites. To enable, real-world split learning, we start with a privacy-preserving way to find common case ids between datasets from different sites, namely [Private Set Intersection](../07.2.4_split_learning/federated_private_set_intersection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef3134",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
