{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9e326e-1d97-45c5-ac54-6bf581e4223f",
   "metadata": {},
   "source": [
    "# Summary of Chapter 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c7385-dd22-4d5c-8d2e-7a73f0b3ac2d",
   "metadata": {},
   "source": [
    "In this chapter, we visited NVFlare's offerings in enabling efficient and robust federated training of language models, especially in the era of LLMs.\n",
    "\n",
    "Specifically, the following items have been covered:\n",
    "1. **Federated BERT**\n",
    "\n",
    "Task-specific model training with BERT in a federated setting\n",
    "* [Federated NLP with BERT Model](../08.1_fed_bert/federated_nlp_with_bert.ipynb)\n",
    "\n",
    "2. **Federated LLM Training with SFT**\n",
    "\n",
    "Supervised Fine-Tuning and its role in adapting LLMs in federated learning\n",
    "* [Federated LLM Tuning with SFT](../08.2_llm_sft/LLM_SFT.ipynb)\n",
    "\n",
    "3. **Federated LLM Training with PEFT**\n",
    "\n",
    "Importance of PEFT in adapting LLMs for specific tasks, which can be achieve in a federated setting\n",
    "* [Federated LLM Tuning with PEFT](../08.3_llm_peft/LLM_PEFT.ipynb)\n",
    "\n",
    "4. **Model Transmission with Quantization**\n",
    "\n",
    "One major hurdle of adapting LLMs in federated learning is the significant communication burden when performing federated SFT. To reduce the message size, quantization method can be applied as filters.\n",
    "* [Model Quantization for Transmission](../08.4_llm_quantization/LLM_quantization.ipynb)\n",
    "\n",
    "5 **Model Transmission with Streaming**\n",
    "\n",
    "While quantization reduced communication cost, system memory requirement is still high for prepareing the message on either side. Therefore, we enabled streaming capabilities for more efficient and robust model communication.\n",
    "* [Message Streaming for Model Transmission](../08.5_llm_streaming/LLM_streaming.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32effe-3b9d-4cd8-b53c-f91907de9d95",
   "metadata": {},
   "source": [
    "With NVFlare, popular training schemes widely used in the industry can be easily adopted to federated learning paradigm, unleasing more posibilities.\n",
    "\n",
    "Now let's move on to the [Chapter 9](../../chapter-9_flare_low_level_apis/09.0_introduction/introduction.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4321c7c-d56c-49b9-89a2-c503290b8232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
