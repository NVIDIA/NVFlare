{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing P2P algorithms\n",
    "\n",
    "In the previous notebooks we learned how to build custom components, send tasks and data and make clients communicate to each other. With that knowledge now available, in this notebook, we'll explore how to build and run custom P2P algorithms. As a guiding example, we will try to re-implement from scratch the basics of the `nvflare.app_opt.p2p` module, which implements peer-to-peer (P2P) distributed optimization algorithms.\n",
    "\n",
    "To do that we need a few things:\n",
    "\n",
    "- A flexible way to define the communication topology of the clients along with some othe configuration parameters. In the previous example we hardcoded the list of clients to which each client should send data. In this notebook we'll use a more flexible approach, where the communication topology is defined by a graph.\n",
    "- A controller that can share the communication topology with the clients and then assign them the task to run the P2P algorithm.\n",
    "- A client that can receive the communication topology and run the P2P algorithm. Since we plan to implement synchronous P2P algorithms, we'll also need a way to synchronize all the clients with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication topology configuration\n",
    "\n",
    "We'll start by simply defining a `Node` (i.e. a client in the network), its `Neighbors` (i.e. other clients with which a client communicates, each with a weight) and combine them to define a `Network` (i.e. a network of clients with neighbors).\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Neighbor:\n",
    "    id: int | str\n",
    "    weight: float | None = None\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    id: int | str\n",
    "    neighbors: list[Neighbor] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Network:\n",
    "    nodes: list[Node] = field(default_factory=list)\n",
    "```\n",
    "\n",
    "Then we'll define a global and a local config objects to be passed to the controller and executors respectively.\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    network: Network\n",
    "    extra: dict = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class LocalConfig:\n",
    "    neighbors: list[Neighbor]\n",
    "    extra: dict = field(default_factory=dict)\n",
    "```\n",
    "\n",
    "The `extra` parameter can be used to pass additional parameters, usually specific for the various algorithms. \n",
    "\n",
    "To actual implementation of the objects above can be found in `nvflare/app_opt/p2p/types/__init__.py` (you'll see they'll have the `__dict__` and `__post_init__` methods defined facilitate serializing and deserializing them, which is needed for NVFlare). You also have some utils to generate random configs for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.app_opt.p2p.utils.config_generator import generate_random_network\n",
    "from rich import print\n",
    "\n",
    "network, adjacency_matrix = generate_random_network(num_clients=3)\n",
    "print(network)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.app_opt.p2p.types import Config\n",
    "config = Config(network=network, extra={\"iterations\": 100})\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Create a ring network with 3 clients and add it to a config, along with the number of iterations. Your config should look like this:\n",
    "```shell\n",
    "Config(\n",
    "    extra={\"iterations\":100},\n",
    "    network=Network(\n",
    "        nodes=[\n",
    "            Node(\n",
    "                id='site-1',\n",
    "                neighbors=[\n",
    "                    Neighbor(id='site-2', weight=0.1),\n",
    "                ]\n",
    "            ),\n",
    "            Node(\n",
    "                id='site-2',\n",
    "                neighbors=[\n",
    "                    Neighbor(id='site-3', weight=0.1),\n",
    "                ]\n",
    "            ),\n",
    "            Node(\n",
    "                id='site-3',\n",
    "                neighbors=[\n",
    "                    Neighbor(id='site-1', weight=0.1),\n",
    "                ]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The controller\n",
    "\n",
    "Let's now look at how to implement our controller with the specifications above. The configuration can be passed to the controller when initializing it, while the `control_flow` method will be responsible for sending the configuration to the clients and then running the algorithm.\n",
    "\n",
    "### Initializing the Controller\n",
    "To initialize the controller to, we override the `__init__` method to accept a `Config` object, which contains the network configuration and any extra parameters needed for the algorithm\n",
    "\n",
    "```python\n",
    "from nvflare.app_opt.p2p.types import Config\n",
    "\n",
    "class DistOptController(Controller):\n",
    "    def __init__(self, config: Config, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = config\n",
    "```\n",
    "\n",
    "> NOTE: the name of the init arguments and the class parameters need to match for the object to be instantiatable by NVFlare (see [here](https://nvflare.readthedocs.io/en/main/programming_guide/fed_job_api.html)).\n",
    "\n",
    "### Implementing the Control Flow\n",
    "\n",
    "In the control_flow method, we'll perform two main steps:\n",
    "\n",
    "1. Send the network configuration to the clients: Each client receives its specific configuration, such as neighbor information.\n",
    "\n",
    "2. Run the algorithm: Instruct all clients to start executing the P2P optimization algorithm.\n",
    "\n",
    "Let's first look at the implementation and then we'll break it down.\n",
    "\n",
    "\n",
    "```python\n",
    "from nvflare.apis.controller_spec import Task\n",
    "from nvflare.apis.dxo import DXO, DataKind\n",
    "\n",
    "class DistOptController(Controller):\n",
    "\n",
    "    ...\n",
    "\n",
    "    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n",
    "        # 1. Send network config to each client\n",
    "        for node in self.config.network.nodes:\n",
    "            # Prepare the data using DXO\n",
    "            data = DXO(\n",
    "                data_kind=DataKind.APP_DEFINED,\n",
    "                data={\"neighbors\": [n.__dict__ for n in node.neighbors]},\n",
    "            ).to_shareable()\n",
    "\n",
    "            # Create the task with name \"config\"\n",
    "            task = Task(name=\"config\", data=data)\n",
    "\n",
    "            # Send the task to the specific client and wait for completion\n",
    "            self.send_and_wait(task=task, targets=[node.id], fl_ctx=fl_ctx)\n",
    "\n",
    "        # 2. Instruct clients to run the algorithm\n",
    "        targets = [node.id for node in self.config.network.nodes]\n",
    "        \n",
    "        # Prepare any extra parameters to send to the clients\n",
    "        data = DXO(\n",
    "            data_kind=DataKind.APP_DEFINED,\n",
    "            data={key: value for key, value in self.config.extra.items()},\n",
    "        ).to_shareable()\n",
    "\n",
    "        # Create the task with name \"run_algorithm\"\n",
    "        task = Task(name=\"run_algorithm\", data=data)\n",
    "\n",
    "        # Broadcast the task to all clients and wait for all to respond\n",
    "        self.broadcast_and_wait(\n",
    "            task=task,\n",
    "            targets=targets,\n",
    "            min_responses=0,\n",
    "            fl_ctx=fl_ctx,\n",
    "        )\n",
    "```\n",
    "\n",
    "#### Implementation break-down\n",
    "1. Send the network configuration to the clients\n",
    "    - For each node in the network configuration:\n",
    "        - Prepare the data using DXO:\n",
    "            - We create a `DXO` object with the neighbors' information. As discussed, it encapsulates the data to be sent to the client. Here, we use `DataKind.APP_DEFINED` to indicate that the data is application-defined.\n",
    "        - Convert the `DXO` to a `Shareable`:\n",
    "            - We call `.to_shareable()` to create a `Shareable` object from the `DXO`. This conversion is necessary because NVFlare's communication mechanism uses `Shareable` objects. As mentioned, the `Shareable` object wraps the data to be transferred between server and clients. \n",
    "        - Create a task with name `\"config\"`:\n",
    "            - We create a `Task` named `\"config\"` with the `Shareable` data. The task name \"config\" identifies the task type, which the client will recognize and handle accordingly (we'll see that in the next section, when building the executors)/\n",
    "        - Send the task to the specific client and wait for completion:\n",
    "            - Here we use the `send_and_wait` method to send the task to the target client (`node.id`) and wait for it to complete the task. This ensures synchronization before moving to the next step.\n",
    "2. Running the Algorithm\n",
    "    - Prepare the list of target clients:\n",
    "        - We collect all node IDs from the network configuration into the `targets` list.\n",
    "    - Prepare any extra parameters:\n",
    "        - We create a `DXO` with any extra parameters needed for the algorithm, stored in `self.config.extra`.\n",
    "    - Create and broadcast the task:\n",
    "        - We create a `Task` named `\"run_algorithm\"` with the `Shareable` data.\n",
    "        - Broadcast and wait:\n",
    "            - We use `broadcast_and_wait` to send the task to all target clients. As the name suggests, this method broadcasts the same task to all specified clients and waits for their responses. Here, we set `min_responses=0`, indicating that we wait for all clients to respond/complete the algorithm before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The executor\n",
    "\n",
    "As said, for our purposes, we'll need our executor to be able to do a few things:\n",
    "- Receive the configuration from the server/controller.\n",
    "- Communicate with its neighbors and send/receive messages to/from them.\n",
    "- Run the algorithm in a synchronous way.\n",
    "\n",
    "As we've learned in the previous sections, the primary method we need to implement is the `execute` method, which processes tasks received from the controller. We'll make it handle 2 different tasks: `config` and `run_algorithm`.\n",
    "\n",
    "### Basic Structure\n",
    "Here's the basic structure of our executor:\n",
    "\n",
    "```python\n",
    "from nvflare.apis.executor import Executor\n",
    "from nvflare.apis.fl_constant import ReturnCode\n",
    "from nvflare.apis.fl_context import FLContext\n",
    "from nvflare.apis.shareable import Shareable, make_reply\n",
    "from nvflare.apis.signal import Signal\n",
    "\n",
    "\n",
    "class SyncAlgorithmExecutor(Executor):\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "        task_name: str,\n",
    "        shareable: Shareable,\n",
    "        fl_ctx: FLContext,\n",
    "        abort_signal: Signal,\n",
    "    ):\n",
    "        if task_name == \"config\":\n",
    "            # TODO: receive and store config\n",
    "            ...\n",
    "            return make_reply(ReturnCode.OK)\n",
    "        elif task_name == \"run_algorithm\":\n",
    "            # TODO: run the algorithm\n",
    "            return make_reply(ReturnCode.OK)\n",
    "        else:\n",
    "            self.log_warning(fl_ctx, f\"Unknown task name: {task_name}\")\n",
    "            return make_reply(ReturnCode.TASK_UNKNOWN)\n",
    "```\n",
    "\n",
    "### Handling the `\"config\"` task\n",
    "\n",
    "Let's focus on handling the `\"config\"` task first. We need to receive configuration data from the server and store it locally. We'll also initialize attributes to store the configuration and the neighbors' information.\n",
    "\n",
    "```python\n",
    "from nvflare.apis.dxo import from_shareable\n",
    "from nvflare.app_opt.p2p.types import LocalConfig, Neighbor\n",
    "\n",
    "\n",
    "class SyncAlgorithmExecutor(Executor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = None\n",
    "        self._weight = None\n",
    "        self.neighbors: list[Neighbor] = []\n",
    "\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "        task_name: str,\n",
    "        shareable: Shareable,\n",
    "        fl_ctx: FLContext,\n",
    "        abort_signal: Signal,\n",
    "    ):\n",
    "        if task_name == \"config\":\n",
    "            # Receive and store config\n",
    "            self.config = LocalConfig(**from_shareable(shareable).data)\n",
    "            self.neighbors = self.config.neighbors\n",
    "\n",
    "            # Compute local weight\n",
    "            self._weight = 1.0 - sum([n.weight for n in self.neighbors])\n",
    "\n",
    "            return make_reply(ReturnCode.OK)\n",
    "\n",
    "        elif task_name == \"run_algorithm\":\n",
    "            # TODO: run the algorithm\n",
    "            return make_reply(ReturnCode.OK)\n",
    "        else:\n",
    "            self.log_warning(fl_ctx, f\"Unknown task name: {task_name}\")\n",
    "            return make_reply(ReturnCode.TASK_UNKNOWN)\n",
    "```\n",
    "\n",
    "Here, we're using the `LocalConfig` we defined above to store the client's local configuration, including neighbors in a pythonic way.\n",
    "\n",
    "> EXERCISE: try to create a job with the controller and executor we built so far and explore the config of each client.\n",
    "\n",
    "### P2P communication and synchronization\n",
    "\n",
    "We know from the previous notebook how to perform P2P communication via the `send_aux_request` and registering a handler to take care of the received message through the aux channel.\n",
    "\n",
    "Now, we'll need two more things for our purposes:\n",
    "- Synchronizing execution: Using threading events and locks to coordinate the execution of the algorithm.\n",
    "- Handling message formats: Implementing methods to serialize and deserialize messages (this is useful, for example, to send torch tensors). We'll add two methods, `_from_message` and `_to_message` to do that.\n",
    "\n",
    "The main message exchange will be done in the `_exchange_values` function. Let's first look at the implementation and then we'll discuss it in detail.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from abc import abstractmethod\n",
    "from collections import defaultdict\n",
    "\n",
    "from nvflare.apis.dxo import DXO, DataKind\n",
    "from nvflare.apis.event_type import EventType\n",
    "from nvflare.apis.fl_constant import ReservedKey\n",
    "from nvflare.apis.signal import Signal\n",
    "\n",
    "\n",
    "class SyncAlgorithmExecutor(Executor):\n",
    "    def __init__(self, sync_timeout: int = 10):\n",
    "        super().__init__()\n",
    "        ... # other attributes\n",
    "\n",
    "        self.neighbors_values = defaultdict(dict)\n",
    "\n",
    "        # Threading primitives for synchronization\n",
    "        self.sync_waiter = threading.Event()\n",
    "        self.lock = threading.Lock()\n",
    "        self.sync_timeout = sync_timeout\n",
    "\n",
    "\n",
    "    def _exchange_values(self, fl_ctx: FLContext, value: any, iteration: int):\n",
    "        engine = fl_ctx.get_engine()\n",
    "\n",
    "        # Clear the event before starting the exchange\n",
    "        self.sync_waiter.clear()\n",
    "\n",
    "        # Send message to neighbors\n",
    "        targets = [neighbor.id for neighbor in self.neighbors]\n",
    "        data = DXO(\n",
    "            data_kind=DataKind.METRICS,\n",
    "            data={\n",
    "                \"value\": self._to_message(value),\n",
    "                \"iteration\": iteration,\n",
    "            },\n",
    "        ).to_shareable()\n",
    "\n",
    "        # Send auxiliary request to neighbors\n",
    "        _ = engine.send_aux_request(\n",
    "            targets=targets,\n",
    "            topic=\"send_value\",\n",
    "            request=data,\n",
    "            timeout=10,\n",
    "            fl_ctx=fl_ctx,\n",
    "        )\n",
    "\n",
    "        # check if all neighbors sent their values\n",
    "        if len(self.neighbors_values[iteration]) < len(self.neighbors):\n",
    "            # if not, wait for them (up to self.sync_timeout seconds, defaults to 10)\n",
    "            if not self.sync_waiter.wait(timeout=self.sync_timeout):\n",
    "                self.system_panic(\"failed to receive values from all neighbors\", fl_ctx)\n",
    "                return\n",
    "\n",
    "    def _handle_neighbor_value(\n",
    "        self, topic: str, request: Shareable, fl_ctx: FLContext\n",
    "    ) -> Shareable:\n",
    "        # Retrieve the sender's identity from the request\n",
    "        sender = request.get_peer_prop(key=ReservedKey.IDENTITY_NAME, default=None)\n",
    "        data = from_shareable(request).data\n",
    "        iteration = data[\"iteration\"]\n",
    "\n",
    "        with self.lock:\n",
    "            # Store the received value\n",
    "            self.neighbors_values[iteration][sender] = self._from_message(data[\"value\"])\n",
    "            # Check if all neighbor values have been received\n",
    "            if len(self.neighbors_values[iteration]) >= len(self.neighbors):\n",
    "                self.sync_waiter.set()  # Signal that we have all neighbor values\n",
    "        return make_reply(ReturnCode.OK)\n",
    "\n",
    "    def handle_event(self, event_type: str, fl_ctx: FLContext):\n",
    "        if event_type == EventType.START_RUN:\n",
    "            engine = fl_ctx.get_engine()\n",
    "            # Register the message handler for receiving neighbor values\n",
    "            engine.register_aux_message_handler(\n",
    "                topic=\"send_value\", message_handle_func=self._handle_neighbor_value\n",
    "            )\n",
    "\n",
    "    def _to_message(self, x):\n",
    "        # Method to serialize the value for transmission\n",
    "        return x\n",
    "\n",
    "    def _from_message(self, x):\n",
    "        # Method to deserialize the received value\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "While this may look complex, it's actually quite straightforward with the knowledge we built up in previous sections.\n",
    "\n",
    "Let's break down the key components of this implementation:\n",
    "- Additional parameters:\n",
    "    - `sync_waiter` (threading.Event): An event that allows threads to wait until it is set. Used here to synchronize the execution of the algorithm, making clients wait until all neighbor values have been received.\n",
    "    - `lock` (threading.Lock): Ensures thread-safe access to shared data structures, such as neighbors_values.\n",
    "    - `neighbors_values`: A dictionary that stores received values from neighbors, organized by iteration.\n",
    "- `_exchange_values`: a custom method to handle the exchange of values with neighbors during each iteration. It follows the following process:\n",
    "    1. Clears the `sync_waiter` event to ensure we're starting fresh.\n",
    "    2. Sends an auxiliary request to each neighbor with the current value and iteration number.\n",
    "    3. Checks if all neighbor values have been received; if not, waits for `sync_waiter` to be set or times out after 10 seconds.\n",
    "    4. Handling Timeout: If the required neighbor values are not received within the timeout, the method calls `system_panic` to handle the error (usually logging and cleanup).\n",
    "- `_handle_neighbor_value`: a custom callback to handle incoming messages from neighbors containing their values. It works by:\n",
    "    1. Extracting the sender's identity and the data from the request.\n",
    "    2. Storing the received value in `neighbors_values` under the appropriate iteration.\n",
    "    3. Checking if all neighbor values for the iteration have been received; if so, sets `sync_waiter` to release any waiting threads.\n",
    "    4. Thread Safety: Uses a `lock` to ensure that the update to `neighbors_values` and the check is atomic.\n",
    "- `handle_event`: implement the `handle_event` of the base `Executor` to handle events sent by the engine. In this case. when `EventType.START_RUN` (i.e. when the run )starts, we register the auxiliary message handler for receiving neighbor values.\n",
    "- `_to_message` and `_from_message`: custom placeholder methods for serializing and deserializing the message content. In subclasses, you might need to override these methods to handle complex data structures or use specific serialization formats (e.g., converting tensors to and from bytes). You can see an example of this in the implementation of the [`GTExecutor`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/p2p/executors/gradient_tracking.py) which implements the Gradient Tracking algorithm in the `nvflare.app_opt.p2p` module.\n",
    "\n",
    "\n",
    "> Notice that `neighbors_values` needs to maintain a dictionary of received values per iteration. This is because, different parts of a network may be at different iterations of the algorithm (plus or minus 1 at most) - this means that I could receive a message from a neighbor valid for iteration `t+1` when I'm still at iteration `t`. Since that message won't be sent again, I need to store it. **To avoid the `neighbors_values` to grow indefinitely, we'll delete its content at iteration `t` after having consumed its values and moving to the next iteration in the algorithm**. This can be done by `del self.neighbors_values[iteration]` after we're done with an iteration.\n",
    "\n",
    "### Creating and running a custom P2P algorithm\n",
    "\n",
    "Now that we have a way to store the configuration and exchange messages with neighbors, we can implement the algorithmic part. For this `SyncAlgorithmExecutor`, we'll define an abstract `run_algorithm` method to be overridden by subclasses implementing specific algorithms.\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SyncAlgorithmExecutor(Executor, ABC):\n",
    "    ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def run_algorithm(\n",
    "        self, fl_ctx: FLContext, shareable: Shareable, abort_signal: Signal\n",
    "    ):\n",
    "        \"\"\"Executes the algorithm. Must be overridden by subclasses.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "        task_name: str,\n",
    "        shareable: Shareable,\n",
    "        fl_ctx: FLContext,\n",
    "        abort_signal: Signal,\n",
    "    ):\n",
    "        if task_name == \"config\":\n",
    "            # Receive topology from the server\n",
    "            self.config = LocalConfig(**from_shareable(shareable).data)\n",
    "            self.neighbors = self.config.neighbors\n",
    "            self._weight = 1.0 - sum([n.weight for n in self.neighbors])\n",
    "            return make_reply(ReturnCode.OK)\n",
    "\n",
    "        elif task_name == \"run_algorithm\":\n",
    "            # Run the algorithm\n",
    "            if abort_signal.triggered:\n",
    "                return make_reply(ReturnCode.TASK_ABORTED)\n",
    "\n",
    "            self.run_algorithm(fl_ctx, shareable, abort_signal)\n",
    "            return make_reply(ReturnCode.OK)\n",
    "\n",
    "        else:\n",
    "            self.log_warning(fl_ctx, f\"Unknown task name: {task_name}\")\n",
    "            return make_reply(ReturnCode.TASK_UNKNOWN)\n",
    "```\n",
    "\n",
    "The full implementation is in `nvflare/app_opt/p2p/executors/sync_executor.py` - note that the implementation of the `SyncAlgorithmExecutor` in `nvflare.app_opt.p2p` is a subclass of `BaseDistOptExecutor`, defined in `nvflare/app_opt/p2p/executors/base_dist_opt_executor.py`. It contains a few additional attributes (namely `self.id` and `self.client_name`) to identify the client, which are potentially useful in algorithms, and two additional methods `_pre_algorithm_run` and `_post_algorithm_run` to be overridden by each specific algorithm to execute some code before and after the algorithm execution, respectively.\n",
    "\n",
    "#### Example: Implementing the `ConsensusExecutor`\n",
    "\n",
    "Now that we have built the main foundation with `SyncAlgorithmExecutor`, we can implement specific algorithms by subclassing it. Let's implement the consensus algorithm in the `ConsensusExecutor`.\n",
    "\n",
    "##### Consensus Algorithm Overview\n",
    "The consensus algorithm allows clients to reach agreement on a certain value through iterative averaging with their neighbors. Each client updates its value based on its own value and the values received from its neighbors, weighted accordingly. In formulas, each client $i$ maintains some local value $x_i^t$ and is connected to a subset of the other clients in the network, defined as the set of its neighbors $\\mathcal{N}_i$.\n",
    "The goal of all the clients is to reach consensus on their local values by communicating with their peers for a certain number of iterations $T$. \n",
    "In other terms, they want to cooperatively compute a weighted average of their initial values $x_i^0$.\n",
    "\n",
    "The consensus algorithm works by having each client updating its local value as\n",
    "\n",
    "$$x_i^{t+1} = \\sum_{j\\in\\mathcal{N}_i}a_{ji}x_j^t$$\n",
    "\n",
    "where $a_{ji}$ is the weight associated by client $i$ to client $j$ and $\\sum_{j=1}^N a_{ji}=1$ for all $i$.\n",
    "\n",
    "#### Implemntation\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "class ConsensusExecutor(SyncAlgorithmExecutor):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_value: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if initial_value is None:\n",
    "            initial_value = random.random()\n",
    "        self.initial_value = initial_value\n",
    "        self.current_value = initial_value\n",
    "        self.value_history = [self.current_value]\n",
    "\n",
    "    def run_algorithm(self, fl_ctx, shareable, abort_signal):\n",
    "        iterations = from_shareable(shareable).data[\"iterations\"]\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            if abort_signal.triggered:\n",
    "                self.log_info(fl_ctx, \"Abort signal received. Exiting the algorithm loop.\")\n",
    "                break\n",
    "\n",
    "            # 1. Exchange values with neighbors\n",
    "            self._exchange_values(\n",
    "                fl_ctx, value=self.current_value, iteration=iteration\n",
    "            )\n",
    "\n",
    "            # 2. Compute new value\n",
    "            current_value = self.current_value * self._weight\n",
    "            for neighbor in self.neighbors:\n",
    "                neighbor_value = self.neighbors_values[iteration][neighbor.id]\n",
    "                current_value += neighbor_value * neighbor.weight\n",
    "\n",
    "            # 3. Store current value and history\n",
    "            self.current_value = current_value\n",
    "            self.value_history.append(self.current_value)\n",
    "\n",
    "            # 4. Free memory that's no longer needed\n",
    "            del self.neighbors_values[iteration]\n",
    "        \n",
    "        # save value_history\n",
    "        torch.save(torch.tensor(self.value_history), \"value_sequence.pt\")\n",
    "\n",
    "```\n",
    "\n",
    "Let's explain the key parts:\n",
    "\n",
    "- Initialization:\n",
    "    - Sets an initial random value if none is provided.\n",
    "    - Initializes `current_value` and `value_history` to keep track of the values over iterations.\n",
    "- `run_algorithm`:\n",
    "    - Retrieves the number of iterations from the shareable received.\n",
    "    - For each iteration:\n",
    "        1. Abort check: Checks if an abort signal has been triggered.\n",
    "        2. Exchange values: Calls `_exchange_values` to send and receive values with neighbors.\n",
    "        3. Compute new value by computing the weighted average of the current value and the received values from neighbors.\n",
    "        4. Update state (`current_value`) and store value in `value_history`\n",
    "        5. Cleanup: Deletes the neighbor values for the iteration to free up memory.\n",
    "    - We let each client save their `value_history` to disk at the end of the algorithm\n",
    "\n",
    "We can now run our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.job_config.api import FedJob\n",
    "from nvflare.app_opt.p2p.executors import ConsensusExecutor\n",
    "from nvflare.app_opt.p2p.controllers import DistOptController\n",
    "\n",
    "job = FedJob(name=\"consensus\")\n",
    "\n",
    "controller = DistOptController(config=config)\n",
    "job.to_server(controller)\n",
    "\n",
    "for i in range(3):\n",
    "    executor = ConsensusExecutor()\n",
    "    job.to(executor, f\"site-{i+1}\")\n",
    "\n",
    "# Run job via the NVFlare simulator\n",
    "job.export_job(\"./tmp/job_configs\")\n",
    "job.simulator_run(\"./tmp/runs/consensus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the saved values to see if the algorithm is working and the clients are reaching a consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib torch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load history\n",
    "history = {\n",
    "    f\"site-{i+1}\": torch.load(f\"tmp/runs/consensus/site-{i+1}/value_sequence.pt\") for i in range(3)\n",
    "}\n",
    "\n",
    "# plot results\n",
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.plot(history[f\"site-{i+1}\"], label=f\"site-{i+1}\")\n",
    "plt.legend()\n",
    "plt.title(\"Evolution of local values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Try to implement another P2P algorithms of your choice - for example the distributed gradient descent. \n",
    "2. What happens if you remove the synchronization?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
