{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1398ef0a-f189-4d04-a8a9-276a17ab0f8b",
   "metadata": {},
   "source": [
    "# Federated Learning with Differential Privacy for BraTS18 Segmentation\n",
    "\n",
    "Please make sure you set up virtual environment and follows [example root readme](../../README.md)\n",
    "\n",
    "## Introduction to MONAI, BraTS and Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f3c69-aeba-4cea-89c8-d54fd6520ab1",
   "metadata": {},
   "source": [
    "### MONAI\n",
    "This example shows how to use [NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html) on medical image applications.\n",
    "It uses [MONAI](https://github.com/Project-MONAI/MONAI),\n",
    "which is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of the PyTorch Ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b7e0b-9dbd-4d21-8b59-a3d08cf2b2bb",
   "metadata": {},
   "source": [
    "### BraTS\n",
    "The application shown in this example is volumetric (3D) segmentation of brain tumor subregions from multimodal MRIs based on BraTS 2018 data.\n",
    "It uses a deep network model published by [Myronenko 2018](https://arxiv.org/abs/1810.11654) [1].\n",
    "\n",
    "The model is trained to segment 3 nested subregions of primary brain tumors (gliomas): the \"enhancing tumor\" (ET), the \"tumor core\" (TC), the \"whole tumor\" (WT) based on 4 aligned input MRI scans (T1c, T1, T2, FLAIR). \n",
    "\n",
    "<img src=\"https://developer.download.nvidia.com/assets/Clara/Images/clara_pt_brain_mri_segmentation_workflow.png\" alt=\"clara_pt_brain_mri_segmentation_workflow\" width=\"600\"/>\\n\n",
    "\n",
    "- The ET is described by areas that show hyper intensity in T1c when compared to T1, but also when compared to \"healthy\" white matter in T1c. \n",
    "- The TC describes the bulk of the tumor, which is what is typically resected. The TC entails the ET, as well as the necrotic (fluid-filled) and the non-enhancing (solid) parts of the tumor. \n",
    "- The WT describes the complete extent of the disease, as it entails the TC and the peritumoral edema (ED), which is typically depicted by hyper-intense signal in FLAIR.\n",
    "\n",
    "To run this example, please make sure you have downloaded BraTS 2018 data, which can be obtained from [Multimodal Brain Tumor Segmentation Challenge (BraTS) 2018](https://www.med.upenn.edu/cbica/brats2018.html) [2-6]. Please download the data to [./dataset_brats18/dataset](./dataset_brats18/dataset). It should result in a sub-folder `./dataset_brats18/dataset/training`.\n",
    "In this example, we split BraTS18 dataset into [4 subsets](./dataset_brats18/datalist) for 4 clients. Each client requires at least a 12 GB GPU to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd90a1-fe96-4f24-b360-bbe73b24e34a",
   "metadata": {},
   "source": [
    "### Differential Privacy (DP)\n",
    "[Differential Privacy (DP)](https://arxiv.org/abs/1910.00962) [7] is method for ensuring that Federated Learning (FL) preserves privacy by obfuscating the model updates sent from clients to the central server.\n",
    "This example shows the usage of a MONAI-based trainer for medical image applications with NVFlare, as well as the usage of DP filters in your FL training. DP is added as a filter in `config_fed_client.json`. Here, we use the \"Sparse Vector Technique\", i.e. the [SVTPrivacy](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.filters.svt_privacy.html) protocol, as utilized in [Li et al. 2019](https://arxiv.org/abs/1910.00962) [7] (see [Lyu et al. 2016](https://arxiv.org/abs/1603.01699) [8] for more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33306153-a8c5-4c2b-9eea-28c3e0d705a6",
   "metadata": {},
   "source": [
    "## Prepare local configs\n",
    "First, we add the image and datalist directory roots to `config_train.json` files for generating the absolute path to the dataset by replacing the `DATASET_ROOT` and  `DATALIST_ROOT` placeholders. In the current folder structure, it will be `${PWD}/dataset_brats18/dataset` for `DATASET_ROOT` and  `${PWD}/dataset_brats18/datalist` for `DATALIST_ROOT` but you can update the below `sed` commands if the data is located somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8a7f47-2a93-4992-85c0-d597f4ecf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sed -i \"s|DATASET_ROOT|${PWD}/dataset_brats18/dataset|g\" config_train.json\n",
    "sed -i \"s|DATALIST_ROOT|${PWD}/dataset_brats18/datalist|g\" config_train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c692a-16dc-4ef9-a432-4b7375a2a7d6",
   "metadata": {},
   "source": [
    "## Run experiments with FL simulator\n",
    "### Training with FL simulator\n",
    "FL simulator is used to simulate FL experiments or debug codes, not for real FL deployment.\n",
    "In this example, we assume four local GPUs with at least 12GB of memory are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d256389-4112-46e6-86bd-115c9bf2e189",
   "metadata": {},
   "source": [
    "Then, we can run the FL simulator with 1 client for centralized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9583165-af58-45ed-a86d-9fbfc74d80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -u -m nvflare.private.fed.app.simulator.simulator './configs/brats_central' -w './workspace_brats/brats_central' -n 1 -t 1 -gpu 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1121bc2-1118-4b64-8d61-06e1a49bc7ef",
   "metadata": {},
   "source": [
    "Similarly, run the FL simulator with 4 clients for federated learning by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5fd7e-f911-4a04-81a6-312e43c832c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare simulator './configs/brats_fedavg' -w './workspace_brats/brats_fedavg' -n 4 -t 4 -gpu 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a3be9-9e58-44ca-9d3f-e85456de7f12",
   "metadata": {},
   "source": [
    "Run the FL simulator with 4 clients for federated learning with differential privacy by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f9065-129f-4e62-ac3d-a1504a3b30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare simulator './configs/brats_fedavg_dp' -w './workspace_brats/brats_fedavg_dp' -n 4 -t 4 -gpu 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118e9a1-85fc-4e5a-8b29-fb5f50a4f941",
   "metadata": {},
   "source": [
    "### Testing with FL simulator\n",
    "The best global models are stored at\n",
    "```\n",
    "workspace_brats/[job]/simulated_job/app_server/best_FL_global_model.pt\n",
    "```\n",
    "\n",
    "Please then add the correct paths to the testing script, and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926d179-4063-4f27-9815-b9e3f9569067",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./result_stat\n",
    "!bash testing_models_3d.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
