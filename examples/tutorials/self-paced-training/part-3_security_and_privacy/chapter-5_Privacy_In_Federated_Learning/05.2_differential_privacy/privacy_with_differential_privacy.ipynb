{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1398ef0a-f189-4d04-a8a9-276a17ab0f8b",
   "metadata": {},
   "source": [
    "# Federated Learning with Differential Privacy\n",
    "\n",
    "Please make sure you set up a virtual environment and follow [example root readme](../../README.md) before starting this notebook.\n",
    "Then, install the requirements.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Some of the cells below generate long text output.  We're using <pre>%%capture --no-display --no-stderr cell_output</pre> to suppress this output.  Comment or delete this line in the cells below to restore full output.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002e45c-f58e-4f68-bb5a-9626e084947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display --no-stderr cell_output\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd90a1-fe96-4f24-b360-bbe73b24e34a",
   "metadata": {},
   "source": [
    "### Differential Privacy (DP)\n",
    "[Differential Privacy (DP)](https://arxiv.org/abs/1910.00962) [7] is a rigorous mathematical framework designed to provide strong privacy guarantees when handling sensitive data. In the context of Federated Learning (FL), DP plays a crucial role in safeguarding user information by introducing randomness into the training process. Specifically, it ensures privacy by adding carefully calibrated noise to the model updates—such as gradients or weights—before they are transmitted from clients to the central server. This obfuscation mechanism makes it statistically difficult to infer whether any individual data point contributed to a particular update, thereby protecting user-specific information.\n",
    "\n",
    "By integrating DP into FL, even if an adversary gains access to the aggregated updates or models, the added noise prevents them from accurately deducing sensitive details about any individual client's data. Common approaches include \n",
    "\n",
    "1. **local differential privacy (LDP)**, where noise is added directly on the client side before updates are sent\n",
    "2. **global differential privacy (GDP)**, where noise is injected after aggregation at the server.\n",
    "\n",
    "The balance between privacy and model utility is typically managed through a privacy budget (ϵ), which quantifies the trade-off between the level of noise added and the resulting model accuracy.\n",
    "\n",
    "\n",
    "This example shows the usage of a CIFAR-10 training code with NVFlare, as well as the usage of **local** DP filters in your FL training. Here, we use the \"Sparse Vector Technique\", i.e. the [SVTPrivacy](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.filters.svt_privacy.html) protocol, as utilized in [Li et al. 2019](https://arxiv.org/abs/1910.00962) [1] (see [Lyu et al. 2016](https://arxiv.org/abs/1603.01699) [2] for more information). \n",
    "\n",
    "DP is added as a filter using the [FedJob API](https://nvflare.readthedocs.io/en/main/programming_guide/fed_job_api.html#fedjob-api) you should have seen in prior chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c692a-16dc-4ef9-a432-4b7375a2a7d6",
   "metadata": {},
   "source": [
    "## Run experiments with FL simulator\n",
    "FL simulator is used to simulate FL experiments or debug codes, not for real FL deployment.\n",
    "\n",
    "First, train a model using the FedAvg algorithm with four clients without DP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3fe64-3915-4c6a-9bed-694d205b0940",
   "metadata": {},
   "source": [
    "#### 0. Download the CIFAR-10 data\n",
    "First, we download the CIFAR-10 dataset to avoid clients overwriting each other's local dataset during this simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609d2de-d033-45a1-b9fa-1ba311bd00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "DATASET_PATH = \"/tmp/nvflare/data\"\n",
    "torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
    "torchvision.datasets.CIFAR10(root=DATASET_PATH, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b05b1b-31d6-4e9a-a07f-90cf9fba37b7",
   "metadata": {},
   "source": [
    "#### 1. Define a FedJob\n",
    "The `FedJob` is used to define how controllers and executors are placed within a federated job using the `to(object, target)` routine.\n",
    "\n",
    "Here we use a PyTorch `BaseFedJob`, where we can define the job name and the initial global model.\n",
    "The `BaseFedJob` automatically configures components for model persistence, model selection, and TensorBoard streaming for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b59f47-a0c5-4038-abf4-80aefc122c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.net import Net\n",
    "\n",
    "from nvflare.app_common.workflows.fedavg import FedAvg\n",
    "from nvflare.app_opt.pt.job_config.base_fed_job import BaseFedJob\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "job = BaseFedJob(\n",
    "    name=\"cifar10_fedavg\",\n",
    "    initial_model=Net(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00fbca-4c8a-4e3f-b258-0f0601291aa4",
   "metadata": {},
   "source": [
    "#### 2. Define the Controller Workflow\n",
    "Define the controller workflow and send it to the server. For simplicity, we will run the simulation only for a few round but you can increase it for the models to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283f379-8d85-4a9d-9723-1ca926e10405",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2\n",
    "\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=3,  # 30 rounds should converge\n",
    ")\n",
    "job.to(controller, \"server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d8cd1-a6c3-476a-bb7b-3603f434d509",
   "metadata": {},
   "source": [
    "That completes the components that need to be defined on the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a27daa-8d73-4bfb-9400-db9c33e24f7e",
   "metadata": {},
   "source": [
    "#### 3. Add clients\n",
    "Next, we can use the `ScriptRunner` and send it to each of the clients to run our training script.\n",
    "\n",
    "Note that our script could have additional input arguments, such as batch size or data path, but we don't use them here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bfa4b-307f-4880-abbc-6788abe0dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clients):\n",
    "    runner = ScriptRunner(\n",
    "        script=\"src/cifar10_fl.py\"\n",
    "    )\n",
    "    job.to(runner, f\"site-{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a13662-97bf-444b-bfcd-d70f67fc7e80",
   "metadata": {},
   "source": [
    "That's it!\n",
    "\n",
    "#### 4. Optionally export the job\n",
    "Now, we could export the job and submit it to a real NVFlare deployment using the [Admin client](https://nvflare.readthedocs.io/en/main/real_world_fl/operation.html) or [FLARE API](https://nvflare.readthedocs.io/en/main/real_world_fl/flare_api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e3d58-a5bc-44f2-997e-2f653b36739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.export_job(\"job_configs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5135c9-13c2-4e3c-8e53-4047bccf42ec",
   "metadata": {},
   "source": [
    "#### 5. Run FL Simulation\n",
    "Finally, we can run our FedJob in simulation using NVFlare's [simulator](https://nvflare.readthedocs.io/en/main/user_guide/nvflare_cli/fl_simulator.html) under the hood.\n",
    "\n",
    "The results will be saved in the specified `workdir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc6f36-4d0c-41ac-8540-32dac533043a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job.simulator_run(f\"/tmp/nvflare/{job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a3be9-9e58-44ca-9d3f-e85456de7f12",
   "metadata": {},
   "source": [
    "#### 6. Run FL Simulation with DP\n",
    "Run the FL simulator with two clients for federated learning with differential privacy. The key now is to add a filer to each client that applies DP before sending the model updates back to the server\n",
    "using the `job.to()` method.\n",
    "\n",
    "Let's create a new FedJob with the DP add through the [SVTPrivacy](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.filters.html#nvflare.app_common.filters.SVTPrivacy) Filter implementing the **sparse vector technique** for differential privacy [[2]](https://arxiv.org/abs/1603.01699).\n",
    "\n",
    "> **Note:** Use `filter_type=FilterType.TASK_RESULT` as we are adding the filter on top of the model updates after local training.\n",
    "> \n",
    "> Furthermore, this filter was developed for use with weight differences. So, we use `params_transfer_type=TransferType.DIFF` here when specifying the `ScriptRunner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e6fca-8098-4be4-8d75-6b5e7ab1869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare import FilterType\n",
    "from nvflare.client.config import TransferType\n",
    "from nvflare.app_common.filters import SVTPrivacy\n",
    "\n",
    "# Create BaseFedJob with the initial model\n",
    "job = BaseFedJob(\n",
    "  name=\"cifar10_fedavg_dp\",\n",
    "  initial_model=Net(),\n",
    ")\n",
    "\n",
    "# Define the controller and send to server\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=3,  # 100 rounds should converge\n",
    ")\n",
    "job.to_server(controller)\n",
    "\n",
    "# Add clients\n",
    "for i in range(n_clients):\n",
    "    runner = ScriptRunner(\n",
    "        script=\"src/cifar10_fl.py\",\n",
    "        params_transfer_type=TransferType.DIFF\n",
    "    )\n",
    "    job.to(runner, f\"site-{i+1}\")\n",
    "\n",
    "    # add privacy filter.\n",
    "    dp_filter = SVTPrivacy(fraction=0.9, epsilon=0.1, noise_var=0.1, gamma=1e-5)\n",
    "    job.to(dp_filter, f\"site-{i+1}\", tasks=[\"train\"], filter_type=FilterType.TASK_RESULT)\n",
    "\n",
    "# Optionally export the configuration\n",
    "job.export_job(\"job_configs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661c68e-6b7f-4215-93e3-d4fe55eb5e7e",
   "metadata": {},
   "source": [
    "Next, start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b911d-a171-49b1-ad2e-b0d73032110c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job.simulator_run(f\"/tmp/nvflare/{job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf57a13-842b-46e0-9032-69d3a03b3182",
   "metadata": {},
   "source": [
    "> **Note:** you can also try adding or combining the filters with other privacy filters or customize them. For example, use the [PercentilePrivacy](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.filters.html#nvflare.app_common.filters.PercentilePrivacy) filter based on Shokri and Shmatikov ([Privacy-preserving deep learning, CCS '15](https://dl.acm.org/doi/abs/10.1145/2810103.2813687)) or [ExcludeVars](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_common.filters.html#nvflare.app_common.filters.ExcludeVars) filter to exclude variables that shouldn't be shared with the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c423d-4784-4956-961f-e2ea1ef1b30e",
   "metadata": {},
   "source": [
    "### 7. Visualize the results\n",
    "You can plot the results by running `tensorboard --logdir /tmp/nvflare` in a new terminal. In this notebook, we only run for a few FL rounds for simplicity. If you uncomment the recommended number of in the FedAvg controller definitions of the cells, you can run the experiments until convergence. As one can observe, the model with DP takes more rounds to achieve a comparable training performance but has less risks of leaking private information compared to the model trained without DP. For more details, see [Li et al. 2019](https://arxiv.org/abs/1910.00962) [1].\n",
    "\n",
    "![TensorBoard Training curve of FedAvg without and with DP](tb_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9c232-e4ae-4c25-acd9-e0cbe756a423",
   "metadata": {},
   "source": [
    "#### References\n",
    "[1] Li, W., Milletarì, F., Xu, D., Rieke, N., Hancox, J., Zhu, W., Baust, M., Cheng, Y., Ourselin, S., Cardoso, M.J. and Feng, A., 2019, October. Privacy-preserving federated brain tumour segmentation. In International workshop on machine learning in medical imaging (pp. 133-141). Springer, Cham.\n",
    "\n",
    "[2] Lyu, M., Su, D., & Li, N. (2016). Understanding the sparse vector technique for differential privacy. arXiv preprint arXiv:1603.01699."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
