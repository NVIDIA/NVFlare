{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust-based Security\n",
    "\n",
    "Trust-based security refers to leveraging confidential computing's trusted execution environment (TEE) in federated learning: confidential federated AI.\n",
    "\n",
    "\n",
    "\n",
    "## Confidential Computing\n",
    "\n",
    "Confidential computing provides a physically isolated trusted execution environment (TEE) to secure the entire workload while data is in use. \n",
    "\n",
    "### Capabilities of Confidential Computing\n",
    "\n",
    "Confidential computing enhances data security and privacy by leveraging specialized hardware and technologies to protect sensitive computations and data in use. The key capabilities include:\n",
    "\n",
    "\n",
    "<img src=\"gpu_cc.png\" alt=\"NVIDIA Confidential Computing\" width=\"500\">\n",
    "\n",
    "* **Trusted Execution Environment (TEE)**\n",
    "    * Provides an isolated environment that ensures the confidentiality and integrity of applications and data during processing.\n",
    "    * Protects against unauthorized access, even from privileged software such as the operating system or hypervisor.\n",
    "\n",
    "* **Virtualization-Based Security (\"Lift & Shift\")**\n",
    "\n",
    "    * Enables applications to run in secure environments without requiring modifications or partitioning.\n",
    "    * Facilitates seamless migration of existing workloads to confidential computing platforms.\n",
    "\n",
    "* **Secure Transfer**\n",
    "    * Supports high-performance hardware acceleration for encryption of data during transfers between CPUs and GPUs.\n",
    "    * Ensures secure communication channels for sensitive data processing.\n",
    "\n",
    "* **Hardware Root of Trust**\n",
    "\n",
    "    * Establishes a secure foundation using authenticated firmware measurement and attestation mechanisms for hardware, including GPUs.\n",
    "    * Validates the integrity and authenticity of the system, ensuring it is operating in a trusted state.\n",
    "\n",
    "\n",
    "<img src=\"cc_tech_stack.png\" alt=\"Confidential Computing Tech Stack\" width=\"500\">\n",
    "\n",
    "## Computing Technology Stack\n",
    "\n",
    "There are multiple components to Confidential computing technology including hardware\n",
    "\n",
    "* Hardware: CPU (AMD SEV-SNP, Intel TDX, etc), GPU (H100, Blackwell) \n",
    "* Attestation Service -- verify if the hardware is trust-worthy\n",
    "* Virtualization:\n",
    "    * Confidential Virtual Machine (CVM)\n",
    "    * Confidential Container \n",
    "    * Kubernetes Pod with Kata container in kubernates (CoCo) \n",
    "\n",
    "* Key Broker Service -- The key broker service (KBS) is a server that facilitates remote attestation and secret delivery.\n",
    "  \n",
    "\n",
    "## Confidential Federated AI Use Cases\n",
    "\n",
    "Federated Training Workflow:\n",
    "Confidential Federated Learning (Confidential FL) enables secure and trustworthy training environments by incorporating Confidential Computing for trust verification at different stages of the training process. These use cases demonstrate how trust among participants is explicitly managed and protected.\n",
    "\n",
    "There are three typical use cases:\n",
    "\n",
    "* **Building Explicit Trust** -- explicitly verifies that participants are trustworthy at any time\n",
    "\n",
    "* **Secure Aggregation** -- ensures that model updates from clients are aggregated securely without exposing individual model weights or enabling reverse engineering of private data\n",
    "\n",
    "* **Model Theft Prevention** -- prevents unauthorized access or theft of the model during the training process\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Build Explicit Trust Among All Participants\n",
    "\n",
    "Trustworthiness Verification: At different stages of the training process, we explicitly check the trustworthiness of participants using Confidential Computing Attestation. The level of trust varies depending on the use case, and different trust models are applied based on the relationship between the clients and the FL server.\n",
    "\n",
    "### Secure Aggregation\n",
    "\n",
    "**Scenario**\n",
    "\n",
    "Clients trust their own infrastructure and training code, but do not trust the FL server. FL Client doesn’t trust FL server due to possible model inversion attack. Secure the server to make sure the attack is not possible\n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Only the FL server needs to be a Confidential Computing Node for secure aggregation. Client nodes do not need to be confidential, and the server’s trustworthiness is verified through self-attestation (server attests its own integrity).\n",
    "\n",
    "\n",
    "### Model Theft Prevention\n",
    "\n",
    "**Scenario**\n",
    "\n",
    "The model owner wants to ensure the model IP is protected during training.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "To prevent model theft, all nodes (both FL clients and the FL server) must be protected via Confidential Computing TEE. Model theft prevention aims to protect the intellectual property (IP) of a model throughout the federated learning process, ensuring that the global model is not shared among unauthorized participants. This process involves securing both the model and the training data during and after the training process to safeguard the model owner's rights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
