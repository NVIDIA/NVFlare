{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Security and Privacy in Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Chapter 3.1 Privacy in Federated Learning](./chapter-3.1_Privacy_In_Federated_Learning/03.1.0_introduction.ipynb)\n",
    "\n",
    "[Chapter 3.2 Security in Federated Computing System](chapter-3.2_Security_in_federated_compute_system/03.2.0_introduction.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated Learning (FL) has emerged as a groundbreaking approach to distributed machine learning, enabling collaborative model training without sharing raw data. This paradigm is particularly vital for sensitive domains like healthcare, finance, and smart cities, where data privacy is paramount. However, the distributed nature of FL introduces unique security and privacy challenges, such as safeguarding against data leakage, adversarial attacks, and ensuring the integrity of model updates. NVIDIA FLARE addresses these concerns by providing a robust, extensible framework designed for secure and privacy-preserving FL workflows. By incorporating advanced cryptographic techniques, secure aggregation protocols, and role-based access control, NVIDIA FLARE empowers organizations to harness the full potential of FL while mitigating risks associated with data and model vulnerabilities. This ensures that collaborative machine learning remains not only effective but also trustworthy.\n",
    "\n",
    "In this part, we will have two chapters with one focused on privacy and another focused on security. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
