{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa01e6ac",
   "metadata": {},
   "source": [
    "# Federated Protein Property Prediction with BioNeMo\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> This notebook was tested on a DGX with one A100 GPU with 80 GB memory and is compatible with BioNeMo Framework v2.5. To leverage additional or higher-performance GPUs, you can modify the configuration files and simulation script to accommodate multiple devices and increase thread utilization, respectively. To run with less memory consumption, you can reduce the micro-batch sizes in the `run_*.py` scripts.</div>\n",
    "\n",
    "This example shows how to fine-tune an ESM-2 finetuned model on a \"subcellular location prediction\" task.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> This notebook is designed to run inside the BioNeMo Framework Docker container. Follow these <a href =https://docs.nvidia.com/ai-enterprise/deployment/vmware/latest/docker.html>instructions</a> to set up your Docker environment and execute the following bash script before opening this notebook.</div>\n",
    "\n",
    "To set up your environment, simply run (outside this notebook):\n",
    "\n",
    "```bash\n",
    "./start_bionemo.sh\n",
    "```\n",
    "\n",
    "This script will automatically pull the [BioNeMo Docker container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/containers/bionemo-framework) (tested with version nvcr.io/nvidia/clara/bionemo-framework:2.5) and launch Jupyter Lab at http://hostname:8888. Open that URL in your browser and access this notebook.\n",
    "\n",
    "For detailed setup guidance, refer to the [BioNeMo User Guide](https://docs.nvidia.com/bionemo-framework/latest/user-guide/).\n",
    "\n",
    "Once you open this notebook, continue executing the cells below.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> Some cells below produce long outputs. To suppress them, we use:<br><br> <pre>%%capture --no-display --no-stderr cell_output</pre><br> Comment or remove this line to restore full output.</div>\n",
    "\n",
    "### Import and install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab20c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-display --no-stderr cell_output\n",
    "! pip install \"nvflare~=2.7.0rc\"\n",
    "! pip install biopython --no-dependencies\n",
    "\n",
    "import io\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8209f",
   "metadata": {},
   "source": [
    "## Subcellular location prediction with ESM2nv\n",
    "Here, we are interested in training a neural network to predict subcellular location from an embedding.\n",
    "\n",
    "The data we will be using comes from the paper [\"Light attention predicts protein location from the language of life\"](https://academic.oup.com/bioinformaticsadvances/article/1/1/vbab035/6432029) by St√§rk et al. In this paper, the authors developed a machine learning algorithm to predict the subcellular location of proteins from sequence through protein language models that are similar to those available in BioNeMo. Protein subcellular location refers to where the protein localizes in the cell; for example, a protein may be expressed in the Nucleus or in the Cytoplasm. Knowing where proteins localize can provide insights into the underlying mechanisms of cellular processes and help identify potential targets for drug development. The following image includes a few examples of subcellular locations in an animal cell:\n",
    "\n",
    "<img src=\"https://cdn.pixabay.com/photo/2012/05/07/14/58/cell-48542_1280.png\" alt=\"Subcellular locations\" width=\"500\"/>\n",
    "(Image freely available at https://pixabay.com/images/id-48542)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e9955-6384-488e-8a18-18d6908c9907",
   "metadata": {},
   "source": [
    "**Data Splitting**\n",
    "\n",
    "Here, we use a heterogeneous sampling with `alpha=1.0`. To speed up the runtime and reduce computational resources, we use the [ESM-2nv 8M](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/esm2nv8m) parameter model pretrained from BioNeMo.\n",
    "\n",
    "<img src=\"./figs/scl_alpha1.0.svg\" alt=\"Dirichlet sampling (alpha=10.0)\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cb529-bc04-4c9c-a09d-e28cde770116",
   "metadata": {},
   "source": [
    "### Data prep\n",
    "For our target input sequences, we will point to FASTA sequences in a benchmark dataset called Fitness Landscape Inference for Proteins (FLIP). FLIP encompasses experimental data across adeno-associated virus stability for gene therapy, protein domain B1 stability and immunoglobulin binding, and thermostability from multiple protein families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71746a94-51ad-40fc-b42d-bc7db41e48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example protein dataset location\n",
    "fasta_url= \"http://data.bioembeddings.com/public/FLIP/fasta/scl/mixed_soft.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72459a0b-1211-455f-95b1-d9cfae82f961",
   "metadata": {},
   "source": [
    "First, we define the source of example protein dataset with the FASTA sequences. This data follows the [biotrainer](https://github.com/sacdallago/biotrainer/blob/main/docs/data_standardization.md) standard, so it includes information about the class in the FASTA header, and the protein sequence. Here are two example sequences in this file:\n",
    "\n",
    "```\n",
    ">Sequence1 TARGET=Cell_membrane SET=train VALIDATION=False\n",
    "MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFEDQYTPTIEDFHRKVYNIHGDMYQLDILDTSGNHPFPAM\n",
    "RRLSILTGDVFILVFSLDSRESFDEVKRLQKQILEVKSCLKNKTKEAAELPMVICGNKNDHSELCRQVPAMEAELLVSGDENC\n",
    "AYFEVSAKKNTNVNEMFYVLFSMAKLPHEMSPALHHKISVQYGDAFHPRPFCMRRTKVAGAYGMVSPFARRPSVNSDLKYIKA\n",
    "KVLREGQARERDKCSIQ\n",
    ">Sequence4833 TARGET=Nucleus SET=train VALIDATION=False\n",
    "MARTKQTARKSTGGKAPRKQLATKAARKSAPATGGVKKPHRFRPGTVALREIRKYQKSTELLIRKLPFQRLVREIAQDFKTDL\n",
    "RFQSSAVAALQEAAEAYLVGLFEDTNLCAIHAKRVTIMPKDIQLARRIRGERA\n",
    "Note the following attributes in the FASTA header:\n",
    "```\n",
    "\n",
    "* `TARGET` attribute holds the subcellular location classification for the sequence, for instance Cell_membrane and Nucleus. This dataset includes a total of ten subcellelular location classes -- more on that below.\n",
    "* `SET` attribute defines whether the sequence should be used for training (train) or testing (test)\n",
    "* `VALIDATION` attribute defines whether the sequence should be used for validation (all sequences where this is True are also in set=train)\n",
    "\n",
    "### Downloading the protein sequences and subcellular location annotations\n",
    "In this step we download the FASTA file defined above and parse the sequences into a list of BioPython SeqRecord objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e0976-3871-4a62-b340-ed837b1cbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the FASTA file from FLIP: https://github.com/J-SNACKKB/FLIP/tree/main/splits/scl\n",
    "fasta_content = requests.get(fasta_url, headers={\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x86)'\n",
    "}).content.decode('utf-8')\n",
    "fasta_stream = io.StringIO(fasta_content)\n",
    "\n",
    "# Obtain a list of SeqRecords/proteins which contain sequence and attributes\n",
    "# from the FASTA header\n",
    "proteins = list(SeqIO.parse(fasta_stream, \"fasta\"))\n",
    "print(f\"Downloaded {len(proteins)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52351066-6251-431b-bd85-66128338ff05",
   "metadata": {},
   "source": [
    "### Data splitting\n",
    "Next, we prepare the data for simulating federated learning using `n_clients`. Note that a copy of the same test set is shared between the clients in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f597b1a-996c-457c-83c7-3b0ce88e43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from split_data import split\n",
    "\n",
    "n_clients = 3\n",
    "# limiting to the proteins with sequence length<512 for embedding queries\n",
    "MAX_SEQUENCE_LEN = 512\n",
    "seed=42\n",
    "data_root = \"/tmp/data/mixed_soft\"\n",
    "split_alpha = 1.0  # moderate label heterogeneity of alpha=1.0\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Extract meta data and split\n",
    "data = []\n",
    "for i, x in enumerate(proteins):\n",
    "        if len(str(x.seq)) > MAX_SEQUENCE_LEN:\n",
    "            continue\n",
    "            \n",
    "        entry = {key: value for key, value in re.findall(r\"([A-Z_]+)=(-?[A-z0-9]+[.0-9]*)\", x.description)}\n",
    "        entry[\"sequences\"] = str(x.seq)\n",
    "        entry[\"id\"] = str(i)\n",
    "        entry[\"labels\"] = entry[\"TARGET\"]\n",
    "       \n",
    "        data.append(entry)\n",
    "print(f\"Read {len(data)} valid sequences.\")\n",
    "               \n",
    "# Split the data and save for each client\n",
    "# Note, test_data is kept the same on each client and is not split\n",
    "# `concat=False` is used for SCL experiments (see ../downstream/scl)\n",
    "split(proteins=data, num_sites=n_clients, split_dir=data_root, alpha=split_alpha, concat=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad6d1a-37e6-46e4-92c0-00e6cf05548d",
   "metadata": {},
   "source": [
    "**Run training (local, & FL)**\n",
    "\n",
    "As usual, [run_sim_scl.py](./run_sim_scl.py) uses the Job API to configure our job.\n",
    "You can change the FL job that's going to be simulated by changing the arguments of the run script. You can choose which ESM2 model to download (8M or 650M parameters). The ESM2 finetuning arguments such as learning rate and others can be modified inside the script itself.\n",
    "\n",
    "First, let's check its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78f758-6614-4a7e-8894-a487a1224779",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_sim_scl.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054079f9-dabb-46ae-ad22-b0805bba822a",
   "metadata": {},
   "source": [
    "In this example, we use the `--encoder-frozen` option inside the `run_sim_scl.py` script. You can specify different base ESM2 models using the `--model` option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670cc6f",
   "metadata": {},
   "source": [
    "**1. Local training**\n",
    "\n",
    "To simulate local training, we use three clients, each running one round of training for several steps using the split datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be284eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each client will run on the same GPU.\n",
    "!python run_sim_scl.py --num_clients=3 --num_rounds=1 --local_steps=5000 --exp_name \"local\" --model \"8m\" --sim_gpus=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40ed12",
   "metadata": {},
   "source": [
    "**2. Federated training with FedAvg**\n",
    "\n",
    "To simulate federated training, we use four clients, running several rounds with FedAvg, each with a smaller number of local steps. The number of rounds and local steps matches the setting of the local training scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_sim_scl.py --num_clients=3 --num_rounds=10 --local_steps=500 --exp_name \"fedavg\" --model \"8m\" --sim_gpus=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4629f3",
   "metadata": {},
   "source": [
    "You can visualize the results in TensorBoard using `tensorboard --logdir /tmp/nvflare/bionemo/scl`. Note that for the FedAvg, you can display a continuous training curve streamed to the server by selecting a `server` subfolder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db113e8",
   "metadata": {},
   "source": [
    "#### Results with heterogeneous data sampling (alpha=1.0)\n",
    "|  Client   | Site-1  | Site-2 | Site-3 | Average    |\n",
    "|:---------:|:-------:|:------:|:------:|:----------:|\n",
    "| # Samples |  1844   | 2921   | 2151   | Accuracy   |\n",
    "| Local     |  0.7819 |\t0.7885 | 0.7921 | 0.7875     |\n",
    "| FedAvg    |  0.8179 |\t0.8131 | 0.8209 | **0.8173** |\n",
    "\n",
    "<img src=\"./figs/tb_curve_scl.png\" alt=\"SCL Training curve with Dirichlet sampling (alpha=1.0)\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbbfee4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we explored the application of federated learning to protein subcellular location prediction using NVIDIA's BioNeMo Framework. Here are the key takeaways:\n",
    "\n",
    "* We tackled the challenge of predicting protein subcellular locations from sequence data. In a similar faction, other crucial task for biopharma and drug development applications could be developed.\n",
    "\n",
    "* We compared both local and federated (FedAvg) training approaches with the ESM-2 8M parameter model from BioNeMo.\n",
    "\n",
    "**Key Learnings**:\n",
    "   - Federated learning can effectively improve protein property prediction\n",
    "   - Collaborative learning benefits all participating sites\n",
    "   - BioNeMo Framework provides powerful tools for biological sequence analysis\n",
    "\n",
    "This example demonstrates how federated learning can be applied to healthcare and life sciences applications, enabling collaborative model development while maintaining data privacy.\n",
    "\n",
    "In the next [section](../11.2.2_drug_discovery_amplify/finetuning_amplify.ipynb), we'll learn how to fine-tune AMPLIFY protein language model on multiple downstream tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
