{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Federated Learning for Medical Image Analysis\n",
        "\n",
        "This tutorial demonstrates how to use NVIDIA FLARE for medical image analysis applications. For local training on medical images, we will use **[MONAI](https://github.com/Project-MONAI/MONAI)**, a PyTorch-based framework for deep learning in medical imaging applications. We will work with two tasks:\n",
        "\n",
        "- **MedNIST Classification Task**: a 2D classification task on medical images, this dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
        "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
        "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest). The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
        "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
        "\n",
        "A 2D Densenet will be trained to classify each image into its corresponding classes, some example images are as below:\n",
        "![](./figs/MedNIST.png)\n",
        "\n",
        "- **Prostate Segmentation Task**: a 3D segmentation of the prostate in T2-weighted MRIs. For tutorial purpose, we will only illustrate the process with a few images from [**MSD Dataset**](http://medicaldecathlon.com/)), without downloading the full multi-source datasets. Please refer to [advanced example](../../../../advanced/prostate/README.md) for the full experiment.\n",
        "\n",
        "The [3D U-Net](https://arxiv.org/abs/1606.06650) model is trained to segment the whole prostate region (binary) in a T2-weighted MRI scan. \n",
        "\n",
        "![](./figs/Prostate3D.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Federated Learning Flow with MONAI \n",
        "\n",
        "In this example, the **server** uses the [`FedAvg`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/fedavg.py) controller, which performs the following steps:\n",
        "1. Initialize the global model. This is achieved through the method `load_model()`\n",
        "  from the base class\n",
        "  [`ModelController`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/workflows/model_controller.py#L292),\n",
        "  which relies on the\n",
        "  [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor). \n",
        "2. During each training round, the global model will be sent to the\n",
        "  list of participating clients to perform a training task. This is\n",
        "  done using the\n",
        "  [`send_model()`](https://github.com/NVIDIA/NVFlare/blob/d6827bca96d332adb3402ceceb4b67e876146067/nvflare/app_common/workflows/model_controller.py#L99)\n",
        "  method under the hood from the `ModelController` base class. Once\n",
        "  the clients finish their local training, results will be collected\n",
        "  and sent back to the server as an [`FLModel`](https://nvflare.readthedocs.io/en/main/programming_guide/fl_model.html#flmodel)s.\n",
        "3. Results sent by clients will be aggregated based on the\n",
        "  [`WeightedAggregationHelper`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/aggregators/weighted_aggregation_helper.py#L20),\n",
        "  which weighs the contribution from each client based on the number\n",
        "  of local training samples. The aggregated updates are\n",
        "  returned as a new `FLModel`.\n",
        "5. After getting the aggregated results, the global model is [updated](https://github.com/NVIDIA/NVFlare/blob/724140e7dc9081eca7a912a818817f89aadfef5d/nvflare/app_common/workflows/fedavg.py#L63).\n",
        "6. The last step is to save the updated global model, again through\n",
        "  the [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor).\n",
        "\n",
        "The **clients** implement the local training logic using NVFlare's [Client\n",
        "API](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type.html#client-api)\n",
        "[here](./code/monai_mednist_train.py). The Client API\n",
        "allows the user to add minimum `nvflare`-specific codes to turn a typical\n",
        "centralized training script to a federated client-side local training\n",
        "script.\n",
        "1. During local training, each client receives a copy of the global\n",
        "  model sent by the server using `flare.receive()` API. The received\n",
        "  global model is an instance of `FLModel`. Integration with MONAI Trainer will handle the local training and validation.\n",
        "2. A local validation is first performed, where validation metrics\n",
        "  (accuracy and precision) are streamed to server using the\n",
        "  [`SummaryWriter`](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.client.tracking.html#nvflare.client.tracking.SummaryWriter). The\n",
        "  streamed metrics can be loaded and visualized using [TensorBoard](https://www.tensorflow.org/tensorboard) or [MLflow](https://mlflow.org/).\n",
        "3. Then, each client performs local training as in the non-federated training [notebook](./monai_101.ipynb). At the end of each FL round, each client then sends the computed results (always in\n",
        "  `FLModel` format) to the server for aggregation, using the `flare.send()`\n",
        "  API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "First, let's set up our environment with necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install nibabel mlflow\n",
        "!pip install \"monai-weekly[ignite, tqdm]\"\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: MedNIST\n",
        "For MedNIST experiment, everything will be handled by MONAI, including data download, we let MONAI create temp folder and files. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MedNIST Training Script\n",
        "We can notice the part of MONAI code handling data, preprocessing, network definition, and training within the [local training code](./mednist_fedavg/app/custom/monai_mednist_train.py):\n",
        "\n",
        "- Data download:\n",
        "```\n",
        "root_dir = tempfile.mkdtemp()\n",
        "print(root_dir)\n",
        "dataset = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"training\", download=True)\n",
        "```\n",
        "- Preprocessing:\n",
        "```\n",
        "transform = Compose(\n",
        "    [\n",
        "        LoadImageD(keys=\"image\", image_only=True),\n",
        "        EnsureChannelFirstD(keys=\"image\"),\n",
        "        ScaleIntensityD(keys=\"image\"),\n",
        "    ]\n",
        ")\n",
        "```\n",
        "- Network definition:\n",
        "```\n",
        "model = densenet121(spatial_dims=2, in_channels=1, out_channels=6).to(DEVICE)\n",
        "```\n",
        "- Trainer definition:\n",
        "```\n",
        "trainer = SupervisedTrainer(\n",
        "        device=torch.device(DEVICE),\n",
        "        max_epochs=max_epochs,\n",
        "        train_data_loader=train_loader,\n",
        "        network=model,\n",
        "        optimizer=torch.optim.Adam(model.parameters(), lr=1e-5),\n",
        "        loss_function=torch.nn.CrossEntropyLoss(),\n",
        "        inferer=SimpleInferer(),\n",
        "        train_handlers=StatsHandler(),\n",
        "    )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use NVFlare JobAPI to run the federated experiments\n",
        "We use NVFlare [JobAPI](https://github.com/NVIDIA/NVFlare/blob/main/examples/advanced/job_api/pt/README.md) to run the FL training experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.densenet import DenseNet121\n",
        "\n",
        "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
        "from nvflare.job_config.script_runner import ScriptRunner\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    n_clients = 2\n",
        "    num_rounds = 5\n",
        "    train_script = \"src/monai_mednist_train.py\"\n",
        "\n",
        "    job = FedAvgJob(\n",
        "        name=\"mednist_fedavg\",\n",
        "        n_clients=n_clients,\n",
        "        num_rounds=num_rounds,\n",
        "        initial_model=DenseNet121(spatial_dims=2, in_channels=1, out_channels=6),\n",
        "    )\n",
        "\n",
        "    # Add clients\n",
        "    executor = ScriptRunner(script=train_script, script_args=\"\")\n",
        "    job.to_clients(executor)\n",
        "\n",
        "    job.export_job(\"/tmp/nvflare/jobs/\")\n",
        "    job.simulator_run(\"/tmp/nvflare/workspaces/mednist_fedavg\", n_clients=n_clients, gpu=\"0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training result visualization:\n",
        "Let's visualize training curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/nvflare/workspaces/mednist_fedavg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2 Prostate\n",
        "Second task is more practical - 3D segmentation.\n",
        "\n",
        "### Data download\n",
        "Let's first set up our directory structure and download the MSD_Prostate dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# Create necessary directories\n",
        "data_folder='/tmp/nvflare/datasets/MSD/Raw'\n",
        "os.makedirs(data_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gdown -O '/tmp/nvflare/datasets/MSD/Raw/Task05_Prostate.tar' \"1Ff7c21UksxyT4JfETjaarmuKEjdqe1-a&confirm=t\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar xf /tmp/nvflare/datasets/MSD/Raw/Task05_Prostate.tar -C /tmp/nvflare/datasets/MSD/Raw/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing\n",
        "Now let's first convert our data to the appropriate format. We'll use the provided conversion script to select the T2 channel and convert labels to binary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run conversion scripts\n",
        "!bash data_conversion.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Datalist Generation\n",
        "With the prepared data, let's then generate data splits. We'll use a 50 : 25 : 25 split for training : validation : testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data lists\n",
        "!bash datalists_gen.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at the datalist json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the content of the datalist json\n",
        "!cat /tmp/nvflare/datasets/MSD/datalist/site-1.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Federated Training\n",
        "\n",
        "Now that we have prepared our data, we can proceed to the federated training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.learners.supervised_monai_prostate_learner import SupervisedMonaiProstateLearner\n",
        "from src.unet import UNet\n",
        "\n",
        "from nvflare.app_common.executors.learner_executor import LearnerExecutor\n",
        "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    n_clients = 4\n",
        "    num_rounds = 3\n",
        "    train_script = \"src/monai_mednist_train.py\"\n",
        "\n",
        "    model = UNet(\n",
        "        spatial_dims=3,\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        channels=[16, 32, 64, 128, 256],\n",
        "        strides=[2, 2, 2, 2],\n",
        "        num_res_units=2,\n",
        "    )\n",
        "\n",
        "    job = FedAvgJob(name=\"prostate_fedavg\", n_clients=n_clients, num_rounds=num_rounds, initial_model=model)\n",
        "\n",
        "    # Add clients\n",
        "    learner = SupervisedMonaiProstateLearner(\n",
        "        train_config_filename=\"../custom/src/config/config_train.json\", aggregation_epochs=10\n",
        "    )\n",
        "    job.to_clients(learner, id=\"prostate-learner\")\n",
        "    executor = LearnerExecutor(learner_id=\"prostate-learner\")\n",
        "    job.to_clients(executor)\n",
        "    job.to_clients(\"src/config/config_train.json\")\n",
        "\n",
        "    job.export_job(\"/tmp/nvflare/jobs/\")\n",
        "    job.simulator_run(\"/tmp/nvflare/workspaces/prostate_fedavg\", n_clients=n_clients, gpu=\"0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For demonstration purpose, we only run 3 rounds, let's visualize training curves, increase in validation accuracy can be observed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/nvflare/workspaces/prostate_fedavg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's move on to [Drug Discovery with Federated Learning](../11.2_drug_discovery/11.2.0_introduction/drug_discovery_with_fl.ipynb), where we'll explore how FL can be applied to accelerate drug discovery and development processes."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
