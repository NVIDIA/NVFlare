{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning for Medical Image Analysis\n",
    "\n",
    "This tutorial demonstrates how to use NVIDIA FLARE for medical image analysis applications. For local training on medical images, we will use **[MONAI](https://github.com/Project-MONAI/MONAI)**, a PyTorch-based framework for deep learning in medical imaging applications. We will work with two tasks:\n",
    "\n",
    "- **MedNIST Classification Task**: a 2D classification task on medical images, this dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest). The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "A 2D Densenet will be trained to classify each image into its corresponding classes, some example images are as below:\n",
    "![](./figs/MedNIST.png)\n",
    "\n",
    "- **Prostate Segmentation Task**: a 3D segmentation of the prostate in T2-weighted MRIs. For tutorial purpose, we will only illustrate the process with a few images from [**MSD Dataset**](http://medicaldecathlon.com/)), without downloading the full multi-source datasets. Please refer to [advanced example](../../../../advanced/prostate/README.md) for the full experiment.\n",
    "\n",
    "The [3D U-Net](https://arxiv.org/abs/1606.06650) model is trained to segment the whole prostate region (binary) in a T2-weighted MRI scan. \n",
    "\n",
    "![](./figs/Prostate3D.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Federated Learning Flow with MONAI \n",
    "\n",
    "In this example, the **server** uses the [`FedAvg`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/fedavg.py) controller, which performs the following steps:\n",
    "1. Initialize the global model. This is achieved through the method `load_model()`\n",
    "  from the base class\n",
    "  [`ModelController`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/workflows/model_controller.py#L292),\n",
    "  which relies on the\n",
    "  [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor). \n",
    "2. During each training round, the global model will be sent to the\n",
    "  list of participating clients to perform a training task. This is\n",
    "  done using the\n",
    "  [`send_model()`](https://github.com/NVIDIA/NVFlare/blob/d6827bca96d332adb3402ceceb4b67e876146067/nvflare/app_common/workflows/model_controller.py#L99)\n",
    "  method under the hood from the `ModelController` base class. Once\n",
    "  the clients finish their local training, results will be collected\n",
    "  and sent back to the server as an [`FLModel`](https://nvflare.readthedocs.io/en/main/programming_guide/fl_model.html#flmodel)s.\n",
    "3. Results sent by clients will be aggregated based on the\n",
    "  [`WeightedAggregationHelper`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/aggregators/weighted_aggregation_helper.py#L20),\n",
    "  which weighs the contribution from each client based on the number\n",
    "  of local training samples. The aggregated updates are\n",
    "  returned as a new `FLModel`.\n",
    "5. After getting the aggregated results, the global model is [updated](https://github.com/NVIDIA/NVFlare/blob/724140e7dc9081eca7a912a818817f89aadfef5d/nvflare/app_common/workflows/fedavg.py#L63).\n",
    "6. The last step is to save the updated global model, again through\n",
    "  the [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor).\n",
    "\n",
    "The **clients** implement the local training logic using NVFlare's [Client\n",
    "API](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type.html#client-api)\n",
    "[here](./code/monai_mednist_train.py). The Client API\n",
    "allows the user to add minimum `nvflare`-specific codes to turn a typical\n",
    "centralized training script to a federated client-side local training\n",
    "script.\n",
    "1. During local training, each client receives a copy of the global\n",
    "  model sent by the server using `flare.receive()` API. The received\n",
    "  global model is an instance of `FLModel`. Integration with MONAI Trainer will handle the local training and validation.\n",
    "2. A local validation is first performed, where validation metrics\n",
    "  (accuracy and precision) are streamed to server using the\n",
    "  [`SummaryWriter`](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.client.tracking.html#nvflare.client.tracking.SummaryWriter). The\n",
    "  streamed metrics can be loaded and visualized using [TensorBoard](https://www.tensorflow.org/tensorboard) or [MLflow](https://mlflow.org/).\n",
    "3. Then, each client performs local training as in the non-federated training [notebook](./monai_101.ipynb). At the end of each FL round, each client then sends the computed results (always in\n",
    "  `FLModel` format) to the server for aggregation, using the `flare.send()`\n",
    "  API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's set up our environment with necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install nibabel mlflow\n",
    "!pip install \"monai-weekly[ignite, tqdm]\"\n",
    "!pip install --upgrade --no-cache-dir gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MedNIST\n",
    "For MedNIST experiment, everything will be handled by MONAI, including data download, we let MONAI create temp folder and files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MedNIST Training Script\n",
    "We can notice the part of MONAI code handling data, preprocessing, network definition, and training within the [local training code](./mednist_fedavg/app/custom/monai_mednist_train.py):\n",
    "\n",
    "- Data download:\n",
    "```\n",
    "root_dir = tempfile.mkdtemp()\n",
    "print(root_dir)\n",
    "dataset = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"training\", download=True)\n",
    "```\n",
    "- Preprocessing:\n",
    "```\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=\"image\", image_only=True),\n",
    "        EnsureChannelFirstD(keys=\"image\"),\n",
    "        ScaleIntensityD(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "- Network definition:\n",
    "```\n",
    "model = densenet121(spatial_dims=2, in_channels=1, out_channels=6).to(DEVICE)\n",
    "```\n",
    "- Trainer definition:\n",
    "```\n",
    "trainer = SupervisedTrainer(\n",
    "        device=torch.device(DEVICE),\n",
    "        max_epochs=max_epochs,\n",
    "        train_data_loader=train_loader,\n",
    "        network=model,\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=1e-5),\n",
    "        loss_function=torch.nn.CrossEntropyLoss(),\n",
    "        inferer=SimpleInferer(),\n",
    "        train_handlers=StatsHandler(),\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NVFlare JobAPI to run the federated experiments\n",
    "We use NVFlare [JobAPI](https://github.com/NVIDIA/NVFlare/blob/main/examples/advanced/job_api/pt/README.md) to run the FL training experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densenet import DenseNet121\n",
    "\n",
    "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_clients = 2\n",
    "    num_rounds = 5\n",
    "    train_script = \"src/monai_mednist_train.py\"\n",
    "\n",
    "    job = FedAvgJob(\n",
    "        name=\"mednist_fedavg\",\n",
    "        n_clients=n_clients,\n",
    "        num_rounds=num_rounds,\n",
    "        initial_model=DenseNet121(spatial_dims=2, in_channels=1, out_channels=6),\n",
    "    )\n",
    "\n",
    "    # Add clients\n",
    "    executor = ScriptRunner(script=train_script, script_args=\"\")\n",
    "    job.to_clients(executor)\n",
    "\n",
    "    job.export_job(\"/tmp/nvflare/jobs/\")\n",
    "    job.simulator_run(\"/tmp/nvflare/workspaces/mednist_fedavg\", n_clients=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result visualization:\n",
    "Let's visualize training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /tmp/nvflare/workspaces/mednist_fedavg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Prostate\n",
    "Second task is more practical - 3D segmentation.\n",
    "\n",
    "### Data download\n",
    "Let's first set up our directory structure and download the MSD_Prostate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create necessary directories\n",
    "data_folder='/tmp/nvflare/datasets/MSD/Raw'\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown -O '/tmp/nvflare/datasets/MSD/Raw/Task05_Prostate.tar' \"1Ff7c21UksxyT4JfETjaarmuKEjdqe1-a&confirm=t\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xf /tmp/nvflare/datasets/MSD/Raw/Task05_Prostate.tar -C /tmp/nvflare/datasets/MSD/Raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Now let's first convert our data to the appropriate format. We'll use the provided conversion script to select the T2 channel and convert labels to binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run conversion scripts\n",
    "!bash data_conversion.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datalist Generation\n",
    "With the prepared data, let's then generate data splits. We'll use a 50 : 25 : 25 split for training : validation : testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data lists\n",
    "!bash datalists_gen.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the datalist json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the content of the datalist json\n",
    "!cat /tmp/nvflare/datasets/MSD/datalist/site-1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Training\n",
    "\n",
    "Now that we have prepared our data, we can proceed to the federated training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.learners.supervised_monai_prostate_learner import SupervisedMonaiProstateLearner\n",
    "from src.unet import UNet\n",
    "\n",
    "from nvflare.app_common.executors.learner_executor import LearnerExecutor\n",
    "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_clients = 4\n",
    "    num_rounds = 3\n",
    "    train_script = \"src/monai_mednist_train.py\"\n",
    "\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=[16, 32, 64, 128, 256],\n",
    "        strides=[2, 2, 2, 2],\n",
    "        num_res_units=2,\n",
    "    )\n",
    "\n",
    "    job = FedAvgJob(name=\"prostate_fedavg\", n_clients=n_clients, num_rounds=num_rounds, initial_model=model)\n",
    "\n",
    "    # Add clients\n",
    "    learner = SupervisedMonaiProstateLearner(\n",
    "        train_config_filename=\"../custom/src/config/config_train.json\", aggregation_epochs=10\n",
    "    )\n",
    "    job.to_clients(learner, id=\"prostate-learner\")\n",
    "    executor = LearnerExecutor(learner_id=\"prostate-learner\")\n",
    "    job.to_clients(executor)\n",
    "    job.to_clients(\"src/config/config_train.json\")\n",
    "\n",
    "    job.export_job(\"/tmp/nvflare/jobs/\")\n",
    "    job.simulator_run(\"/tmp/nvflare/workspaces/prostate_fedavg\", n_clients=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demostration purpose, we only run 3 rounds, let's visualize training curves, increase in validation accuracy can be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /tmp/nvflare/workspaces/prostate_fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
