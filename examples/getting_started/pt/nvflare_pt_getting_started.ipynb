{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c3d67-a6ea-4f59-84d2-effc3ef016e1",
   "metadata": {},
   "source": [
    "# Getting Started with NVFlare (PyTorch)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/NVFlare/blob/main/examples/getting_started/pt/nvflare_pt_getting_started.ipynb)\n",
    "\n",
    "NVFlare is an open-source framework that allows researchers and\n",
    "data scientists to seamlessly move their machine learning and deep\n",
    "learning workflows into a federated paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2b4a8-ed42-421d-8898-c0c93f9d8a09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Concepts\n",
    "At the heart of NVFlare lies the concept of collaboration through\n",
    "\"tasks.\" An FL controller assigns tasks (e.g., training on local data) to one or more FL clients, processes returned\n",
    "results (e.g., model weight updates), and may assign additional\n",
    "tasks based on these results and other factors (e.g., a pre-configured\n",
    "number of training rounds). The clients run executors which can listen for tasks and perform the necessary computations locally, such as model training. This task-based interaction repeats\n",
    "until the experimentâ€™s objectives are met. \n",
    "\n",
    "<img src=\"../../../docs/resources/controller_executor_no_filter.png\" alt=\"NVIDIA FLARE Controller and Executor\" width=75% height=75% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907933a8-20fd-4aa7-a3bf-3f5b5829a544",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5496ffe",
   "metadata": {},
   "source": [
    "Install nvflare and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bba668-72ac-4e69-aaed-8d4254f547c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --ignore-installed blinker\n",
    "! pip install nvflare~=2.5.0rc torch torchvision tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa517fe",
   "metadata": {},
   "source": [
    "If running in Google Colab, download the source code for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c139be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! npx degit NVIDIA/NVFlare/examples/getting_started/pt/src src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68cb248-dc6a-48d1-880d-33c4324d9723",
   "metadata": {},
   "source": [
    "## Federated Averaging with NVFlare\n",
    "Given the flexible controller and executor concepts, it is easy to implement different computing & communication patterns with NVFlare, such as [FedAvg](https://proceedings.mlr.press/v54/mcmahan17a?ref=https://githubhelp.com) and [cyclic weight transfer](https://academic.oup.com/jamia/article/25/8/945/4956468). \n",
    "\n",
    "The controller's `run()` routine is responsible for assigning tasks and processing task results from the Executors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f84fb1-9dd3-4c72-a727-c4614260f02f",
   "metadata": {},
   "source": [
    "### Server Code\n",
    "First, we provide a simple implementation of the [FedAvg](https://proceedings.mlr.press/v54/mcmahan17a?ref=https://githubhelp.com) algorithm with NVFlare. \n",
    "The `run()` routine implements the main algorithmic logic. \n",
    "Subroutines, like `sample_clients()` and `scatter_and_gather_model()` utilize the communicator object, native to each Controller to get the list of available clients,\n",
    "distribute the current global model to the clients, and collect their results.\n",
    "\n",
    "The FedAvg controller implements these main steps:\n",
    "1. FL server initializes an initial model using `self.load_model()`.\n",
    "2. For each round (global iteration):\n",
    "    - FL server samples available clients using `self.sample_clients()`.\n",
    "    - FL server sends the global model to clients and waits for their updates using `self.send_model_and_wait()`.\n",
    "    - FL server aggregates all the `results` and produces a new global model using `self.update_model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a13d5-1130-44e6-8818-70e30de401e6",
   "metadata": {},
   "source": [
    "```python\n",
    "class FedAvg(BaseFedAvg):\n",
    "    def run(self) -> None:\n",
    "        self.info(\"Start FedAvg.\")\n",
    "\n",
    "        model = self.load_model()\n",
    "        model.start_round = self.start_round\n",
    "        model.total_rounds = self.num_rounds\n",
    "\n",
    "        for self.current_round in range(self.start_round, self.start_round + self.num_rounds):\n",
    "            self.info(f\"Round {self.current_round} started.\")\n",
    "            model.current_round = self.current_round\n",
    "\n",
    "            clients = self.sample_clients(self.num_clients)\n",
    "\n",
    "            results = self.send_model_and_wait(targets=clients, data=model)\n",
    "\n",
    "            aggregate_results = self.aggregate(results)\n",
    "\n",
    "            model = self.update_model(model, aggregate_results)\n",
    "\n",
    "            self.save_model(model)\n",
    "\n",
    "        self.info(\"Finished FedAvg.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b6476-089a-4e9d-825b-07107bd5d84a",
   "metadata": {},
   "source": [
    "### Client Code \n",
    "We take a CIFAR-10 example directly from [PyTorch website](https://github.com/pytorch/tutorials/blob/main/beginner_source/blitz/cifar10_tutorial.py) with some minor modifications, such as removing comments, move the network to [src/net.py](src/net.py), and add a main method and GPU support. The original code can be found at [cifar10_original.py](../../hello-world/ml-to-fl/pt/code/cifar10_original.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c551053-5460-4d83-8578-796074170342",
   "metadata": {},
   "source": [
    "Now, we need to adapt this centralized training code to something that can run in a federated setting.\n",
    "\n",
    "On the client side, the training workflow is as follows:\n",
    "1. Receive the model from the FL server.\n",
    "2. Perform local training on the received global model\n",
    "and/or evaluate the received global model for model\n",
    "selection.\n",
    "3. Send the new model back to the FL server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bfc2a-783c-494f-9427-c38f40a2e870",
   "metadata": {},
   "source": [
    "Using NVFlare's client API, we can easily adapt machine learning code that was written for centralized training and apply it in a federated scenario.\n",
    "For a general use case, there are three essential methods to achieve this using the Client API :\n",
    "- `init()`: Initializes NVFlare Client API environment.\n",
    "- `receive()`: Receives model from the FL server.\n",
    "- `send()`: Sends the model to the FL server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ee07-d848-4a7c-99ad-64e20ab7093c",
   "metadata": {},
   "source": [
    "With these simple methods, the developers can use the Client API\n",
    "to change their centralized training code to an FL scenario with\n",
    "five lines of code changes as shown below.\n",
    "```python\n",
    "    import nvflare.client as flare\n",
    "    \n",
    "    flare.init() # 1. Initializes NVFlare Client API environment.\n",
    "    input_model = flare.receive() # 2. Receives model from the FL server.\n",
    "    params = input_model.params # 3. Obtain the required information from the received model.\n",
    "    \n",
    "    # original local training code\n",
    "    new_params = local_train(params)\n",
    "    \n",
    "    output_model = flare.FLModel(params=new_params) # 4. Put the results in a new `FLModel`\n",
    "    flare.send(output_model) # 5. Sends the model to the FL server.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432f44-4144-4347-8d74-e7f57e065a14",
   "metadata": {},
   "source": [
    "The full client training script is saved in a separate file, e.g. [./src/cifar10_fl.py](./src/cifar10_fl.py) doing CNN training on the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da34414-bac4-4352-8077-ab7ade998eec",
   "metadata": {},
   "source": [
    "## Run an NVFlare Job\n",
    "Now that we have defined the FedAvg controller to run our federated compute workflow on the FL server, and our client training script to receive the global models, run local training, and send the results back to the FL server, we can put everything together using NVFlare's Job API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedaf75-3a4a-4843-8017-7716b53149a2",
   "metadata": {},
   "source": [
    "#### 1. Define the initial model\n",
    "First, we define the global model used to initialize the model on the FL server. See [src/net.py](src/net.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93889e62-b725-427c-8839-2771ca81d24c",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70da5d-ba8b-4e65-b47f-44bb9bddae4d",
   "metadata": {},
   "source": [
    "#### 2. Define a FedJob\n",
    "The `FedJob` is used to define how controllers and executors are placed within a federated job using the `to(object, target)` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13771bfb-901f-485a-9a23-84db1ccd5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare import FedJob\n",
    "from nvflare.app_common.executors.script_executor import ScriptExecutor\n",
    "from nvflare.app_common.workflows.fedavg import FedAvg\n",
    "\n",
    "job = FedJob(name=\"cifar10_fedavg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361d9f8-54f3-4363-b3ba-706a7ae3a8e9",
   "metadata": {},
   "source": [
    "#### 3. Define the Controller Workflow\n",
    "Define the controller workflow and send to server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6962e6cc-995e-4356-8156-3ceba2c7a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2\n",
    "\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=2,\n",
    ")\n",
    "job.to(controller, \"server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63ce0c-ad3e-4434-b2a8-c8f2a4c2e7a5",
   "metadata": {},
   "source": [
    "#### 4. Create Global Model\n",
    "Now, we create the initial global model and send to server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2c514c-7758-4d30-bb5c-ae3c63be50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.net import Net\n",
    "from nvflare.job_config.pt.model import PTModel\n",
    "\n",
    "job.to(PTModel(Net()), \"server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5bc7f-4fb4-46e9-8f02-5e7245d95070",
   "metadata": {},
   "source": [
    "That completes the components that need to be defined on the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548966c2-90bf-47ad-91d2-5c6c22c3c4f0",
   "metadata": {},
   "source": [
    "#### 5. Add clients\n",
    "Next, we can use the `ScriptExecutor` and send it to each of the clients to run our training script.\n",
    "\n",
    "Note that our script could have additional input arguments, such as batch size or data path, but we don't use them here for simplicity.\n",
    "We can also specify, which GPU should be used to run this client, which is helpful for simulated environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad5d36fe-9ae5-43c3-80bc-2cdc66bf7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_clients):\n",
    "    executor = ScriptExecutor(\n",
    "        task_script_path=\"src/cifar10_fl.py\", task_script_args=\"\"  # f\"--batch_size 32 --data_path /tmp/data/site-{i}\"\n",
    "    )\n",
    "    job.to(executor, f\"site-{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113fd6af-85be-4f75-8a8e-4666771252b3",
   "metadata": {},
   "source": [
    "That's it!\n",
    "\n",
    "#### 6. Optionally export the job\n",
    "Now, we could export the job and submit it to a real NVFlare deployment using the [Admin client](https://nvflare.readthedocs.io/en/main/real_world_fl/operation.html) or [FLARE API](https://nvflare.readthedocs.io/en/main/real_world_fl/flare_api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a270bf-c906-425b-b999-2306cb76eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3f0a8-06bb-4bea-89d3-4a5fc5b76c63",
   "metadata": {},
   "source": [
    "#### 7. Run FL Simulation\n",
    "Finally, we can run our FedJob in simulation using NVFlare's [simulator](https://nvflare.readthedocs.io/en/main/user_guide/nvflare_cli/fl_simulator.html) under the hood. The results will be saved in the specified `workdir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13068ab7-35cf-49e7-91ed-10993049ef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:29:21,325 - SimulatorRunner - INFO - When running with multi GPU, each GPU group will run with only 1 thread. Set the Threads to 1.\n",
      "2024-08-16 12:29:21,327 - SimulatorRunner - INFO - Create the Simulator Server.\n",
      "2024-08-16 12:29:21,329 - CoreCell - INFO - server: creating listener on tcp://0:34219\n",
      "2024-08-16 12:29:21,338 - CoreCell - INFO - server: created backbone external listener for tcp://0:34219\n",
      "2024-08-16 12:29:21,339 - ConnectorManager - INFO - 27586: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}\n",
      "2024-08-16 12:29:21,340 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:26151] is starting\n",
      "2024-08-16 12:29:21,841 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:26151\n",
      "2024-08-16 12:29:21,842 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE tcp://0:34219] is starting\n",
      "2024-08-16 12:29:21,908 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 50775\n",
      "2024-08-16 12:29:21,908 - SimulatorRunner - INFO - Deploy the Apps.\n",
      "2024-08-16 12:29:21,914 - SimulatorRunner - INFO - Create the simulate clients.\n",
      "2024-08-16 12:29:21,920 - ClientManager - INFO - Client: New client site-1@192.168.86.31 joined. Sent token: 530696e3-3924-4486-8808-fce1b242f3db.  Total clients: 1\n",
      "2024-08-16 12:29:21,921 - FederatedClient - INFO - Successfully registered client:site-1 for project simulator_server. Token:530696e3-3924-4486-8808-fce1b242f3db SSID:\n",
      "2024-08-16 12:29:21,923 - ClientManager - INFO - Client: New client site-2@192.168.86.31 joined. Sent token: 11c59cad-e85b-4807-a3dc-b0b37b56520f.  Total clients: 2\n",
      "2024-08-16 12:29:21,923 - FederatedClient - INFO - Successfully registered client:site-2 for project simulator_server. Token:11c59cad-e85b-4807-a3dc-b0b37b56520f SSID:\n",
      "2024-08-16 12:29:21,924 - SimulatorRunner - INFO - Set the client status ready.\n",
      "2024-08-16 12:29:21,924 - SimulatorRunner - INFO - Deploy and start the Server App.\n",
      "2024-08-16 12:29:21,925 - Cell - INFO - Register blob CB for channel='server_command', topic='*'\n",
      "2024-08-16 12:29:21,926 - Cell - INFO - Register blob CB for channel='aux_communication', topic='*'\n",
      "2024-08-16 12:29:21,926 - ServerCommandAgent - INFO - ServerCommandAgent cell register_request_cb: server.simulate_job\n",
      "2024-08-16 12:29:23,514 - IntimeModelSelector - INFO - model selection weights control: {}\n",
      "2024-08-16 12:29:23,517 - AuxRunner - INFO - registered aux handler for topic __sync_runner__\n",
      "2024-08-16 12:29:23,518 - AuxRunner - INFO - registered aux handler for topic __job_heartbeat__\n",
      "2024-08-16 12:29:23,519 - AuxRunner - INFO - registered aux handler for topic __task_check__\n",
      "2024-08-16 12:29:23,520 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REQUEST\n",
      "2024-08-16 12:29:23,521 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REPLY\n",
      "2024-08-16 12:29:23,521 - ReliableMessage - INFO - enabled reliable message: max_request_workers=20 query_interval=2.0\n",
      "2024-08-16 12:29:23,522 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: Server runner starting ...\n",
      "2024-08-16 12:29:23,523 - AuxRunner - INFO - registered aux handler for topic fed.event\n",
      "2024-08-16 12:29:23,523 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job]: starting workflow controller (<class 'nvflare.app_common.workflows.fedavg.FedAvg'>) ...\n",
      "2024-08-16 12:29:23,524 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Initializing BaseModelController workflow.\n",
      "2024-08-16 12:29:23,524 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Workflow controller (<class 'nvflare.app_common.workflows.fedavg.FedAvg'>) started\n",
      "2024-08-16 12:29:23,525 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Beginning model controller run.\n",
      "2024-08-16 12:29:23,525 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Start FedAvg.\n",
      "2024-08-16 12:29:23,526 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: loading initial model from persistor\n",
      "2024-08-16 12:29:23,526 - PTFileModelPersistor - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Both source_ckpt_file_full_name and ckpt_preload_path are not provided. Using the default model weights initialized on the persistor side.\n",
      "2024-08-16 12:29:23,527 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Round 0 started.\n",
      "2024-08-16 12:29:23,528 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Sampled clients: ['site-1', 'site-2']\n",
      "2024-08-16 12:29:23,528 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Sending task train to ['site-1', 'site-2']\n",
      "2024-08-16 12:29:23,529 - WFCommServer - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: scheduled task train\n",
      "2024-08-16 12:29:23,927 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2024-08-16 12:29:23,928 - SimulatorClientRunner - INFO - Start the clients run simulation.\n",
      "2024-08-16 12:29:24,931 - SimulatorClientRunner - INFO - Simulate Run client: site-1 on GPU group: 0\n",
      "2024-08-16 12:29:24,932 - SimulatorClientRunner - INFO - Simulate Run client: site-2 on GPU group: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:29:26.813808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-16 12:29:26.847750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:29:28,017 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00005 127.0.0.1:34219 <= 127.0.0.1:50372] is created: PID: 27586\n",
      "2024-08-16 12:29:28,030 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00006 127.0.0.1:34219 <= 127.0.0.1:50382] is created: PID: 27586\n",
      "2024-08-16 12:29:27,967 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2024-08-16 12:29:27,981 - ClientTaskWorker - INFO - ClientTaskWorker started to run\n",
      "2024-08-16 12:29:28,016 - CoreCell - INFO - site-1.simulate_job: created backbone external connector to tcp://localhost:34219\n",
      "2024-08-16 12:29:28,016 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:34219] is starting\n",
      "2024-08-16 12:29:28,017 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 127.0.0.1:50372 => 127.0.0.1:34219] is created: PID: 27698\n",
      "2024-08-16 12:29:28,029 - CoreCell - INFO - site-2.simulate_job: created backbone external connector to tcp://localhost:34219\n",
      "2024-08-16 12:29:28,029 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:34219] is starting\n",
      "2024-08-16 12:29:28,030 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 127.0.0.1:50382 => 127.0.0.1:34219] is created: PID: 27699\n",
      "2024-08-16 12:29:29,828 - AuxRunner - INFO - registered aux handler for topic __end_run__\n",
      "2024-08-16 12:29:29,828 - AuxRunner - INFO - registered aux handler for topic __do_task__\n",
      "2024-08-16 12:29:29,828 - Cell - INFO - Register blob CB for channel='aux_communication', topic='*'\n",
      "2024-08-16 12:29:29,848 - AuxRunner - INFO - registered aux handler for topic __end_run__\n",
      "2024-08-16 12:29:29,848 - AuxRunner - INFO - registered aux handler for topic __do_task__\n",
      "2024-08-16 12:29:29,849 - Cell - INFO - Register blob CB for channel='aux_communication', topic='*'\n",
      "2024-08-16 12:29:30,346 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: assigned task to client site-1: name=train, id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:29:30,347 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: sent task assignment to client. client_name:site-1 task_id:c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:29:30,348 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: train   task_id: c2ea9c72-12a7-4c56-bdac-7dfc83524f20  sharable_header_task_id: c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:29:30,365 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: assigned task to client site-2: name=train, id=8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:29:30,366 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: sent task assignment to client. client_name:site-2 task_id:8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:29:30,366 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: train   task_id: 8e246740-698d-406e-8cab-9f91a762db52  sharable_header_task_id: 8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:29:30,338 - Cell - INFO - broadcast: channel='aux_communication', topic='__sync_runner__', targets=['server.simulate_job'], timeout=2.0\n",
      "2024-08-16 12:29:30,343 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: synced to Server Runner in 0.5059611797332764 seconds\n",
      "2024-08-16 12:29:30,343 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REQUEST\n",
      "2024-08-16 12:29:30,343 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REPLY\n",
      "2024-08-16 12:29:30,343 - ReliableMessage - INFO - enabled reliable message: max_request_workers=20 query_interval=2.0\n",
      "2024-08-16 12:29:30,344 - TaskScriptRunner - INFO - start task run() with full path: /tmp/nvflare/jobs/workdir/site-1/simulate_job/app_site-1/custom/src/cifar10_fl.py\n",
      "2024-08-16 12:29:30,344 - AuxRunner - INFO - registered aux handler for topic fed.event\n",
      "2024-08-16 12:29:30,344 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: client runner started\n",
      "2024-08-16 12:29:30,344 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-1\n",
      "2024-08-16 12:29:30,358 - Cell - INFO - broadcast: channel='aux_communication', topic='__sync_runner__', targets=['server.simulate_job'], timeout=2.0\n",
      "2024-08-16 12:29:30,361 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: synced to Server Runner in 0.5038559436798096 seconds\n",
      "2024-08-16 12:29:30,362 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REQUEST\n",
      "2024-08-16 12:29:30,362 - AuxRunner - INFO - registered aux handler for topic RM.RELIABLE_REPLY\n",
      "2024-08-16 12:29:30,362 - ReliableMessage - INFO - enabled reliable message: max_request_workers=20 query_interval=2.0\n",
      "2024-08-16 12:29:30,362 - TaskScriptRunner - INFO - start task run() with full path: /tmp/nvflare/jobs/workdir/site-2/simulate_job/app_site-2/custom/src/cifar10_fl.py\n",
      "2024-08-16 12:29:30,362 - AuxRunner - INFO - registered aux handler for topic fed.event\n",
      "2024-08-16 12:29:30,362 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: client runner started\n",
      "2024-08-16 12:29:30,362 - ClientTaskWorker - INFO - Initialize ClientRunner for client: site-2\n",
      "2024-08-16 12:29:30,393 - Communicator - INFO - Received from simulator_server server. getTask: train size: 251.5KB (251471 Bytes) time: 0.049074 seconds\n",
      "2024-08-16 12:29:30,394 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2024-08-16 12:29:30,394 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:29:30,394 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: invoking task executor ScriptExecutor\n",
      "2024-08-16 12:29:30,394 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: execute for task (train)\n",
      "2024-08-16 12:29:30,394 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: send data to peer\n",
      "2024-08-16 12:29:30,394 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: sending payload to peer\n",
      "2024-08-16 12:29:30,394 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: Waiting for result from peer\n",
      "2024-08-16 12:29:30,412 - Communicator - INFO - Received from simulator_server server. getTask: train size: 251.5KB (251471 Bytes) time: 0.049131 seconds\n",
      "2024-08-16 12:29:30,412 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2024-08-16 12:29:30,412 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:29:30,412 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: invoking task executor ScriptExecutor\n",
      "2024-08-16 12:29:30,413 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: execute for task (train)\n",
      "2024-08-16 12:29:30,413 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: send data to peer\n",
      "2024-08-16 12:29:30,413 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: sending payload to peer\n",
      "2024-08-16 12:29:30,413 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: Waiting for result from peer\n",
      "2024-08-16 12:29:30,570 - nvflare.app_common.executors.task_script_runner - INFO - Files already downloaded and verified\n",
      "2024-08-16 12:29:30,591 - nvflare.app_common.executors.task_script_runner - INFO - Files already downloaded and verified\n",
      "2024-08-16 12:29:31,221 - nvflare.app_common.executors.task_script_runner - INFO - Files already downloaded and verified\n",
      "2024-08-16 12:29:31,243 - nvflare.app_common.executors.task_script_runner - INFO - Files already downloaded and verified\n",
      "2024-08-16 12:29:31,446 - nvflare.app_common.executors.task_script_runner - INFO - current_round=0\n",
      "2024-08-16 12:29:31,471 - nvflare.app_common.executors.task_script_runner - INFO - current_round=0\n",
      "2024-08-16 12:29:35,393 - nvflare.app_common.executors.task_script_runner - INFO - [1,  2000] loss: 2.169\n",
      "2024-08-16 12:29:35,476 - nvflare.app_common.executors.task_script_runner - INFO - [1,  2000] loss: 2.182\n",
      "2024-08-16 12:29:39,001 - nvflare.app_common.executors.task_script_runner - INFO - [1,  4000] loss: 1.868\n",
      "2024-08-16 12:29:39,231 - nvflare.app_common.executors.task_script_runner - INFO - [1,  4000] loss: 1.889\n",
      "2024-08-16 12:29:42,652 - nvflare.app_common.executors.task_script_runner - INFO - [1,  6000] loss: 1.678\n",
      "2024-08-16 12:29:43,070 - nvflare.app_common.executors.task_script_runner - INFO - [1,  6000] loss: 1.678\n",
      "2024-08-16 12:29:46,068 - nvflare.app_common.executors.task_script_runner - INFO - [1,  8000] loss: 1.575\n",
      "2024-08-16 12:29:46,496 - nvflare.app_common.executors.task_script_runner - INFO - [1,  8000] loss: 1.582\n",
      "2024-08-16 12:29:49,514 - nvflare.app_common.executors.task_script_runner - INFO - [1, 10000] loss: 1.513\n",
      "2024-08-16 12:29:50,091 - nvflare.app_common.executors.task_script_runner - INFO - [1, 10000] loss: 1.511\n",
      "2024-08-16 12:29:52,948 - nvflare.app_common.executors.task_script_runner - INFO - [1, 12000] loss: 1.455\n",
      "2024-08-16 12:29:53,525 - nvflare.app_common.executors.task_script_runner - INFO - [1, 12000] loss: 1.459\n",
      "2024-08-16 12:29:57,355 - nvflare.app_common.executors.task_script_runner - INFO - [2,  2000] loss: 1.366\n",
      "2024-08-16 12:29:58,065 - nvflare.app_common.executors.task_script_runner - INFO - [2,  2000] loss: 1.388\n",
      "2024-08-16 12:30:00,912 - nvflare.app_common.executors.task_script_runner - INFO - [2,  4000] loss: 1.347\n",
      "2024-08-16 12:30:01,693 - nvflare.app_common.executors.task_script_runner - INFO - [2,  4000] loss: 1.353\n",
      "2024-08-16 12:30:04,517 - nvflare.app_common.executors.task_script_runner - INFO - [2,  6000] loss: 1.310\n",
      "2024-08-16 12:30:05,375 - nvflare.app_common.executors.task_script_runner - INFO - [2,  6000] loss: 1.344\n",
      "2024-08-16 12:30:08,208 - nvflare.app_common.executors.task_script_runner - INFO - [2,  8000] loss: 1.288\n",
      "2024-08-16 12:30:09,223 - nvflare.app_common.executors.task_script_runner - INFO - [2,  8000] loss: 1.330\n",
      "2024-08-16 12:30:11,910 - nvflare.app_common.executors.task_script_runner - INFO - [2, 10000] loss: 1.277\n",
      "2024-08-16 12:30:12,984 - nvflare.app_common.executors.task_script_runner - INFO - [2, 10000] loss: 1.295\n",
      "2024-08-16 12:30:16,006 - nvflare.app_common.executors.task_script_runner - INFO - [2, 12000] loss: 1.265\n",
      "2024-08-16 12:30:17,097 - nvflare.app_common.executors.task_script_runner - INFO - Finished Training\n",
      "2024-08-16 12:30:17,228 - nvflare.app_common.executors.task_script_runner - INFO - [2, 12000] loss: 1.258\n",
      "2024-08-16 12:30:18,154 - nvflare.app_common.executors.task_script_runner - INFO - Finished Training\n",
      "2024-08-16 12:30:19,991 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=train, id=8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:30:19,912 - nvflare.app_common.executors.task_script_runner - INFO - Accuracy of the network on the 10000 test images: 10 %\n",
      "2024-08-16 12:30:19,915 - InProcessClientAPI - INFO - send local model back to peer \n",
      "2024-08-16 12:30:19,980 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: finished processing task\n",
      "2024-08-16 12:30:19,981 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: try #1: sending task result to server\n",
      "2024-08-16 12:30:19,981 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: checking task ...\n",
      "2024-08-16 12:30:19,981 - Cell - INFO - broadcast: channel='aux_communication', topic='__task_check__', targets=['server.simulate_job'], timeout=5.0\n",
      "2024-08-16 12:30:19,984 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: start to send task result to server\n",
      "2024-08-16 12:30:19,984 - FederatedClient - INFO - Starting to push execute result.\n",
      "2024-08-16 12:30:20,228 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: finished processing client result by controller\n",
      "2024-08-16 12:30:20,229 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:8e246740-698d-406e-8cab-9f91a762db52\n",
      "2024-08-16 12:30:20,231 - Communicator - INFO -  SubmitUpdate size: 251.5KB (251509 Bytes). time: 0.247214 seconds\n",
      "2024-08-16 12:30:20,232 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=8e246740-698d-406e-8cab-9f91a762db52]: task result sent to server\n",
      "2024-08-16 12:30:20,232 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "2024-08-16 12:30:20,661 - nvflare.app_common.executors.task_script_runner - INFO - Accuracy of the network on the 10000 test images: 10 %\n",
      "2024-08-16 12:30:20,664 - InProcessClientAPI - INFO - send local model back to peer \n",
      "2024-08-16 12:30:20,970 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=train, id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:30:20,960 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: finished processing task\n",
      "2024-08-16 12:30:20,961 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: try #1: sending task result to server\n",
      "2024-08-16 12:30:20,961 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: checking task ...\n",
      "2024-08-16 12:30:20,961 - Cell - INFO - broadcast: channel='aux_communication', topic='__task_check__', targets=['server.simulate_job'], timeout=5.0\n",
      "2024-08-16 12:30:20,965 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: start to send task result to server\n",
      "2024-08-16 12:30:20,965 - FederatedClient - INFO - Starting to push execute result.\n",
      "2024-08-16 12:30:21,172 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: finished processing client result by controller\n",
      "2024-08-16 12:30:21,173 - WFCommServer - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: task train exit with status TaskCompletionStatus.OK\n",
      "2024-08-16 12:30:21,174 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:c2ea9c72-12a7-4c56-bdac-7dfc83524f20\n",
      "2024-08-16 12:30:21,372 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: aggregating 2 update(s) at round 0\n",
      "2024-08-16 12:30:21,374 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: Start persist model on server.\n",
      "2024-08-16 12:30:21,176 - Communicator - INFO -  SubmitUpdate size: 251.5KB (251509 Bytes). time: 0.210118 seconds\n",
      "2024-08-16 12:30:21,176 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: task result sent to server\n",
      "2024-08-16 12:30:21,176 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "2024-08-16 12:30:21,376 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: End persist model on server.\n",
      "2024-08-16 12:30:21,377 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: Round 1 started.\n",
      "2024-08-16 12:30:21,377 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: Sampled clients: ['site-1', 'site-2']\n",
      "2024-08-16 12:30:21,378 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: Sending task train to ['site-1', 'site-2']\n",
      "2024-08-16 12:30:21,379 - WFCommServer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c2ea9c72-12a7-4c56-bdac-7dfc83524f20]: scheduled task train\n",
      "2024-08-16 12:30:22,237 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: assigned task to client site-2: name=train, id=913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:30:22,239 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: sent task assignment to client. client_name:site-2 task_id:913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:30:22,239 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: train   task_id: 913b8035-b820-4e38-9efb-ba761ae5b0d8  sharable_header_task_id: 913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:30:22,244 - Communicator - INFO - Received from simulator_server server. getTask: train size: 251.5KB (251536 Bytes) time: 0.009714 seconds\n",
      "2024-08-16 12:30:22,245 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2024-08-16 12:30:22,245 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:30:22,245 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: invoking task executor ScriptExecutor\n",
      "2024-08-16 12:30:22,245 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: execute for task (train)\n",
      "2024-08-16 12:30:22,245 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: send data to peer\n",
      "2024-08-16 12:30:22,245 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: sending payload to peer\n",
      "2024-08-16 12:30:22,246 - ScriptExecutor - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: Waiting for result from peer\n",
      "2024-08-16 12:30:22,419 - nvflare.app_common.executors.task_script_runner - INFO - current_round=1\n",
      "2024-08-16 12:30:23,179 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: assigned task to client site-1: name=train, id=410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:30:23,180 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: sent task assignment to client. client_name:site-1 task_id:410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:30:23,181 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: train   task_id: 410b5bfc-db8e-4149-b890-64ee730c4fa4  sharable_header_task_id: 410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:30:23,185 - Communicator - INFO - Received from simulator_server server. getTask: train size: 251.5KB (251536 Bytes) time: 0.006905 seconds\n",
      "2024-08-16 12:30:23,185 - FederatedClient - INFO - pull_task completed. Task name:train Status:True \n",
      "2024-08-16 12:30:23,185 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:30:23,185 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: invoking task executor ScriptExecutor\n",
      "2024-08-16 12:30:23,185 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: execute for task (train)\n",
      "2024-08-16 12:30:23,185 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: send data to peer\n",
      "2024-08-16 12:30:23,185 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: sending payload to peer\n",
      "2024-08-16 12:30:23,186 - ScriptExecutor - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: Waiting for result from peer\n",
      "2024-08-16 12:30:23,668 - nvflare.app_common.executors.task_script_runner - INFO - current_round=1\n",
      "2024-08-16 12:30:25,721 - nvflare.app_common.executors.task_script_runner - INFO - [1,  2000] loss: 1.231\n",
      "2024-08-16 12:30:27,161 - nvflare.app_common.executors.task_script_runner - INFO - [1,  2000] loss: 1.226\n",
      "2024-08-16 12:30:29,237 - nvflare.app_common.executors.task_script_runner - INFO - [1,  4000] loss: 1.232\n",
      "2024-08-16 12:30:30,768 - nvflare.app_common.executors.task_script_runner - INFO - [1,  4000] loss: 1.222\n",
      "2024-08-16 12:30:33,029 - nvflare.app_common.executors.task_script_runner - INFO - [1,  6000] loss: 1.219\n",
      "2024-08-16 12:30:34,387 - nvflare.app_common.executors.task_script_runner - INFO - [1,  6000] loss: 1.220\n",
      "2024-08-16 12:30:36,732 - nvflare.app_common.executors.task_script_runner - INFO - [1,  8000] loss: 1.206\n",
      "2024-08-16 12:30:38,238 - nvflare.app_common.executors.task_script_runner - INFO - [1,  8000] loss: 1.187\n",
      "2024-08-16 12:30:41,041 - nvflare.app_common.executors.task_script_runner - INFO - [1, 10000] loss: 1.169\n",
      "2024-08-16 12:30:42,687 - nvflare.app_common.executors.task_script_runner - INFO - [1, 10000] loss: 1.192\n",
      "2024-08-16 12:30:45,298 - nvflare.app_common.executors.task_script_runner - INFO - [1, 12000] loss: 1.173\n",
      "2024-08-16 12:30:46,980 - nvflare.app_common.executors.task_script_runner - INFO - [1, 12000] loss: 1.166\n",
      "2024-08-16 12:30:49,936 - nvflare.app_common.executors.task_script_runner - INFO - [2,  2000] loss: 1.111\n",
      "2024-08-16 12:30:51,449 - nvflare.app_common.executors.task_script_runner - INFO - [2,  2000] loss: 1.117\n",
      "2024-08-16 12:30:53,517 - nvflare.app_common.executors.task_script_runner - INFO - [2,  4000] loss: 1.107\n",
      "2024-08-16 12:30:54,919 - nvflare.app_common.executors.task_script_runner - INFO - [2,  4000] loss: 1.102\n",
      "2024-08-16 12:30:57,182 - nvflare.app_common.executors.task_script_runner - INFO - [2,  6000] loss: 1.101\n",
      "2024-08-16 12:30:58,493 - nvflare.app_common.executors.task_script_runner - INFO - [2,  6000] loss: 1.097\n",
      "2024-08-16 12:31:00,841 - nvflare.app_common.executors.task_script_runner - INFO - [2,  8000] loss: 1.111\n",
      "2024-08-16 12:31:01,974 - nvflare.app_common.executors.task_script_runner - INFO - [2,  8000] loss: 1.098\n",
      "2024-08-16 12:31:04,379 - nvflare.app_common.executors.task_script_runner - INFO - [2, 10000] loss: 1.115\n",
      "2024-08-16 12:31:05,393 - nvflare.app_common.executors.task_script_runner - INFO - [2, 10000] loss: 1.105\n",
      "2024-08-16 12:31:07,895 - nvflare.app_common.executors.task_script_runner - INFO - [2, 12000] loss: 1.101\n",
      "2024-08-16 12:31:08,798 - nvflare.app_common.executors.task_script_runner - INFO - Finished Training\n",
      "2024-08-16 12:31:08,851 - nvflare.app_common.executors.task_script_runner - INFO - [2, 12000] loss: 1.095\n",
      "2024-08-16 12:31:09,709 - nvflare.app_common.executors.task_script_runner - INFO - Finished Training\n",
      "2024-08-16 12:31:11,804 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job]: got result from client site-2 for task: name=train, id=913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:31:11,805 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: validation metric 54 from client site-2\n",
      "2024-08-16 12:31:11,644 - nvflare.app_common.executors.task_script_runner - INFO - Accuracy of the network on the 10000 test images: 54 %\n",
      "2024-08-16 12:31:11,647 - InProcessClientAPI - INFO - send local model back to peer \n",
      "2024-08-16 12:31:11,798 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: finished processing task\n",
      "2024-08-16 12:31:11,798 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: try #1: sending task result to server\n",
      "2024-08-16 12:31:11,798 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: checking task ...\n",
      "2024-08-16 12:31:11,798 - Cell - INFO - broadcast: channel='aux_communication', topic='__task_check__', targets=['server.simulate_job'], timeout=5.0\n",
      "2024-08-16 12:31:11,801 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: start to send task result to server\n",
      "2024-08-16 12:31:11,801 - FederatedClient - INFO - Starting to push execute result.\n",
      "2024-08-16 12:31:12,011 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: finished processing client result by controller\n",
      "2024-08-16 12:31:12,012 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-2   task_id:913b8035-b820-4e38-9efb-ba761ae5b0d8\n",
      "2024-08-16 12:31:12,014 - Communicator - INFO -  SubmitUpdate size: 251.5KB (251509 Bytes). time: 0.212835 seconds\n",
      "2024-08-16 12:31:12,014 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=913b8035-b820-4e38-9efb-ba761ae5b0d8]: task result sent to server\n",
      "2024-08-16 12:31:12,014 - ClientTaskWorker - INFO - Finished one task run for client: site-2 interval: 2 task_processed: True\n",
      "2024-08-16 12:31:12,366 - nvflare.app_common.executors.task_script_runner - INFO - Accuracy of the network on the 10000 test images: 54 %\n",
      "2024-08-16 12:31:12,370 - InProcessClientAPI - INFO - send local model back to peer \n",
      "2024-08-16 12:31:12,753 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job]: got result from client site-1 for task: name=train, id=410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:31:12,755 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: validation metric 54 from client site-1\n",
      "2024-08-16 12:31:12,744 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: finished processing task\n",
      "2024-08-16 12:31:12,745 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: try #1: sending task result to server\n",
      "2024-08-16 12:31:12,745 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: checking task ...\n",
      "2024-08-16 12:31:12,745 - Cell - INFO - broadcast: channel='aux_communication', topic='__task_check__', targets=['server.simulate_job'], timeout=5.0\n",
      "2024-08-16 12:31:12,749 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: start to send task result to server\n",
      "2024-08-16 12:31:12,749 - FederatedClient - INFO - Starting to push execute result.\n",
      "2024-08-16 12:31:12,962 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: finished processing client result by controller\n",
      "2024-08-16 12:31:12,962 - WFCommServer - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: task train exit with status TaskCompletionStatus.OK\n",
      "2024-08-16 12:31:12,963 - SubmitUpdateCommand - INFO - submit_update process. client_name:site-1   task_id:410b5bfc-db8e-4149-b890-64ee730c4fa4\n",
      "2024-08-16 12:31:13,162 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: new best validation metric at round 1: 54.0\n",
      "2024-08-16 12:31:13,164 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: aggregating 2 update(s) at round 1\n",
      "2024-08-16 12:31:12,965 - Communicator - INFO -  SubmitUpdate size: 251.5KB (251509 Bytes). time: 0.215980 seconds\n",
      "2024-08-16 12:31:12,965 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: task result sent to server\n",
      "2024-08-16 12:31:12,965 - ClientTaskWorker - INFO - Finished one task run for client: site-1 interval: 2 task_processed: True\n",
      "2024-08-16 12:31:13,166 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: Start persist model on server.\n",
      "2024-08-16 12:31:13,167 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: End persist model on server.\n",
      "2024-08-16 12:31:13,168 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=410b5bfc-db8e-4149-b890-64ee730c4fa4]: Finished FedAvg.\n",
      "2024-08-16 12:31:13,169 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Workflow: controller finalizing ...\n",
      "2024-08-16 12:31:13,169 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: ABOUT_TO_END_RUN fired\n",
      "2024-08-16 12:31:13,171 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:13,172 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: received request from Server to end current RUN\n",
      "2024-08-16 12:31:13,173 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: received request from Server to end current RUN\n",
      "2024-08-16 12:31:13,673 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:14,018 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-2, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2024-08-16 12:31:14,020 - GetTaskCommand - INFO - return task to client.  client_name: site-2  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2024-08-16 12:31:14,175 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:14,193 - FederatedClient - INFO - Shutting down client run: site-2\n",
      "2024-08-16 12:31:14,195 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00006 Not Connected] is closed PID: 27586\n",
      "2024-08-16 12:31:14,021 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2024-08-16 12:31:14,022 - ClientRunner - INFO - [identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2024-08-16 12:31:14,022 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: started end-run events sequence\n",
      "2024-08-16 12:31:14,022 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: ABOUT_TO_END_RUN fired\n",
      "2024-08-16 12:31:14,022 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:14,022 - InProcessClientAPI - WARNING - ask to stop job: reason: END_RUN received\n",
      "2024-08-16 12:31:14,149 - InProcessClientAPI - WARNING - request to stop the job for reason END_RUN received\n",
      "2024-08-16 12:31:14,152 - ClientRunner - INFO - [identity=site-2, run=simulate_job]: END_RUN fired\n",
      "2024-08-16 12:31:14,152 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2024-08-16 12:31:14,193 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-2 \n",
      "2024-08-16 12:31:14,195 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 Not Connected] is closed PID: 27699\n",
      "2024-08-16 12:31:14,676 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:14,968 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-1, peer_run=simulate_job]: server runner is finalizing - asked client to end the run\n",
      "2024-08-16 12:31:14,969 - GetTaskCommand - INFO - return task to client.  client_name: site-1  task_name: __end_run__   task_id:   sharable_header_task_id: \n",
      "2024-08-16 12:31:14,971 - FederatedClient - INFO - pull_task completed. Task name:__end_run__ Status:True \n",
      "2024-08-16 12:31:14,971 - ClientRunner - INFO - [identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: server asked to end the run\n",
      "2024-08-16 12:31:14,971 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: started end-run events sequence\n",
      "2024-08-16 12:31:14,971 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: ABOUT_TO_END_RUN fired\n",
      "2024-08-16 12:31:14,971 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: Firing CHECK_END_RUN_READINESS ...\n",
      "2024-08-16 12:31:14,972 - InProcessClientAPI - WARNING - ask to stop job: reason: END_RUN received\n",
      "2024-08-16 12:31:15,418 - FederatedClient - INFO - Shutting down client run: site-1\n",
      "2024-08-16 12:31:15,419 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: asked to abort - triggered abort_signal to stop the RUN\n",
      "2024-08-16 12:31:15,420 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00005 Not Connected] is closed PID: 27586\n",
      "2024-08-16 12:31:15,374 - InProcessClientAPI - WARNING - request to stop the job for reason END_RUN received\n",
      "2024-08-16 12:31:15,376 - ClientRunner - INFO - [identity=site-1, run=simulate_job]: END_RUN fired\n",
      "2024-08-16 12:31:15,377 - ClientTaskWorker - INFO - End the Simulator run.\n",
      "2024-08-16 12:31:15,418 - ClientTaskWorker - INFO - Clean up ClientRunner for : site-1 \n",
      "2024-08-16 12:31:15,420 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 Not Connected] is closed PID: 27698\n",
      "2024-08-16 12:31:16,688 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: END_RUN fired\n",
      "2024-08-16 12:31:16,690 - ReliableMessage - INFO - ReliableMessage is shutdown\n",
      "2024-08-16 12:31:16,690 - ServerRunner - INFO - [identity=simulator_server, run=simulate_job, wf=controller]: Server runner finished.\n",
      "2024-08-16 12:31:17,628 - ReliableMessage - INFO - shutdown reliable message monitor\n",
      "2024-08-16 12:31:17,638 - SimulatorServer - INFO - Server app stopped.\n",
      "\n",
      "\n",
      "2024-08-16 12:31:17,730 - nvflare.fuel.hci.server.hci - INFO - Admin Server localhost on Port 50775 shutdown!\n",
      "2024-08-16 12:31:17,732 - SimulatorServer - INFO - shutting down server\n",
      "2024-08-16 12:31:17,733 - SimulatorServer - INFO - canceling sync locks\n",
      "2024-08-16 12:31:17,733 - SimulatorServer - INFO - server off\n",
      "2024-08-16 12:31:21,035 - MPM - WARNING - #### MPM: still running thread Thread-14\n",
      "2024-08-16 12:31:21,036 - MPM - INFO - MPM: Good Bye!\n"
     ]
    }
   ],
   "source": [
    "job.simulator_run(\"/tmp/nvflare/jobs/workdir\", gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccbe893",
   "metadata": {},
   "source": [
    "If using Google Colab and the output is not showing correctly, export the job and run it with the simulator command instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvflare simulator -w /tmp/nvflare/jobs/workdir -n 2 -t 2 -gpu 0 /tmp/nvflare/jobs/job_config/cifar10_fedavg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474ddfa-0d2e-4d7f-b033-8ccfbbd57a75",
   "metadata": {},
   "source": [
    "tensorboard --logdir=/tmp/nvflare/jobs/workdir/server/simulate_job/tb_events\n",
    "tensorboard --logdir=/tmp/nvflare/jobs/workdir/server/simulate_job/tb_events### Visualize the Training Results\n",
    "By default, we enable TensorBoard metric [streaming](https://nvflare.readthedocs.io/en/main/examples/tensorboard_streaming.html) using NVFlare's `SummaryWriter` in [src/cifar10_fl.py](src/cifar10_fl.py). \n",
    "\n",
    "The TensorBoard metrics will be received at the server, and you can visualize the training progress by running \n",
    "```commandline\n",
    "tensorboard --logdir=/tmp/nvflare/jobs/workdir/server/simulate_job/tb_events\n",
    "```\n",
    "in a new terminal.\n",
    "\n",
    "<img src=\"figs/tb_loss.png\" alt=\"Streamed TensorBoard metric\" width=50% height=50% />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
