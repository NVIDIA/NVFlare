{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3220cbc8-47aa-4825-bc80-c504d9fa1bb9",
   "metadata": {},
   "source": [
    "# Prepare Data for Higgs Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6fa44-7dcb-4072-8b27-f722147102f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install requirements\n",
    "We will need pandas for the data preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747456a-978a-4ebd-8fad-d3b6f71886aa",
   "metadata": {},
   "source": [
    "\n",
    "## Prepare data\n",
    "\n",
    "### Download and Store Data\n",
    "\n",
    "To run the examples, we first download the dataset from the HIGGS link above, which is a single .csv file. By default, we assume the dataset is downloaded, uncompressed, and stored in \n",
    "\n",
    "```\n",
    "/tmp/nvflare/dataset/input/higgs.zip.\n",
    "\n",
    "```\n",
    "\n",
    "You can either use wget or curl to download directly if you have wget or curl installed. here is using curl command. This will takes a while to download 2.6+GB file. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b4914b-79ed-444b-bdd5-0cae13a789a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2686M    0 2686M    0     0  22.6M      0 --:--:--  0:01:58 --:--:-- 19.4M9M    0     0  22.7M      0 --:--:--  0:00:30 --:--:-- 23.9M  0 1431M    0     0  22.6M      0 --:--:--  0:01:03 --:--:-- 24.1M\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p /tmp/nvflare/dataset/input\n",
    "\n",
    "! curl -o /tmp/nvflare/dataset/input/higgs.zip https://archive.ics.uci.edu/static/public/280/higgs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e10ba2-1c60-4253-9a6a-581f8faeaf57",
   "metadata": {},
   "source": [
    "Alternative download with wget ```wget -P /tmp/nvflare/dataset/input/ https://archive.ics.uci.edu/static/public/280/higgs.zip```\n",
    "\n",
    "First we need to unzip the higgs.zip, we have already pre-installed \"unzip\" and \"gunzip\", so we just directly use this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a03df95-8d94-4027-9538-91cd00422468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/nvflare/dataset/input/higgs.zip\n",
      "  inflating: /tmp/nvflare/dataset/input/HIGGS.csv.gz  \n"
     ]
    }
   ],
   "source": [
    "! unzip -d /tmp/nvflare/dataset/input/ /tmp/nvflare/dataset/input/higgs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dcb921b-731c-4733-a573-d4bb4291e556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gunzip -c /tmp/nvflare/dataset/input/HIGGS.csv.gz > /tmp/nvflare/dataset/input/higgs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08774782-790c-4a7a-a48c-bbcc11f633cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13348436\n",
      "drwxrwxr-x 2 chester chester       4096 Nov 22 10:05 .\n",
      "drwxrwxr-x 3 chester chester       4096 Nov 22 09:55 ..\n",
      "-rw-rw-r-- 1 chester chester 8035497980 Nov 22 10:12 higgs.csv\n",
      "-rwx------ 1 chester chester 2816407858 May 22  2023 HIGGS.csv.gz\n",
      "-rw-rw-r-- 1 chester chester 2816865137 Nov 22 09:57 higgs.zip\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tmp/nvflare/dataset/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4f685-31b3-499b-881e-fc5f73b3f662",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "\n",
    "HIGGS dataset contains 11 million instances (rows), each with 28 attributes.\n",
    "The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. \n",
    "The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. The last 500,000 examples are used as a test set.\n",
    "\n",
    "The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton  pT, lepton  eta, lepton  phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed information about each feature see the original paper.\n",
    "\n",
    "Since HIGGS dataset is already randomly recorded, data split will be specified by the continuous index ranges for each client, rather than a vector of random instance indices. We will split the dataset uniformly: all clients has the same amount of data. The output directory \n",
    "\n",
    "```\n",
    "/tmp/nvflare/dataset/output/\n",
    "\n",
    "```\n",
    "\n",
    "To make it similar to the real world use cases, we put features (CSV file headers) into a file in the input directory.  When we split the file, we make sure each site will has a \"header.csv\" file corresponding to the csv data. In horizontal split. all the header will be the same. but for vertical learning, each site may have different headers. \n",
    "\n",
    "\n",
    "We create a simple python code to split data: called split_csv.py. Let's run this, you will need to wait for few minutes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d5c919-9d99-494f-b216-8431ff2f23c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features written to /tmp/nvflare/dataset/input/headers.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Your list of data\n",
    "features = [\"label\", \"lepton_pt\", \"lepton_eta\", \"lepton_phi\", \"missing_energy_magnitude\", \"missing_energy_phi\", \"jet_1_pt\", \"jet_1_eta\", \"jet_1_phi\", \"jet_1_b_tag\", \"jet_2_pt\", \"jet_2_eta\", \"jet_2_phi\", \"jet_2_b_tag\", \"jet_3_pt\", \"jet_3_eta\", \"jet_3_phi\", \"jet_3_b_tag\",\\\n",
    "            \"jet_4_pt\", \"jet_4_eta\", \"jet_4_phi\", \"jet_4_b_tag\", \\\n",
    "            \"m_jj\", \"m_jjj\", \"m_lv\", \"m_jlv\", \"m_bb\", \"m_wbb\", \"m_wwbb\"]\n",
    "\n",
    "# Specify the file path\n",
    "file_path =  '/tmp/nvflare/dataset/input/headers.csv'\n",
    "\n",
    "with open(file_path, 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(features)\n",
    "\n",
    "print(f\"features written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33eb485b-f28b-42aa-935e-3bdcd7087047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,lepton_pt,lepton_eta,lepton_phi,missing_energy_magnitude,missing_energy_phi,jet_1_pt,jet_1_eta,jet_1_phi,jet_1_b_tag,jet_2_pt,jet_2_eta,jet_2_phi,jet_2_b_tag,jet_3_pt,jet_3_eta,jet_3_phi,jet_3_b_tag,jet_4_pt,jet_4_eta,jet_4_phi,jet_4_b_tag,m_jj,m_jjj,m_lv,m_jlv,m_bb,m_wbb,m_wwbb\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/nvflare/dataset/input/headers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d0283-53dc-48e6-86bb-605c5b84ebd9",
   "metadata": {},
   "source": [
    "Now we prepare to split data, note that, we used certain sample rate to make demo faster to run. You can change the number to even smaller such 0.003 to reduce the file size especially when you development or debugging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fcb6c-756a-40f1-afd7-8039d561298d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now assume you are on the \"higgs\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a243cb-5857-4cc1-8c40-49f455d5745d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chester/projects/NVFlare/examples/hello-world/step-by-step/higgs\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b11273-230f-47e5-a4bb-c3672d5d862b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site-1= start_index=0 end_index=1100000\n",
      "site-2= start_index=1100000 end_index=2200000\n",
      "site-3= start_index=2200000 end_index=3300000\n",
      "File copied to /tmp/nvflare/dataset/output/site-1_header.csv\n",
      "File copied to /tmp/nvflare/dataset/output/site-2_header.csv\n",
      "File copied to /tmp/nvflare/dataset/output/site-3_header.csv\n"
     ]
    }
   ],
   "source": [
    "!python split_csv.py \\\n",
    "  --input_data_path=/tmp/nvflare/dataset/input/higgs.csv \\\n",
    "  --input_header_path=/tmp/nvflare/dataset/input/headers.csv \\\n",
    "  --output_dir=/tmp/nvflare/dataset/output/ \\\n",
    "  --site_num=3 \\\n",
    "  --sample_rate=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29502248-aa2a-4435-b1c3-b13269d916d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1631120\n",
      "drwxrwxr-x 2 chester chester      4096 Nov 22 11:01 .\n",
      "drwxrwxr-x 4 chester chester      4096 Nov 22 11:00 ..\n",
      "-rw-rw-r-- 1 chester chester 556739675 Nov 22 16:14 site-1.csv\n",
      "-rw-rw-r-- 1 chester chester       287 Nov 22 16:15 site-1_header.csv\n",
      "-rw-rw-r-- 1 chester chester 556755003 Nov 22 16:15 site-2.csv\n",
      "-rw-rw-r-- 1 chester chester       287 Nov 22 16:15 site-2_header.csv\n",
      "-rw-rw-r-- 1 chester chester 556736056 Nov 22 16:15 site-3.csv\n",
      "-rw-rw-r-- 1 chester chester       287 Nov 22 16:15 site-3_header.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tmp/nvflare/dataset/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8826f-b786-4715-b2fe-3b62a3b0a3ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we have our data prepared. we are ready to do other computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4553632-f692-4529-91f4-25acf6b2bc39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100000 /tmp/nvflare/dataset/output/site-1.csv\n"
     ]
    }
   ],
   "source": [
    "! wc -l /tmp/nvflare/dataset/output/site-1.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
