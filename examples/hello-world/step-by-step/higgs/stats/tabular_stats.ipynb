{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf1c433-ba7f-4967-b066-670eb5e016ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tabular Data Federated Statistics \n",
    "\n",
    "Before we perform machine learning tasks on the Higgs data, let's examine the statistics of the dataset. \n",
    "\n",
    "\n",
    "## Setup NVFLARE\n",
    "\n",
    "Follow [Getting Started](https://nvflare.readthedocs.io/en/main/getting_started.html) to set up a virtual environment and install NVFLARE.\n",
    "\n",
    "You can also follow this [notebook](https://github.com/NVIDIA/NVFlare/blob/main/examples/nvflare_setup.ipynb) to get set up.\n",
    "\n",
    "> Make sure you have installed nvflare from **terminal** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf2d68-b020-457f-a1f1-b1f95509c929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install requirements\n",
    "assuming the current directory is 'higgs/stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552a5eb-dbfb-42da-8cfa-082c1739012e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f373c84-b3d9-43e2-9e6a-9ff0db33f3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5cd9a-3da9-446c-aac0-6ae84bf0ead1",
   "metadata": {},
   "source": [
    "\n",
    "## Prepare data\n",
    "Please reference [prepare_higgs_data](../prepare_data.ipynb) notebooks. Pay attention to the current location. You need to switch \"higgs\" directory to run the data split.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2dd58-210f-4006-86ec-a821713d5cac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we have our data prepared, let's first take a look at these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47416d89-74f9-4ede-b8b9-99f0eeaa9814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [\"label\", \"lepton_pt\", \"lepton_eta\", \"lepton_phi\", \"missing_energy_magnitude\", \"missing_energy_phi\", \"jet_1_pt\", \"jet_1_eta\", \"jet_1_phi\", \"jet_1_b_tag\", \"jet_2_pt\", \"jet_2_eta\", \"jet_2_phi\", \"jet_2_b_tag\", \"jet_3_pt\", \"jet_3_eta\", \"jet_3_phi\", \"jet_3_b_tag\",\\\n",
    "            \"jet_4_pt\", \"jet_4_eta\", \"jet_4_phi\", \"jet_4_b_tag\", \\\n",
    "            \"m_jj\", \"m_jjj\", \"m_lv\", \"m_jlv\", \"m_bb\", \"m_wbb\", \"m_wwbb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ab17c-8af7-43af-923d-becf6dec919c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ad635-5b8a-4430-8bce-8e3bb4b0a0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(\"/tmp/nvflare/dataset/output/site-1.csv\", names=features, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751d35c-99ce-4bef-9b8f-af3a57507a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cefa5-d579-45c0-815e-70dac06809c4",
   "metadata": {},
   "source": [
    "## Create a statistics calculator for the local tabular dataset\n",
    "\n",
    "\n",
    "```\n",
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.series import Series\n",
    "\n",
    "from nvflare.apis.fl_context import FLContext\n",
    "from nvflare.app_common.abstract.statistics_spec import BinRange, Feature, Histogram, HistogramType, Statistics\n",
    "from nvflare.app_common.statistics.numpy_utils import dtype_to_data_type, get_std_histogram_buckets\n",
    "\n",
    "\n",
    "class DFStatistics(Statistics):\n",
    "    def __init__(self, data_root_dir: str):\n",
    "        super().__init__()\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.data: Optional[Dict[str, pd.DataFrame]] = None\n",
    "        self.data_features = None\n",
    "\n",
    "    def load_features(self, fl_ctx: FLContext) -> List:\n",
    "        client_name = self.get_client_name(fl_ctx)\n",
    "        try:\n",
    "            data_path = f\"{self.data_root_dir}/{client_name}_header.csv\"\n",
    "\n",
    "            features = []\n",
    "            with open(data_path, 'r') as file:\n",
    "                # Create a CSV reader object\n",
    "                csv_reader = csv.reader(file)\n",
    "                line_list = next(csv_reader)\n",
    "                features = line_list\n",
    "            return features\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Load header for client {client_name} failed! {e}\")\n",
    "\n",
    "    def load_data(self, fl_ctx: FLContext) -> Dict[str, pd.DataFrame]:\n",
    "        client_name = self.get_client_name(fl_ctx)\n",
    "        try:\n",
    "            data_path = f\"{self.data_root_dir}/{client_name}.csv\"\n",
    "            # example of load data from CSV\n",
    "            df: pd.DataFrame = pd.read_csv(\n",
    "                data_path, names=self.data_features, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\"\n",
    "            )\n",
    "            return {\"train\": df}\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Load data for client {client_name} failed! {e}\")\n",
    "\n",
    "    def get_client_name(self, fl_ctx):\n",
    "        client_name = fl_ctx.get_identity_name() if fl_ctx is not None else \"site-1\"\n",
    "        if fl_ctx:\n",
    "            self.log_info(fl_ctx, f\"load data for client {client_name}\")\n",
    "        else:\n",
    "            print(f\"load data for client {client_name}\")\n",
    "        return client_name\n",
    "\n",
    "    def initialize(self, fl_ctx: FLContext):\n",
    "        self.data_features = self.load_features(fl_ctx)\n",
    "        self.data = self.load_data(fl_ctx)\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"data is not loaded. make sure the data is loaded\")\n",
    "\n",
    "    def features(self) -> Dict[str, List[Feature]]:\n",
    "        results: Dict[str, List[Feature]] = {}\n",
    "        for ds_name in self.data:\n",
    "            df = self.data[ds_name]\n",
    "            results[ds_name] = []\n",
    "            for feature_name in df:\n",
    "                data_type = dtype_to_data_type(df[feature_name].dtype)\n",
    "                results[ds_name].append(Feature(feature_name, data_type))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def count(self, dataset_name: str, feature_name: str) -> int:\n",
    "        df: pd.DataFrame = self.data[dataset_name]\n",
    "        return df[feature_name].count()\n",
    "\n",
    "    def sum(self, dataset_name: str, feature_name: str) -> float:\n",
    "        df: pd.DataFrame = self.data[dataset_name]\n",
    "        return df[feature_name].sum().item()\n",
    "\n",
    "    def mean(self, dataset_name: str, feature_name: str) -> float:\n",
    "\n",
    "        count: int = self.count(dataset_name, feature_name)\n",
    "        sum_value: float = self.sum(dataset_name, feature_name)\n",
    "        return sum_value / count\n",
    "\n",
    "    def stddev(self, dataset_name: str, feature_name: str) -> float:\n",
    "        df = self.data[dataset_name]\n",
    "        return df[feature_name].std().item()\n",
    "\n",
    "    def variance_with_mean(\n",
    "        self, dataset_name: str, feature_name: str, global_mean: float, global_count: float\n",
    "    ) -> float:\n",
    "        df = self.data[dataset_name]\n",
    "        tmp = (df[feature_name] - global_mean) * (df[feature_name] - global_mean)\n",
    "        variance = tmp.sum() / (global_count - 1)\n",
    "        return variance.item()\n",
    "\n",
    "    def histogram(\n",
    "        self, dataset_name: str, feature_name: str, num_of_bins: int, global_min_value: float, global_max_value: float\n",
    "    ) -> Histogram:\n",
    "\n",
    "        num_of_bins: int = num_of_bins\n",
    "\n",
    "        df = self.data[dataset_name]\n",
    "        feature: Series = df[feature_name]\n",
    "        flattened = feature.ravel()\n",
    "        flattened = flattened[flattened != np.array(None)]\n",
    "        buckets = get_std_histogram_buckets(flattened, num_of_bins, BinRange(global_min_value, global_max_value))\n",
    "        return Histogram(HistogramType.STANDARD, buckets)\n",
    "\n",
    "    def max_value(self, dataset_name: str, feature_name: str) -> float:\n",
    "        \"\"\"this is needed for histogram calculation, not used for reporting\"\"\"\n",
    "\n",
    "        df = self.data[dataset_name]\n",
    "        return df[feature_name].max()\n",
    "\n",
    "    def min_value(self, dataset_name: str, feature_name: str) -> float:\n",
    "        \"\"\"this is needed for histogram calculation, not used for reporting\"\"\"\n",
    "\n",
    "        df = self.data[dataset_name]\n",
    "        return df[feature_name].min()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Let's see if the code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e59bd-0b97-4ad9-a0de-abd10dd76d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d46c3-3986-4faf-bde8-1d4af749bf57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from df_stats import DFStatistics\n",
    "\n",
    "df_stats_cal = DFStatistics(data_root_dir = \"/tmp/nvflare/dataset/output\")\n",
    "\n",
    "# We use fl_ctx = None for local calculation ( where the data set default to \"site-1.csv\", so we can explore the stats locally without federated settings. \n",
    "df_stats_cal.initialize(fl_ctx = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9f923-54eb-4b7b-a23d-c93201554332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_features = df_stats_cal.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8f648-c5b9-4b71-b80c-431613c33dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0464f5e-b9ae-42d9-8bbe-7c180ce48767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_cal.count(\"train\", \"lepton_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31419dd6-afdd-4612-becf-ce5a53d756cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_cal.mean(\"train\", \"lepton_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36773f44-5153-4fcf-9814-c054f64f2723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_cal.mean(\"train\", \"m_wwbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d0c62-1c7a-4a4c-bd98-3feb2c439268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_cal.stddev(\"train\", \"m_wwbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4599e3-bd78-4152-b255-246f801a51dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats_cal.histogram(\"train\", \"lepton_pt\", 20, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3735304-860d-41f1-bd9b-f05b1f048e4b",
   "metadata": {},
   "source": [
    "Great ! The code works. Let's move to the federated statistics calculations. Befor we do that, we need to move back to the parent directory of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d8014-ed54-4d0e-bc96-adad905a29dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd ../."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19adbde-b204-4483-810b-56c5d1517112",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Federated Statistics Job\n",
    "\n",
    "We are going to use NVFLARE job cli to create job. For detailed instructions on Job CLI, please follow the [job cli tutorial](https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/job_cli.ipynb)\n",
    "\n",
    "Let's check the available job templates, we are going to use one of the existing job templates and modify it to fit our needs. The job template is nothing but server and client-side job configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe46054-ada9-41da-8879-373c78ed2431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c86f2b-5a2a-4138-88df-757fd763ef8f",
   "metadata": {},
   "source": [
    "there is \"stats_df\" job template, which what we need. We are going to use that. Now, use ```nvflare job create``` command\n",
    "We would like to use our new df_statistics.py file we just tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307eea6-0ca8-46e5-a24b-13d7ff3a315f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -w stats_df -j /tmp/nvflare/jobs/stats_df -sd code -force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a6e07-c8c0-476d-84db-e3609f6dd0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree /tmp/nvflare/jobs/stats_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ffdb3-7dbb-4b24-8252-39bfd51aeffa",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's modify the server configuration to set the bin = 20, global min_max range in [0,10] instead of [0,120] and stats_writer output path  \"statistics/adults_stats.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb6cb2-2e25-42ad-b881-8dea2aeb1391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -w stats_df -force -j /tmp/nvflare/jobs/stats_df -sd code -f config_fed_server.conf bins=20 range=\"[0,10]\" output_path=\"statistics/stats.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699865f-8e9b-494d-ba4d-b6b952fb7cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/jobs/stats_df/app/config/config_fed_server.conf         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696eb79-dc4f-4bf7-a8a5-545f79de8891",
   "metadata": {},
   "source": [
    "Now, look at the client configuration, we notice that the job template component configuration \n",
    "```\n",
    "components = [\n",
    "  {\n",
    "    id = \"df_stats_generator\"\n",
    "    path = \"df_statistics.DFStatistics\"\n",
    "    args {\n",
    "      data_path = \"data.csv\"\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "is different from our new DFStatistics class, where the arguments are\n",
    "features, data_root_dir not \"data_path\". So we will need to modify that. \n",
    "\n",
    "```\n",
    "\n",
    "class DFStatistics(Statistics):\n",
    "    def __init__(self, data_root_dir: str):\n",
    "        super().__init__()\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.data: Optional[Dict[str, pd.DataFrame]] = None\n",
    "        self.data_features = None\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec04d1d-b3fd-4a38-b2eb-b43b9f04c7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/jobs/stats_df/app/config/config_fed_client.conf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96a85a-056d-4594-a348-30e69142ea33",
   "metadata": {},
   "source": [
    "what we need to do are the followings\n",
    "1. remove data_path argument\n",
    "2. add data_root_dir arguments\n",
    "3. change the path of the DFStatistics class from 'df_statistics.DFStatistics' to df_stats.DFStatistics'\n",
    "\n",
    "We use the following syntax to do this (you can always open it with your editing tool to direct edit the file). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4d563-ec0e-4d03-a6ae-008d9ba62171",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvflare job create -w stats_df -force -j /tmp/nvflare/jobs/stats_df \\-sd code \\\n",
    "-f config_fed_server.conf \\\n",
    "   bins=20 \\\n",
    "   range=\"[0,10]\" \\\n",
    "   output_path=\"statistics/stats.json\" \\\n",
    "-f config_fed_client.conf \\\n",
    "   components[0].path=\"df_stats.DFStatistics\" \\\n",
    "   components[0].args.data_path- \\\n",
    "   components[0].args.data_root_dir=\"/tmp/nvflare/dataset/output\" -debug\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7118a07-9c90-4f9c-97a5-2dcfa58cb091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree  /tmp/nvflare/jobs/stats_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b1fa7-1eef-42a4-b297-81289f4440c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Run job in FL Simulator\n",
    "\n",
    "Now we can run the job with simulator. \n",
    "\n",
    "```\n",
    "nvflare simulator  /tmp/nvflare/jobs/stats_df  -w /tmp/nvflare/tabular/stats_df  -n 3 -t 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4ffde-627c-4f72-b114-fb9e92c1dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare simulator  /tmp/nvflare/jobs/stats_df  -w /tmp/nvflare/tabular/stats_df  -n 3 -t 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981ae44-00b7-41b8-a2f0-4c49e05d6014",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The results are stored in \n",
    "```\n",
    "/tmp/nvflare/tabular/stats_df/simulate_job/statistics/stats.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6117ca2-c9bf-43f1-98ed-4eb3dc8f369b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -al  /tmp/nvflare/tabular/stats_df/simulate_job/statistics/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f83f8-f96f-4943-af27-c5e6551d3449",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76c3f3-af15-4ec9-bade-0ae2de86e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp /tmp/nvflare/tabular/stats_df/simulate_job/statistics//stats.json ./."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef772576-d87a-4a6e-b530-6a440e230839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from nvflare.app_opt.statistics.visualization.statistics_visualization import Visualization\n",
    "with open('stats.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "vis = Visualization()\n",
    "vis.show_stats(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cdfe52-28a4-499f-9884-d833fec6d3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100%  depth:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f354b9-6238-40be-91d9-67229c7b5891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis.show_histograms(data = data, plot_type=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3d942-9b8d-45de-85aa-b21d27ca60ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "The global and local histograms differences are none as we are using the same dataset for all clients. \n",
    "\n",
    "## We are done !\n",
    "Congratulations! you have just completed the federated stats calulation for tabular data. \n",
    "\n",
    "If you would like to see a detailed discussion regarding privacy filtering, please checkout the example in [federated statistics](https://github.com/NVIDIA/NVFlare/tree/main/examples/advanced/federated-statistics) examples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e6273-5b79-4eb9-beb3-4ae96c21218c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
