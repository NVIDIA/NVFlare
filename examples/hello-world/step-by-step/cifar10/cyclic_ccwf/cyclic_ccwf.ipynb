{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# Cyclic Weight Transfer (CWT) with Client-Controlled Cyclic Workflow\n",
    "\n",
    "In this example, we will demonstrate the Client-Controlled Cyclic Workflow using the Client API with the CIFAR10 dataset. \n",
    "This differs from the [Server-Controlled Cyclic Workflow](../cyclic/cyclic.ipynb), as the server is not involved in communication with sensitive information in the case that is it not trusted.\n",
    "\n",
    "## Client-Controlled Cyclic Workflow\n",
    "\n",
    "<img src=\"figs/cyclic_ccwf.png\" alt=\"cyclic ccwf\" width=35% height=35% />\n",
    "\n",
    "The `CyclicServerController` is responsible for managing the lifecycle of the job, and will assign `cyclic_config` and `cyclic_start` tasks for configuration and to begin the training workflow. The configuration includes picking the starting client, result clients, and defining the cyclic order.\n",
    "\n",
    "The `CyclicClientController` is responsible for the training logic once `cyclic_start` is sent, and the [Cyclic Workflow](../cyclic/cyclic.ipynb#cyclic_workflow) is algorithmically the same as the server-controlled version. The main difference is transferring the model is now encrypted with secure peer-to-peer messaging, and only the result clients receive the model, rather than the server.\n",
    "\n",
    "See the [docs](https://nvflare.readthedocs.io/en/main/programming_guide/controllers/client_controlled_workflows.html#cyclic-learning) for more information about the Client-Controlled Cyclic Workflow.\n",
    "\n",
    "## Converting DL training code to FL training code\n",
    "\n",
    "We will be using the [Client API FL code](../code/fl/train.py) trainer converted from the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example.\n",
    "\n",
    "See [Converting to FL code using Client API](../sag/sag.ipynb#code) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d41df",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Make sure the CIFAR10 dataset is downloaded with the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36c5e4",
   "metadata": {},
   "source": [
    "## Job API\n",
    "\n",
    "Let's use the Job API to create a CCWF Job.\n",
    "\n",
    "We use the `add_cyclic()` function to add our server_config and client_config.\n",
    "\n",
    "First add the `CyclicServerConfig` for the `CyclicServerController` with our desired parameters.\n",
    "Here we set the required number of rounds, and also increase the max status report interval to 300 seconds.\n",
    "\n",
    "Next we add the `CyclicClientConfig` for the `CyclicClientController` that handles all `cyclic_*` tasks and maps the `learn_task_name` to the `train` task handled by the `ScriptRunner` with our `train.py` script. The `PTFileModelPersistor` with the initial `Net()` model and the `FullModelShareableGenerator` are also added as components in the `CyclicClientConfig`.\n",
    "\n",
    "Below is the Job API script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64090e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "code_path = \"../code/fl\"\n",
    "if code_path not in sys.path:\n",
    "    sys.path.append(code_path)\n",
    "\n",
    "from net import Net\n",
    "\n",
    "from nvflare.app_common.ccwf.ccwf_job import CCWFJob, CyclicClientConfig, CyclicServerConfig\n",
    "from nvflare.app_common.ccwf.comps.simple_model_shareable_generator import SimpleModelShareableGenerator\n",
    "from nvflare.app_opt.pt.file_model_persistor import PTFileModelPersistor\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "n_clients = 2\n",
    "num_rounds = 3\n",
    "train_script = \"../code/fl/train.py\"\n",
    "\n",
    "job = CCWFJob(name=\"cifar10_cyclic\")\n",
    "\n",
    "job.add_cyclic(\n",
    "    server_config=CyclicServerConfig(num_rounds=num_rounds, max_status_report_interval=300),\n",
    "    client_config=CyclicClientConfig(\n",
    "        executor=ScriptRunner(script=train_script),\n",
    "        persistor=PTFileModelPersistor(model=Net()),\n",
    "        shareable_generator=SimpleModelShareableGenerator(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")\n",
    "job.simulator_run(\"/tmp/nvflare/jobs/workdir\", n_clients=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed5d4a",
   "metadata": {},
   "source": [
    "Ensure that the `train_script` is set to the Client API FL `train.py` code and the model path for the persistor is set to `net.Net`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run the Job\n",
    "\n",
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n",
    "If you want to run in production system, you will need to submit this exported job folder to nvflare system.\n",
    "\n",
    "Lastly, we have the [swarm](../swarm/swarm.ipynb) example, which covers swarm learning and client-controlled cross-site evaluation workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7827c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
