{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# Swarm Learning with Cross-Site Evaluation\n",
    "\n",
    "In this example, we will demonstrate the Swarm Learning and Client-Controlled Cross-Site Evaluation Workflows using the Client API and the CIFAR10 dataset. \n",
    "\n",
    "## Swarm Learning\n",
    "\n",
    "<img src=\"figs/swarm_learning.png\" alt=\"swarm ccwf\" width=35% height=35% />\n",
    "\n",
    "Swarm Learning is a decentralized Federated Averaging algorithm where the key difference is that the server is not trusted with any sensitive information. The server is now only responsible for job health and lifecycle management via the `SwarmServerController`, while the clients are now responsible for training and aggregration logic via the swarm client-controlled `SwarmClientController`.\n",
    "\n",
    "- `SwarmServerController`: manages swarm job lifecycle and configurations such as `aggr_clients` and `train_clients`\n",
    "- `SwarmClientController`: sends `learn_task`  to all training clients to invoke their executors for `train` task each round, and sends results to designated `aggr_client` for aggregration.\n",
    "\n",
    "Required tasks: `train`\n",
    "\n",
    "See the full definitions of [SwarmServerController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/swarm_server_ctl.py) and [SwarmClientController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/swarm_client_ctl.py) for all available arguments.\n",
    "\n",
    "## Client-Controlled Cross-Site Evaluation\n",
    "\n",
    "<img src=\"figs/client_controlled_cse.png\" alt=\"cse ccwf\" width=35% height=35% />\n",
    "\n",
    "In client-controlled cross-site evaluation, rather than sending client models to the server for distribution, clients instead communicate directly with each other to share their models for validation.\n",
    "\n",
    "See the [cse example](../cse/cse.ipynb) for more details on server-controlled cross-site evaluation for a comparison.\n",
    "\n",
    "- `CrossSiteEvalServerController`: manages evaluation workflow and configurations such as `evaluators` and `evaluatees`\n",
    "- `CrossSiteEvalClientController`: sends `eval` request to evaluators, evaluators send `get_model` task to evaluatees, evaluatees send their model back with `submit_model`, and evaluators perform `validate` on the model and send the results to the server. \n",
    "\n",
    "Required tasks: `validate`, `submit_model`\n",
    "\n",
    "See the full definitions of [CrossSiteEvalServerController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/cse_server_ctl.py) and [CrossSiteEvalClientController](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/ccwf/cse_client_ctl.py) for all available arguments.\n",
    "\n",
    "## Converting DL training code to FL training code\n",
    "We will be using the [Client API FL code](../code/fl/train.py) trainer converted from the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example.\n",
    "\n",
    "For more details on using the Client API with multi-task support, see [Converting DL training code to FL training code with Multi-Task Support](../cse/cse.ipynb#code).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e8bb1",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Make sure the CIFAR10 dataset is downloaded with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4861f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e15709",
   "metadata": {},
   "source": [
    "## Job API\n",
    "\n",
    "Let's use the Job API to create a CCWF Job.\n",
    "\n",
    "We use the `add_swarm()` function to add our server_config, client_config, and cse_config.\n",
    "\n",
    "First add the `SwarmServerConfig` with the number of rounds for the `SwarmServerController`.\n",
    "\n",
    "We also add `CrossSiteEvalConfig` for the `CrossSiteEvalServerController`.\n",
    "\n",
    "On the client side, we add the `SwarmClientConfig` for the `SwarmClientController` which maps the `learn_task_name` to `train` and add the `CrossSiteEvalClientController` which uses the `validate` and `submit_model` tasks. These task are handled by the `ScriptRunner` with our `train.py` script. Additionally, required components including the persistor with the initial `Net()` model, aggregator, and shareable generator are defined as client-side components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1729c19",
   "metadata": {},
   "source": [
    "Let's first copy the required files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../code/fl/train.py train.py\n",
    "! cp ../code/fl/net.py net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbd053",
   "metadata": {},
   "source": [
    "Then we can use Job API to easily create a job and run in simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import Net\n",
    "\n",
    "from nvflare.apis.dxo import DataKind\n",
    "from nvflare.app_common.aggregators.intime_accumulate_model_aggregator import InTimeAccumulateWeightedAggregator\n",
    "from nvflare.app_common.ccwf.ccwf_job import CCWFJob, CrossSiteEvalConfig, SwarmClientConfig, SwarmServerConfig\n",
    "from nvflare.app_common.ccwf.comps.simple_model_shareable_generator import SimpleModelShareableGenerator\n",
    "from nvflare.app_opt.pt.file_model_persistor import PTFileModelPersistor\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "n_clients = 2\n",
    "num_rounds = 3\n",
    "train_script = \"train.py\"\n",
    "\n",
    "job = CCWFJob(name=\"swarm\")\n",
    "aggregator = InTimeAccumulateWeightedAggregator(expected_data_kind=DataKind.WEIGHTS)\n",
    "job.add_swarm(\n",
    "    server_config=SwarmServerConfig(num_rounds=num_rounds),\n",
    "    client_config=SwarmClientConfig(\n",
    "        executor=ScriptRunner(script=train_script),\n",
    "        aggregator=aggregator,\n",
    "        persistor=PTFileModelPersistor(model=Net()),\n",
    "        shareable_generator=SimpleModelShareableGenerator(),\n",
    "    ),\n",
    "    cse_config=CrossSiteEvalConfig(eval_task_timeout=300),\n",
    ")\n",
    "\n",
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")\n",
    "job.simulator_run(\"/tmp/nvflare/jobs/workdir\", n_clients=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run the Job\n",
    "\n",
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n",
    "If you want to run in production system, you will need to submit this exported job folder to nvflare system.\n",
    "\n",
    "As an additional resource, also see the [Swarm Learning Example](../../../../advanced/swarm_learning/README.md) which utilizes the CIFAR10 ModelLearner instead of the Client API.\n",
    "\n",
    "Congratulations! You have completed the CIFAR10 step-by-step example series.\n",
    "Next take a look at the [higgs](../../higgs/README.md) example series for how to use machine learning methods for federated learning on tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef3134",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
