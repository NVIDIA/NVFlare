{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# FedAvg using Executor\n",
    "\n",
    "In this example, we will demonstrate the FegAvg algorithm using the CIFAR10 dataset using an Executor. \n",
    "\n",
    "While the previous example [FedAvg with SAG workflow](../sag/sag.ipynb#title) utilized the Client API, here we will demonstrate how to convert the original training code into a Executor trainer, showcase its capabilities, and recommend the best use cases.\n",
    "\n",
    "We build on top of the previous example [FedAvg algorithm](../sag/sag.ipynb#title)\n",
    "\n",
    "Please follow these steps before proceeding to the next section:\n",
    "  * [Understanding FedAvg and SAG](../sag/sag.ipynb#sag)\n",
    "\n",
    "## Executor\n",
    "\n",
    "An `Executor` in FLARE is an FLComponent for clients used for executing tasks, wherein the `execute` method receives and returns a `Shareable` object given a task name.\n",
    "\n",
    "Key Concepts:\n",
    "- Executor is a client-side FLComponent for executing tasks\n",
    "- Produces `Shareable` from input `Shareable` and handles `DXO` object conversion for standardized data passing\n",
    "- Directly uses FLARE-specific communication concepts, and as such serves as the basis of higher level learning APIs made to abstract these concepts away\n",
    "\n",
    "See the [documentation](https://nvflare.readthedocs.io/en/main/programming_guide/executor.html#executor) for more information about Executors and other FLARE-specific constructs.\n",
    "\n",
    "### When to use Executors\n",
    "\n",
    "The Executor is best used when implementing tasks and logic that do not fit the standard learning methods of higher level APIs such as the ModelLearner or Client API. In this example, in addition to the `train`, `validate`, and `submit_model` tasks, we also introduce the `get_weights` task. This pretrain task allows us to perform the `InitializeGlobalWeights` workflow, which would otherwise not be supported.\n",
    "\n",
    "## Converting DL training code to FL Executor training code\n",
    "We will use the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example\n",
    "in PyTorch as our base [DL code](../code/dl/train.py).\n",
    "\n",
    "In order to transform the existing PyTorch classifier training code into Federated Classifer training code, we must restructure our code to implement tasks to execute, as well as handle the data exchange formats. The converted code can be found at [FL Executor code](../code/fl/executor.py).\n",
    "\n",
    "Key changes:\n",
    "- Encapsulate the original DL train and validate code inside `local_train()` and `local_validate()` and the dataset and PyTorch training utilities in `initialize()`\n",
    "- Implement `execute` function to handle `get_weights`, `train`, `validate`, and `submit_model` tasks\n",
    "- Process incoming and outgoing `Shareable` objects, and converting to and from `DXO` objects\n",
    "- Implement `_save_local_model()` and `_load_local_model()` using the `PTPersistenceManager` to handle `ModelLearnable` object and manage the format for PyTorch model persistence.\n",
    "\n",
    "```\n",
    "def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n",
    "    try:\n",
    "        if task_name == self.pre_train_task_name:\n",
    "            # Get the new state dict and send as weights\n",
    "            return self._get_model_weights()\n",
    "        if task_name == self.train_task_name:\n",
    "            # Get model weights\n",
    "            try:\n",
    "                dxo = from_shareable(shareable)\n",
    "            except:\n",
    "                self.log_error(fl_ctx, \"Unable to extract dxo from shareable.\")\n",
    "                return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "            # Ensure data kind is weights.\n",
    "            if not dxo.data_kind == DataKind.WEIGHTS:\n",
    "                self.log_error(fl_ctx, f\"data_kind expected WEIGHTS but got {dxo.data_kind} instead.\")\n",
    "                return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "            # Convert weights to tensor. Run training\n",
    "            torch_weights = {k: torch.as_tensor(v) for k, v in dxo.data.items()}\n",
    "            self._local_train(fl_ctx, torch_weights)\n",
    "\n",
    "            # Check the abort_signal after training.\n",
    "            if abort_signal.triggered:\n",
    "                return make_reply(ReturnCode.TASK_ABORTED)\n",
    "\n",
    "            # Save the local model after training.\n",
    "            self._save_local_model(fl_ctx)\n",
    "\n",
    "            # Get the new state dict and send as weights\n",
    "            return self._get_model_weights()\n",
    "        if task_name == self.validate_task_name:\n",
    "            model_owner = \"?\"\n",
    "            try:\n",
    "                try:\n",
    "                    dxo = from_shareable(shareable)\n",
    "                except:\n",
    "                    self.log_error(fl_ctx, \"Error in extracting dxo from shareable.\")\n",
    "                    return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "                # Ensure data_kind is weights.\n",
    "                if not dxo.data_kind == DataKind.WEIGHTS:\n",
    "                    self.log_exception(fl_ctx, f\"DXO is of type {dxo.data_kind} but expected type WEIGHTS.\")\n",
    "                    return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "                # Extract weights and ensure they are tensor.\n",
    "                model_owner = shareable.get_header(AppConstants.MODEL_OWNER, \"?\")\n",
    "                weights = {k: torch.as_tensor(v, device=self.device) for k, v in dxo.data.items()}\n",
    "\n",
    "                # Get validation accuracy\n",
    "                val_accuracy = self._local_validate(fl_ctx, weights)\n",
    "                if abort_signal.triggered:\n",
    "                    return make_reply(ReturnCode.TASK_ABORTED)\n",
    "\n",
    "                self.log_info(\n",
    "                    fl_ctx,\n",
    "                    f\"Accuracy when validating {model_owner}'s model on\"\n",
    "                    f\" {fl_ctx.get_identity_name()}\"\n",
    "                    f\"s data: {val_accuracy}\",\n",
    "                )\n",
    "\n",
    "                dxo = DXO(data_kind=DataKind.METRICS, data={\"val_acc\": val_accuracy})\n",
    "                return dxo.to_shareable()\n",
    "            except:\n",
    "                self.log_exception(fl_ctx, f\"Exception in validating model from {model_owner}\")\n",
    "                return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n",
    "        elif task_name == self.submit_model_task_name:\n",
    "            # Load local model\n",
    "            ml = self._load_local_model(fl_ctx)\n",
    "\n",
    "            # Get the model parameters and create dxo from it\n",
    "            dxo = model_learnable_to_dxo(ml)\n",
    "            return dxo.to_shareable()\n",
    "        else:\n",
    "            return make_reply(ReturnCode.TASK_UNKNOWN)\n",
    "    except Exception as e:\n",
    "        self.log_exception(fl_ctx, f\"Exception in simple trainer: {e}.\")\n",
    "        return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e2b51",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Make sure the CIFAR10 dataset is downloaded with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de697fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py --dataset_path /tmp/nvflare/data/cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2bd7b",
   "metadata": {},
   "source": [
    "## Job Configuration\n",
    "\n",
    "Now we must install the Executor to the training client. We define our CIFAR10Executor in the client configuration, and list the implemented tasks.\n",
    "\n",
    "Let's first copy the required files over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec9f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../code/fl/net.py net.py\n",
    "! cp ../code/fl/executor.py executor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5faa03",
   "metadata": {},
   "source": [
    "We can use Job API to easily create a job and run in simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc55042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import Net\n",
    "from executor import CIFAR10Executor\n",
    "\n",
    "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_clients = 2\n",
    "    num_rounds = 5\n",
    "\n",
    "    job = FedAvgJob(\n",
    "        name=\"fedavg_executor\",\n",
    "        n_clients=n_clients,\n",
    "        num_rounds=num_rounds,\n",
    "        initial_model=Net()\n",
    "    )\n",
    "\n",
    "    # Add clients\n",
    "    for i in range(n_clients):\n",
    "        executor = CIFAR10Executor()\n",
    "        job.to(executor, f\"site-{i+1}\")\n",
    "\n",
    "\n",
    "    job.export_job(\"/tmp/nvflare/jobs\")\n",
    "    job.simulator_run(\"/tmp/nvflare/jobs/workdir\", gpu=\"0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run Job\n",
    "\n",
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n",
    "If you want to run in production system, you will need to submit this exported job folder to nvflare system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48271064",
   "metadata": {},
   "source": [
    "For additional resources, take a look at the various other executors with different use cases in the app_common, app_opt, and examples folder.\n",
    "\n",
    "In the previous examples we have finished covering each of Execution API types: the Client API, Model Learner, and Executor.\n",
    "Now we will be using the Client API in future examples to highlight other features and workflows.\n",
    "\n",
    "Next we have the [sag_mlflow](../sag_mlflow/sag_mlflow.ipynb) example, which shows how to enable MLflow experiment tracking logs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
