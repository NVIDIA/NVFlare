{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# FedAvg with SAG workflow using Executor\n",
    "\n",
    "In this example, we will demonstrate the FegAvg SAG workflow using the CIFAR10 dataset using an Executor. \n",
    "\n",
    "While the previous example [FedAvg with SAG workflow](../sag/sag.ipynb#title) utilized the Client API, here we will demonstrate how to convert the original training code into a Executor trainer, showcase its capabilities, and recommend the best use cases.\n",
    "\n",
    "For an overview on Federated Averaging and SAG, see the section from the previous example: [Understanding FedAvg and SAG](../sag/sag.ipynb#sag)\n",
    "\n",
    "## Executor\n",
    "\n",
    "An `Executor` in FLARE is an FLComponent for clients used for executing tasks, wherein the `execute` method receives and returns a `Shareable` object given a task name.\n",
    "\n",
    "Key Concepts:\n",
    "- Executor is a client-side FLComponent for executing tasks\n",
    "- Produces `Shareable` from input `Shareable` and handles `DXO` object conversion for standardized data passing\n",
    "- Directly uses FLARE-specific communication concepts, and as such serves as the basis of higher level learning APIs made to abstract these concepts away\n",
    "\n",
    "See the [documentation](https://nvflare.readthedocs.io/en/main/programming_guide/executor.html#executor) for more information about Executors and other FLARE-specific constructs.\n",
    "\n",
    "### When to use Executors\n",
    "\n",
    "The Executor is best used when implementing tasks and logic that do not fit the standard learning methods of higher level APIs such as the ModelLearner or Client API. In this example, in addition to the `train`, `validate`, and `submit_model` tasks, we also introduce the `get_weights` task. This pretrain task allows us to perform the `InitializeGlobalWeights` workflow, which would otherwise not be supported.\n",
    "\n",
    "## Converting DL training code to FL Executor training code\n",
    "We will use the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example\n",
    "in PyTorch as our base [DL code](../code/dl/train.py).\n",
    "\n",
    "In order to transform the existing PyTorch classifier training code into Federated Classifer training code, we must restructure our code to implement tasks to execute, as well as handle the data exchange formats. The converted code can be found at [FL Executor code](../code/fl/executor.py).\n",
    "\n",
    "Key changes:\n",
    "- Encapsulate the original DL train and validate code inside `local_train()` and `local_validate()` and the dataset and PyTorch training utilities in `initialize()`\n",
    "- Implement `execute` function to handle `get_weights`, `train`, `validate`, and `submit_model` tasks\n",
    "- Process incoming and outgoing `Shareable` objects, and converting to and from `DXO` objects\n",
    "- Implement `_save_local_model()` and `_load_local_model()` using the `PTPersistenceManager` to handle `ModelLearnable` object and manage the format for PyTorch model persistence.\n",
    "\n",
    "```\n",
    "def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n",
    "    try:\n",
    "        if task_name == self.pre_train_task_name:\n",
    "            # Get the new state dict and send as weights\n",
    "            return self._get_model_weights()\n",
    "        if task_name == self.train_task_name:\n",
    "            # Get model weights\n",
    "            try:\n",
    "                dxo = from_shareable(shareable)\n",
    "            except:\n",
    "                self.log_error(fl_ctx, \"Unable to extract dxo from shareable.\")\n",
    "                return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "            # Ensure data kind is weights.\n",
    "            if not dxo.data_kind == DataKind.WEIGHTS:\n",
    "                self.log_error(fl_ctx, f\"data_kind expected WEIGHTS but got {dxo.data_kind} instead.\")\n",
    "                return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "            # Convert weights to tensor. Run training\n",
    "            torch_weights = {k: torch.as_tensor(v) for k, v in dxo.data.items()}\n",
    "            self._local_train(fl_ctx, torch_weights)\n",
    "\n",
    "            # Check the abort_signal after training.\n",
    "            if abort_signal.triggered:\n",
    "                return make_reply(ReturnCode.TASK_ABORTED)\n",
    "\n",
    "            # Save the local model after training.\n",
    "            self._save_local_model(fl_ctx)\n",
    "\n",
    "            # Get the new state dict and send as weights\n",
    "            return self._get_model_weights()\n",
    "        if task_name == self.validate_task_name:\n",
    "            model_owner = \"?\"\n",
    "            try:\n",
    "                try:\n",
    "                    dxo = from_shareable(shareable)\n",
    "                except:\n",
    "                    self.log_error(fl_ctx, \"Error in extracting dxo from shareable.\")\n",
    "                    return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "                # Ensure data_kind is weights.\n",
    "                if not dxo.data_kind == DataKind.WEIGHTS:\n",
    "                    self.log_exception(fl_ctx, f\"DXO is of type {dxo.data_kind} but expected type WEIGHTS.\")\n",
    "                    return make_reply(ReturnCode.BAD_TASK_DATA)\n",
    "\n",
    "                # Extract weights and ensure they are tensor.\n",
    "                model_owner = shareable.get_header(AppConstants.MODEL_OWNER, \"?\")\n",
    "                weights = {k: torch.as_tensor(v, device=self.device) for k, v in dxo.data.items()}\n",
    "\n",
    "                # Get validation accuracy\n",
    "                val_accuracy = self._local_validate(fl_ctx, weights)\n",
    "                if abort_signal.triggered:\n",
    "                    return make_reply(ReturnCode.TASK_ABORTED)\n",
    "\n",
    "                self.log_info(\n",
    "                    fl_ctx,\n",
    "                    f\"Accuracy when validating {model_owner}'s model on\"\n",
    "                    f\" {fl_ctx.get_identity_name()}\"\n",
    "                    f\"s data: {val_accuracy}\",\n",
    "                )\n",
    "\n",
    "                dxo = DXO(data_kind=DataKind.METRICS, data={\"val_acc\": val_accuracy})\n",
    "                return dxo.to_shareable()\n",
    "            except:\n",
    "                self.log_exception(fl_ctx, f\"Exception in validating model from {model_owner}\")\n",
    "                return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n",
    "        elif task_name == self.submit_model_task_name:\n",
    "            # Load local model\n",
    "            ml = self._load_local_model(fl_ctx)\n",
    "\n",
    "            # Get the model parameters and create dxo from it\n",
    "            dxo = model_learnable_to_dxo(ml)\n",
    "            return dxo.to_shareable()\n",
    "        else:\n",
    "            return make_reply(ReturnCode.TASK_UNKNOWN)\n",
    "    except Exception as e:\n",
    "        self.log_exception(fl_ctx, f\"Exception in simple trainer: {e}.\")\n",
    "        return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n",
    "...\n",
    "```\n",
    "\n",
    "## Job Configuration\n",
    "\n",
    "Now we must install the Executor to the training client. We define our CIFAR10Executor in the client configuration, and list the implemented tasks.\n",
    "\n",
    "Since our CIFAR10Executor supports the get_weights, train, validate, and submit_model tasks, we can use the InitializeGlobalWeights, ScatterAndGather, and CrossSiteModelEval (see [CSE example](../cse/cse.ipynb)) workflows in the server configuration.\n",
    "\n",
    "Let's use the Job CLI to create the job from an PyTorch Executor template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de430380",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/jobs/sag_pt_executor -w sag_pt_executor -sd ../code/fl -force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8e88f",
   "metadata": {},
   "source": [
    "We can take a look at the server and client configurations and make any changes as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /tmp/nvflare/jobs/sag_pt_executor/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /tmp/nvflare/jobs/sag_pt_executor/app/config/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc8869",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63bf0f",
   "metadata": {},
   "source": [
    "Make sure the CIFAR10 dataset is downloaded with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17323f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run the Job\n",
    "\n",
    "Now we can run the job with the simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70738539-3df6-4779-831f-0a1375d6aabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare simulator /tmp/nvflare/jobs/sag_pt_executor -w /tmp/nvflare/sag_pt_executor -t 2 -n 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48271064",
   "metadata": {},
   "source": [
    "For additional resources, take a look at the various other executors with different use cases in the app_common, app_opt, and examples folder.\n",
    "\n",
    "In the previous examples we have finished covering each of Execution API types: the Client API, Model Learner, and Executor.\n",
    "Now we will be using the Client API in future examples to highlight other features and workflows.\n",
    "\n",
    "Next we have the [sag_mlflow](../sag_mlflow/sag_mlflow.ipynb) example, which shows how to enable MLflow experiment tracking logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef3134",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
