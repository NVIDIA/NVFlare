{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# Cyclic Weight Transfer (CWT) with Cyclic Workflow\n",
    "\n",
    "In this example, we will demonstrate the Cyclic workflow using the Client API with the CIFAR10 dataset. \n",
    "\n",
    "## Cyclic Workflow\n",
    "<a id = \"cyclic_workflow\"></a>\n",
    "\n",
    "Cyclic Weight Transfer (CWF) uses the server-controlled `CyclicController` to pass the model weights from one site to the next in a cyclic fashion. \n",
    "\n",
    "In the Cyclic workflow, sites train one at a time, while sending the model to the next site. The order of the sites can be specifed as fixed, random, or random (without same in a row).  A round is finished once all sites in the defined order have completed training once, and the final result is returned to the server. This differs from Scatter-and-Gather, wherein all sites train simultaneously and aggregrate their results together at the end of a round.\n",
    "\n",
    "## Converting DL training code to FL training code\n",
    "\n",
    "We will be using the [Client API FL code](../code/fl/train.py) trainer converted from the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example.\n",
    "\n",
    "See [Converting to FL code using Client API](../sag/sag.ipynb#code) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea004ad8",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65761292",
   "metadata": {},
   "source": [
    "## Job Configuration\n",
    "\n",
    "The client configuration for the trainer with the Client API is standard with the `PTClientAPILauncherExecutor`, `SubprocessLauncher`, and our defined `train.py` that supports the `train` task. This is the same configuration used in the SAG pt workflow.\n",
    "\n",
    "For the server configuration we use the `CyclicController` for the workflow, and define arguments such as number of rounds, order of relaying sites, and the `train` task name that the clients support. The two required components ids are also mapped to the corresponding `PTFileModelPersistor` and `FullModelShareableGenerator` defined under components.\n",
    "\n",
    "Let's first copy the required files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../code/fl/train.py train.py\n",
    "! cp ../code/fl/net.py net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495568f",
   "metadata": {},
   "source": [
    "Then we can use Job API to easily create a job and run in simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import Net\n",
    "from nvflare import FedJob\n",
    "from nvflare.app_common.workflows.cyclic import Cyclic\n",
    "from nvflare.app_opt.pt.job_config.model import PTModel\n",
    "from nvflare.job_config.script_runner import FrameworkType, ScriptRunner\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_clients = 2\n",
    "    num_rounds = 3\n",
    "    train_script = \"train.py\"\n",
    "\n",
    "    job = FedJob(name=\"cyclic\")\n",
    "\n",
    "    # Define the controller workflow and send to server\n",
    "    controller = Cyclic(\n",
    "        num_clients=n_clients,\n",
    "        num_rounds=num_rounds,\n",
    "    )\n",
    "    job.to(controller, \"server\")\n",
    "\n",
    "    # Define the initial global model and send to server\n",
    "    job.to(PTModel(Net()), \"server\")\n",
    "\n",
    "    # Add clients\n",
    "    for i in range(n_clients):\n",
    "        runner = ScriptRunner(\n",
    "            script=train_script,\n",
    "            script_args=\"\",\n",
    "        )\n",
    "        job.to(runner, f\"site-{i+1}\")\n",
    "\n",
    "    job.export_job(\"/tmp/nvflare/jobs\")\n",
    "    job.simulator_run(\"/tmp/nvflare/jobs/workdir\", gpu=\"0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed5d4a",
   "metadata": {},
   "source": [
    "Ensure that the `app_script` is set to the Client API FL `train.py` code and the model path for the persistor is set to the `net.Net`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run Job\n",
    "\n",
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n",
    "If you want to run in production system, you will need to submit this exported job folder to nvflare system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48271064",
   "metadata": {},
   "source": [
    "As an additional resource, also see the [hello-cyclic](../../../../hello-world/hello-cyclic/README.md) for a Tensorflow Executor implementation using the MNIST dataset.\n",
    "\n",
    "While this example focused on the server-controlled cyclic workflow, now we will introduce the idea of client-controlled workflows.\n",
    "The next [cyclic_ccwf](../cyclic_ccwf/cyclic_ccwf.ipynb) example is a client-controlled version of the cyclic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef3134",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
