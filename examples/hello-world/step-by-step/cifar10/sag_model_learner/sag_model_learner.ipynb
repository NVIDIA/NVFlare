{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514c47e2-420d-4af4-9bf0-cac337c51c39",
   "metadata": {},
   "source": [
    "# FedAvg algorithm with Model Learner\n",
    "\n",
    "In this example, we will demonstrate the FegAvg algorithm using the CIFAR10 dataset and the ModelLearner API. \n",
    "\n",
    "While the previous example [FedAvg algorithm](../sag/sag.ipynb#title) utilized the Client API, here we will demonstrate how to convert the original training code into a ModelLearner trainer, showcase its capabilities, and recommend the best use cases.\n",
    "\n",
    "We build on top of the previous example [FedAvg algorithm](../sag/sag.ipynb#title)\n",
    "\n",
    "Please follow these steps before proceeding to the next section:\n",
    "  * [Understanding FedAvg and SAG](../sag/sag.ipynb#sag)\n",
    "\n",
    "## ModelLearner\n",
    "\n",
    "The main goal of the ModelLearner is to make it easier to write learning logic by minimizing FLARE specific concepts that the user is exposed to. The ModelLearner defines familiar learning functions for training and validation, and uses the FLModel object for transferring learning information.\n",
    "\n",
    "Key Concepts:\n",
    "- Learning\n",
    "    - `FLModel` object defines structure to contain essential information about the learning task, such as `params`, `metrics`, `meta`, etc.\n",
    "    - learning logic implemented in `train()` and `validate` methods, which both receive and send an `FLModel` object\n",
    "    - return requested model via `get_model()`\n",
    "- Lifecycle\n",
    "    - `initialize` for logic before learning job start and `finalize` for once learning job is finished\n",
    "    - abort gracefully with `abort()` or `is_aborted()`\n",
    "- Convenience \n",
    "    - various logging methods such as `info`, `debug`, `error`, etc.\n",
    "    - contextual information availabled in learner\n",
    "\n",
    "\n",
    "Here are the full definitions of the APIs for the [ModelLearner](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/abstract/model_learner.py) and [FLModel](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/abstract/fl_model.py).\n",
    "\n",
    "### When to use ModelLearner\n",
    "\n",
    "The ModelLearner is best used when working with standard machine learning code that can fit well into the train and validate methods and can be easily adapated to the ModelLearner structure. This allows for the separation of FLARE specific communication constructs from the machine learning specific tasks, and provides the FLModel object for data transfer. \n",
    "\n",
    "On the otherhand, if the user would rather not adapt the code structure, we recommend using the [Client API](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/ml-to-fl/README.md) for even simpler conversion to FL code at the cost of losing some convenience functionalities.\n",
    "\n",
    "Finally, if the user wishes to implement something more specific that is not supported by the ModelLearner, we recommend writing an Executor which gives greater freedom for defining logic and tasks. The main tradeoff is this requires the use of more FLARE concepts such as FLContext, Shareable, DXO, etc.\n",
    "\n",
    "\n",
    "## Converting DL training code to FL ModelLearner training code\n",
    "We will use the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example\n",
    "in PyTorch as our base [DL code](../code/dl/train.py).\n",
    "\n",
    "With the FLARE ModelLearner API, we need to transform the existing PyTorch classifer into a Federated classifer by restructuring our code to subclass ModelLearner, and implementing the required methods. The converted code can be found at [FL ModelLearner code](../code/fl/model_learner.py).\n",
    "\n",
    "Key Changes:\n",
    "- Subclass ModelLearner with appropriate init args\n",
    "- Encapsulate the original DL train and validate code inside `local_train()` and `local_validate()` and the dataset and PyTorch training utilities in `initialize()`\n",
    "- Implement the `train()` and `validate()` methods by wrapping the local learning methods and processing and returning `FLModel`\n",
    "- Implement `get_model()` method to load and return best local model, so it can then be sent to other sites for validation (via the cross-site evaluation workflow)\n",
    "\n",
    "```\n",
    "def get_model(self, model_name: str) -> Union[str, FLModel]:\n",
    "    # Retrieve the best local model saved during training.\n",
    "    if model_name == ModelName.BEST_MODEL:\n",
    "        try:\n",
    "            model_data = torch.load(self.model_path, map_location=\"cpu\")\n",
    "            np_model_data = {k: v.cpu().numpy() for k, v in model_data.items()}\n",
    "\n",
    "            return FLModel(params_type=ParamsType.FULL, params=np_model_data)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to load best model\") from e\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_name}\")  # Raised errors are caught in LearnerExecutor class.\n",
    "\n",
    "def train(self, model: FLModel) -> Union[str, FLModel]:\n",
    "    self.info(f\"Current/Total Round: {self.current_round + 1}/{self.total_rounds}\")\n",
    "    self.info(f\"Client identity: {self.site_name}\")\n",
    "\n",
    "    pt_input_params = {k: torch.as_tensor(v) for k, v in model.params.items()}\n",
    "    self._local_train(pt_input_params)\n",
    "\n",
    "    pt_output_params = {k: torch.as_tensor(v) for k, v in self.net.cpu().state_dict().items()}\n",
    "    accuracy = self._local_validate(pt_output_params)\n",
    "\n",
    "    if accuracy > self.best_acc:\n",
    "        self.best_acc = accuracy\n",
    "        torch.save(self.net.state_dict(), self.model_path)\n",
    "\n",
    "    np_output_params = {k: v.cpu().numpy() for k, v in self.net.cpu().state_dict().items()}\n",
    "    return FLModel(\n",
    "        params=np_output_params,\n",
    "        metrics={\"accuracy\": accuracy},\n",
    "        meta={\"NUM_STEPS_CURRENT_ROUND\": 2 * len(self.trainloader)},\n",
    "    )\n",
    "\n",
    "def validate(self, model: FLModel) -> Union[str, FLModel]:\n",
    "    pt_params = {k: torch.as_tensor(v) for k, v in model.params.items()}\n",
    "    val_accuracy = self._local_validate(pt_params)\n",
    "\n",
    "    return FLModel(metrics={\"val_accuracy\": val_accuracy})\n",
    "\n",
    "...\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f8a58",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Make sure the CIFAR10 dataset is downloaded with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e686dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../data/download.py --dataset_path /tmp/nvflare/data/cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635d93a",
   "metadata": {},
   "source": [
    "## Job Configuration\n",
    "\n",
    "Now we must install the ModelLearner to the training clients. We use the predefined `ModelLearnerExecutor`, which handles setting up the Learner and executing the tasks using the ModelLearner methods. In the client configuration, the `learner_id` of the `ModelLearnerExecutor` is mapped to the `id` of the ModelLearner trainer component that we implemented.\n",
    "\n",
    "We can use Job API to easily create a job and run in simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de430380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "code_path = \"../code/fl\"\n",
    "if code_path not in sys.path:\n",
    "    sys.path.append(code_path)\n",
    "\n",
    "from net import Net\n",
    "from model_learner import CIFAR10ModelLearner\n",
    "\n",
    "from nvflare.app_opt.pt.job_config.fed_avg import FedAvgJob\n",
    "from nvflare.app_common.executors.model_learner_executor import ModelLearnerExecutor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_clients = 2\n",
    "    num_rounds = 5\n",
    "\n",
    "    job = FedAvgJob(\n",
    "        name=\"cifar10_fedavg_model_learner\",\n",
    "        n_clients=n_clients,\n",
    "        num_rounds=num_rounds,\n",
    "        initial_model=Net()\n",
    "    )\n",
    "\n",
    "    # Add clients\n",
    "    for i in range(n_clients):\n",
    "        executor = ModelLearnerExecutor(\n",
    "            learner_id = job.to(CIFAR10ModelLearner(), f\"site-{i+1}\")\n",
    "        )\n",
    "        job.to(executor, f\"site-{i+1}\")\n",
    "\n",
    "\n",
    "    job.export_job(\"/tmp/nvflare/jobs\")\n",
    "    job.simulator_run(\"/tmp/nvflare/jobs/workdir\", gpu=\"0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3c9f-8185-47d3-8658-40f7b16699c5",
   "metadata": {},
   "source": [
    "## Run Job\n",
    "\n",
    "The previous cell exports the job config and executes the job in NVFlare simulator.\n",
    "\n",
    "If you want to run in production system, you will need to submit this exported job folder to nvflare system.\n",
    "\n",
    "We can check the content of a job folder using tree command or ls -all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70738539-3df6-4779-831f-0a1375d6aabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree /tmp/nvflare/jobs/cifar10_fedavg_model_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48271064",
   "metadata": {},
   "source": [
    "As an additional resource, also see the [CIFAR10 examples](../../../../advanced/cifar10/README.md) for a comprehensive implementation of a PyTorch ModelLearner.\n",
    "\n",
    "In the next example [sag_executor](../sag_executor/sag_executor.ipynb), we will illustrate how to use the Executor API for more specific use cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
