{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a554d44-78e0-4078-bf85-bfa2d0551cc0",
   "metadata": {},
   "source": [
    "# FedAvg Algorithm with SAG (Scatter & Gather) workflow\n",
    "\n",
    "In this example, we will demonstrate the SAG workflow with FedAvg using CIFAR10 dataset. \n",
    "\n",
    "Both Job Lifecycle and training workflow are controlled on the **server side**, we will just use the existing available SAG controller availalbe in NVFLARE. \n",
    "\n",
    "For client side training code, we will leverage new DL to FL **Client API**\n",
    "\n",
    "First, Let's look at the FedAvg Algorithm and SAG Workflow. \n",
    "\n",
    "## FedAvg with SAG\n",
    "<img src=\"fed_avg.png\" alt=\"FedAvg\" width=50% height=45% /> <img src=\"sag.png\" alt=\"Scatter and Gather\" width=40% height=40% />\n",
    "\n",
    "The Fed Avg aggregation is done on the server side, its weighted on the number of training steps on each client\n",
    " \n",
    "## Convert training code to federated learning training code\n",
    "\n",
    "We will use the original [Training a Classifer](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) example\n",
    "in pytorch as the code base. The cleanup code (remove comments etc.) can be found in [here](../code/dl/train.py)\n",
    "\n",
    "\n",
    "With the NVFLARE DL to FL Client APIs, we need to transform the existing pytorch classifer training code into Federated Classifer training code with few lines of code changes. The already converted code can be found in **[here](../code/fl/train.py)**\n",
    "\n",
    "For detailed discussion how to convert training code into federated learning training code using Client API, you can also checked out the examples [here](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/ml-to-fl/README.md) and code \n",
    "\n",
    "The key changes are the following steps: \n",
    "\n",
    "```\n",
    "    #  import nvflare client API\n",
    "    import nvflare.client as flare\n",
    "\n",
    "    #  initializes NVFlare client API\n",
    "    flare.init()\n",
    "\n",
    "    # gets FLModel from NVFlare\n",
    "    input_model = flare.receive()\n",
    "\n",
    "    # loads model from NVFlare\n",
    "    net.load_state_dict(input_model.params)\n",
    "\n",
    "    # evaluate on received model\n",
    "    accuracy = evaluate(input_model.params)\n",
    "    \n",
    "    # construct trained FL model\n",
    "    output_model = flare.FLModel(\n",
    "        params=net.cpu().state_dict(),\n",
    "        metrics={\"accuracy\": accuracy},\n",
    "        meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "    )\n",
    "    \n",
    "    # send model back to NVFlare\n",
    "    flare.send(output_model)\n",
    "```\n",
    "\n",
    "If you are using pytorch-lightning, the changes are much smaller, 1-line import , 1-line change applies to trainer, 1-line global model evaluation. see [cifar10_lightning_examples](https://github.com/NVIDIA/NVFlare/blob/main/examples/hello-world/ml-to-fl/codes/cifar10_lightning.py) \n",
    "# Prepare Data\n",
    "\n",
    "Let's get the data first. Follow the instruction of cifar10, we can download the data with following scripts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e487166-1e47-47db-83cc-f482735b76a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIFAR10_ROOT = \"/tmp/nvflare/data/cifar10\"\n",
    "\n",
    "! python ../data/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667a9be-a911-4485-a3cb-cc2067852545",
   "metadata": {},
   "source": [
    "## Job Folder and Configurations\n",
    "\n",
    "Now we need to setup the configurations for server and clients and constructure Job folder NVFLARE needed to run. We can do this using NVFLARE job CLI. You can study the [Job CLI tutorials](https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/job_cli.ipynb) later with all the details. But for now, you can just use the following commands\n",
    "\n",
    "* Find out the available job templates\n",
    "\n",
    "We need to set the job templates directory, so the job cli commands can find the job templates. If have already set NVFLARE_HOME=```<NVFLARE git clone directory> ```then, you can skipt the folllowing step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d4443-a274-4176-a5ac-b36008178d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare config -jt ../../../../../job_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608e860-ba67-4c5c-8219-acf5d52860f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c354739-e464-4bca-afbe-eb04baa5751d",
   "metadata": {},
   "source": [
    "* Create job folder and initial configs\n",
    "\n",
    "The template **'sag_pt'** seems to fit our needs: SAG with pytorch, using client API. Lets create a job folder with this template initially without specifying the code location, just see what's needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b39c7-6744-48b4-b73c-47d64c945102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/jobs/cifar10_sag_pt -w sag_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78d674-5d4f-4d2a-8c70-90e538f86727",
   "metadata": {},
   "source": [
    "Lets also looks at the server and client configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6688e-1072-45b2-b6e1-cd240807d9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/jobs/cifar10_sag_pt/app/config/config_fed_server.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174903e1-824d-4a7b-98c4-e190d357a431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/jobs/cifar10_sag_pt/app/config/config_fed_client.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03f275-9810-4617-b007-b4e62113e434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /tmp/nvflare/jobs/cifar10_sag_pt/app/config/config_exchange.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb79b5c-f97f-472f-91a5-5a5175fb9759",
   "metadata": {},
   "source": [
    "* Create job folder with all the configs\n",
    "\n",
    "Let's change the num_rounds = 5, script = train.py, min_clients = 2 for meta.conf.  We also like to change the arguments for train.py \n",
    "dataset_path=CIFAR10_ROOT, batch_size=6, num_workers = 2. Here dataset_path is actually not changed, but we just want to show you could change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10603e48-ef80-46fc-9163-e287ce43c803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare job create -j /tmp/nvflare/jobs/cifar10_sag_pt -w sag_pt -f meta.conf min_clients=2 -force -f config_fed_server.conf num_rounds=5 -s ../code/fl/train.py -sd ../code/fl -a batch_size=6 dataset_path={CIFAR10_ROOT} num_workers=2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208467c-8cf7-4446-963e-af92f79bfad5",
   "metadata": {},
   "source": [
    "OK, we are ready to run the job, let's look at the job folder, use \"ls -al\" if you don't have \"tree\" installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf68fbb-eefc-4268-b341-2558dfe35c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree /tmp/nvflare/jobs/cifar10_sag_pt  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05147756-57b3-4976-bddf-794a1cd0fd4d",
   "metadata": {},
   "source": [
    "## Run Job\n",
    "We can use simulator to run the job directly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd4d00-810f-416c-a2e1-e469a9697e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! nvflare simulator /tmp/nvflare/jobs/cifar10_sag_pt  -w /tmp/nvflare/jobs/cifar10_sag_pt_workspace -t 2 -n 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055bde7-432d-4e6b-9163-b5ab7ede7b73",
   "metadata": {},
   "source": [
    "The job should be running in the simulator mode. We are done with the training. Now we have done this. Let's move on to the next examaple and see how can we monitoring the losses in MLFlow or Tensorboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
