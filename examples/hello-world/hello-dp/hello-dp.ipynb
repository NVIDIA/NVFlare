{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with NVFlare: Differential Privacy with DP-SGD\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/NVFlare/blob/main/examples/hello-world/hello-dp/hello-dp.ipynb)\n",
        "\n",
        "This example demonstrates how to use NVIDIA FLARE with PyTorch and **Differential Privacy (DP)** to train a regression model with privacy guarantees. We use [Opacus](https://opacus.ai) to implement DP-SGD (Differentially Private Stochastic Gradient Descent) during local client training on each client. This achieves sample-level differential privacy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Differential Privacy?\n",
        "\n",
        "[Differential Privacy (DP)](https://en.wikipedia.org/wiki/Differential_privacy) is a rigorous mathematical framework designed to provide strong privacy guarantees when handling sensitive data. In Federated Learning (FL), DP protects user information by adding carefully calibrated noise to the model updates during training.\n",
        "\n",
        "**DP-SGD** (Differentially Private Stochastic Gradient Descent) adds noise during each optimization step:\n",
        "1. **Gradient Clipping**: Gradients are clipped to a maximum norm to bound their sensitivity\n",
        "2. **Noise Addition**: Gaussian noise is added to the clipped gradients  \n",
        "3. **Privacy Accounting**: The privacy budget (ε, δ) is tracked across training steps\n",
        "\n",
        "The privacy guarantee is characterized by:\n",
        "- **ε (epsilon)**: Privacy budget - **smaller values = stronger privacy** (more noise)\n",
        "- **δ (delta)**: Probability of privacy breach - typically set to 1/n² where n is dataset size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If running in Google Colab, download the source code for this example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --ignore-installed blinker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! npx --yes degit -f NVIDIA/NVFlare/examples/hello-world/hello-dp ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install nvflare and dependencies (including opacus for DP):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset: California Housing\n",
        "\n",
        "This example uses the [California Housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) - a regression problem to predict median house values.\n",
        "\n",
        "**Dataset characteristics:**\n",
        "- 20,640 samples\n",
        "- 8 features (median income, house age, average rooms, etc.)\n",
        "- 1 target (median house value)\n",
        "\n",
        "The dataset is automatically partitioned across clients, so each client has a non-overlapping subset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model: Tabular MLP\n",
        "\n",
        "We use a simple Multi-Layer Perceptron (MLP) for tabular data regression. See [model.py](model.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TabularMLP(nn.Module):\n",
        "    \"\"\"Simple Multi-Layer Perceptron for tabular data regression\"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim=8, hidden_dims=[64, 32], output_dim=1):\n",
        "        super(TabularMLP, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        \n",
        "        # Build hidden layers\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "        \n",
        "        self.model = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The architecture:\n",
        "- **Input layer**: 8 features\n",
        "- **Hidden layers**: 64 → 32 neurons with ReLU activation and dropout\n",
        "- **Output layer**: 1 neuron (house price prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Client Code with Differential Privacy\n",
        "\n",
        "The client code [client.py](client.py) implements DP-SGD using **Opacus**. The key difference from standard training is adding the `PrivacyEngine`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "from opacus import PrivacyEngine\n",
        "import nvflare.client as flare\n",
        "\n",
        "# Initialize NVFlare client\n",
        "flare.init()\n",
        "\n",
        "while flare.is_running():\n",
        "    # Receive model from server\n",
        "    input_model = flare.receive()\n",
        "    model.load_state_dict(input_model.params)\n",
        "    \n",
        "    # === Apply Differential Privacy ===\n",
        "    privacy_engine = PrivacyEngine()\n",
        "    model, optimizer, train_loader = privacy_engine.make_private(\n",
        "        module=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=train_loader,\n",
        "        noise_multiplier=1.1,  # Controls noise level\n",
        "        max_grad_norm=1.0,      # Gradient clipping threshold\n",
        "    )\n",
        "    # ==================================\n",
        "    \n",
        "    # Train as usual - PrivacyEngine handles gradient clipping & noise\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(data), target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    # Check privacy budget spent\n",
        "    epsilon = privacy_engine.get_epsilon(delta)\n",
        "    print(f\"Privacy spent: (ε = {epsilon:.2f}, δ = {delta})\")\n",
        "    \n",
        "    # Send model back (note: use _module to get original model)\n",
        "    output_model = flare.FLModel(\n",
        "        params=model._module.state_dict(),\n",
        "        metrics={\"rmse\": rmse, \"privacy_epsilon\": epsilon}\n",
        "    )\n",
        "    flare.send(output_model)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `PrivacyEngine.make_private()` method:\n",
        "1. Wraps the model to enable per-sample gradient computation\n",
        "2. Modifies the optimizer to clip gradients and add noise\n",
        "3. Wraps the data loader for privacy accounting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run FL Experiment with DP\n",
        "\n",
        "Now we'll create a federated job that trains the model with differential privacy across multiple clients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Define the FedJob Recipe\n",
        "\n",
        "We use the `FedAvgRecipe` which implements the FedAvg algorithm. No custom server code needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import TabularMLP\n",
        "\n",
        "from nvflare.app_opt.pt.recipes.fedavg import FedAvgRecipe\n",
        "from nvflare.recipe import SimEnv, add_experiment_tracking\n",
        "from nvflare.recipe.utils import add_cross_site_evaluation\n",
        "\n",
        "n_clients = 2\n",
        "num_rounds = 5\n",
        "batch_size = 64\n",
        "target_epsilon = 1.0  # Total privacy budget (cumulative across all rounds)\n",
        "\n",
        "recipe = FedAvgRecipe(\n",
        "    name=\"hello-dp\",\n",
        "    min_clients=n_clients,\n",
        "    num_rounds=num_rounds,\n",
        "    initial_model=TabularMLP(input_dim=8, hidden_dims=[64, 32], output_dim=1),\n",
        "    train_script=\"client.py\",\n",
        "    train_args=f\"--batch_size {batch_size} --target_epsilon {target_epsilon} --n_clients {n_clients}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Add experiment tracking\n",
        "\n",
        "Enable TensorBoard to visualize training metrics and privacy budget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_experiment_tracking(recipe, tracking_type=\"tensorboard\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. (Optional) Add Cross-Site Evaluation\n",
        "\n",
        "Uncomment to evaluate trained models across all client sites:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to enable cross-site evaluation\n",
        "# add_cross_site_evaluation(recipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Run the FL Job\n",
        "\n",
        "Execute the federated learning job in simulation mode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = SimEnv(num_clients=n_clients)\n",
        "run = recipe.execute(env)\n",
        "print()\n",
        "print(\"Job Status is:\", run.get_status())\n",
        "print(\"Result can be found in:\", run.get_result())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "You can visualize training metrics and privacy budget using TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --bind_all --logdir /tmp/nvflare/simulation/hello-dp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics to Monitor:\n",
        "- **train_loss**: Training loss over time\n",
        "- **rmse**: Root Mean Squared Error on test set\n",
        "- **privacy_epsilon**: Privacy budget spent (ε)\n",
        "\n",
        "If you enabled cross-site evaluation, view results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "try:\n",
        "    with open('/tmp/nvflare/simulation/hello-dp/server/simulate_job/cross_site_val/cross_val_results.json') as f:\n",
        "        print(json.dumps(json.load(f), indent=2))\n",
        "except FileNotFoundError:\n",
        "    print(\"Cross-site evaluation not enabled. Uncomment add_cross_site_evaluation(recipe) to enable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Privacy-Utility Trade-off\n",
        "\n",
        "Experiment with different epsilon values to observe the privacy-utility trade-off. **Note**: Epsilon is cumulative across all federated rounds.\n",
        "\n",
        "| Epsilon (ε) | Privacy Level | Model Accuracy | Use Case |\n",
        "|-------------|---------------|----------------|----------|\n",
        "| ε ≤ 0.5     | Very Strong   | Lower          | Highly sensitive |\n",
        "| ε = 0.5-1.0 | Strong        | Moderate       | Sensitive data |\n",
        "| ε = 1.0-3.0 | Moderate      | Good (default) | General private |\n",
        "| ε > 10      | Weak          | High           | Minimal privacy |\n",
        "\n",
        "Try running with different epsilon values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Try with different privacy levels\n",
        "# Uncomment and run to compare results\n",
        "\n",
        "# Stronger privacy (lower epsilon)\n",
        "# target_epsilon = 0.5  # Very strong privacy\n",
        "# recipe_strong_privacy = FedAvgRecipe(\n",
        "#     name=\"hello-dp-strong\",\n",
        "#     min_clients=n_clients,\n",
        "#     num_rounds=num_rounds,\n",
        "#     initial_model=TabularMLP(input_dim=8, hidden_dims=[64, 32], output_dim=1),\n",
        "#     train_script=\"client.py\",\n",
        "#     train_args=f\"--batch_size {batch_size} --target_epsilon {target_epsilon} --n_clients {n_clients}\",\n",
        "# )\n",
        "# add_experiment_tracking(recipe_strong_privacy, tracking_type=\"tensorboard\")\n",
        "# run_strong = recipe_strong_privacy.execute(SimEnv(num_clients=n_clients))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this example, you learned:\n",
        "\n",
        "1. **What is Differential Privacy**: A mathematical framework for privacy-preserving machine learning\n",
        "2. **DP-SGD with Opacus**: How to add differential privacy using Opacus' `PrivacyEngine`\n",
        "3. **FL with DP**: How to integrate DP into federated learning with NVFlare\n",
        "4. **Privacy Accounting**: How to track privacy budget (ε, δ) during training\n",
        "5. **Privacy-Utility Trade-off**: Balance between privacy (noise) and model accuracy\n",
        "\n",
        "### Best Practices:\n",
        "- Start with moderate epsilon (e.g., 50) and adjust based on privacy requirements\n",
        "- For sensitive data (medical, financial), use ε < 10\n",
        "- Pre-train on public data before fine-tuning on private data\n",
        "- Monitor privacy budget to ensure it doesn't exceed target\n",
        "\n",
        "### Next Steps:\n",
        "- Explore [Homomorphic Encryption](https://nvflare.readthedocs.io/) for additional privacy\n",
        "- Try different model architectures and datasets\n",
        "- Learn about [Secure Aggregation](https://nvflare.readthedocs.io/)\n",
        "- Apply to your own use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "1. Abadi, M., et al. (2016). [Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133). ACM CCS 2016.\n",
        "2. McMahan, B., et al. (2017). [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://proceedings.mlr.press/v54/mcmahan17a). AISTATS 2017.\n",
        "3. [Opacus: User-friendly library for training PyTorch models with differential privacy](https://opacus.ai/)\n",
        "4. [NVIDIA FLARE Documentation](https://nvflare.readthedocs.io/)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
