{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cb3afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tabular Data Federated Statistics \n",
    "\n",
    "In this example, we will show how to generate federated statistics for data that can be represented as Pandas Data Frame.\n",
    "\n",
    "## Set Up NVFLARE\n",
    "\n",
    "Follow [Getting Started](https://nvflare.readthedocs.io/en/main/getting_started.html) to set up a virtual environment and install NVFLARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a17f22-5667-4f99-b4f6-d49116db74b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install requirements\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8969bf-d010-42b5-a807-0808922402d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50272776",
   "metadata": {},
   "source": [
    "## Install Optional Quantile Dependency – fastdigest\n",
    "\n",
    "If you intend to calculate quantiles, you need to install fastdigest.\n",
    "\n",
    "Skip this step if you don’t need quantile statistics.\n",
    "```\n",
    "pip install fastdigest==0.4.0\n",
    "```\n",
    "\n",
    "on Ubuntu, you might get the following error:\n",
    "```\n",
    "Cargo, the Rust package manager, is not installed or is not on PATH.\n",
    "This package requires Rust and Cargo to compile extensions. Install it through\n",
    "the system's package manager or via https://rustup.rs/\n",
    "\n",
    "Checking for Rust toolchain....\n",
    "```\n",
    "This is because fastdigest (or its dependencies) requires Rust and Cargo to build.\n",
    "\n",
    "You need to install Rust and Cargo on your Ubuntu system. Follow these steps: Install Rust and Cargo Run the following command to install Rust using rustup:\n",
    "\n",
    "```\n",
    "./install_cargo.sh\n",
    "```\n",
    "Then you can install fastdigest again\n",
    "```\n",
    "pip install fastdigest==0.4.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad601e",
   "metadata": {},
   "source": [
    "# Code Structure\n",
    "\n",
    "Assume you have ```tree``` command installed, if not you can either installed it or use ``` ls -al ``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74837229",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6dc8b4",
   "metadata": {},
   "source": [
    "The code structure is \"client.py\", \"job.py\". The rests are supporting files. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94faaa6b-08fd-485c-87d5-53b4520177fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## data\n",
    "\n",
    "In this example, we are using UCI (University of California, Irvine) [adult dataset](https://archive.ics.uci.edu/dataset/2/adult)\n",
    "The original dataset has already contains \"training\" and \"test\" datasets. Here we simply assume that \"training\" and test data sets are belong to different clients.\n",
    "so we assigned the training data and test data into two clients.\n",
    " \n",
    "Now we use data utility to download UCI datasets to separate client package directory to /tmp/nvflare/data/ directory.\n",
    "Please note that the UCI's website may experience occasional downtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea959f-7282-4e55-bb26-11524ec47e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python prepare_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5444d8f-4938-4759-bd43-831013043c23",
   "metadata": {},
   "source": [
    "#### Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf37d0-7555-4818-9963-ca7342161a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path =\"/tmp/nvflare/df_stats/data/site-1/data.csv\"\n",
    "data_features = [\n",
    "            \"Age\",\n",
    "            \"Workclass\",\n",
    "            \"fnlwgt\",\n",
    "            \"Education\",\n",
    "            \"Education-Num\",\n",
    "            \"Marital Status\",\n",
    "            \"Occupation\",\n",
    "            \"Relationship\",\n",
    "            \"Race\",\n",
    "            \"Sex\",\n",
    "            \"Capital Gain\",\n",
    "            \"Capital Loss\",\n",
    "            \"Hours per week\",\n",
    "            \"Country\",\n",
    "            \"Target\",\n",
    "        ]\n",
    "\n",
    "        # the original dataset has no header,\n",
    "        # we will use the adult.train dataset for site-1, the adult.test dataset for site-2\n",
    "        # the adult.test dataset has incorrect formatted row at 1st line, we will skip it.\n",
    "skip_rows = {\n",
    "            \"site-1\": [],\n",
    "            \"site-2\": [0],\n",
    "        }\n",
    "\n",
    "df= pd.read_csv(data_path, names=data_features, sep=r\"\\s*,\\s*\", skiprows=skip_rows, engine=\"python\", na_values=\"?\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6d572-7dc0-4cec-8382-f25555f52af9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "> Note **We will only calculate the statistics of numerical features, categorical features will be skipped**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b5a75",
   "metadata": {},
   "source": [
    "# Client Code\n",
    "Local statistics generator. The statistics generator AdultStatistics implements Statistics spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6828084",
   "metadata": {},
   "source": [
    "Many of the functions needed for tabular statistics have already been implemented DFStatisticsCore\n",
    "\n",
    "In the AdultStatistics class, we really need to have the followings\n",
    "\n",
    "data_features – here we hard-coded the feature name array.\n",
    "\n",
    "implement ```load_data() -> Dict[str, pd.DataFrame]``` function, where the method will return a dictionary of panda DataFrames with one for each data source (“train”, “test”)\n",
    "\n",
    "data_path = ```<data_root_dir>/<site-name>/<filename>```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d282465",
   "metadata": {},
   "source": [
    "## Server Code\n",
    "The server aggregation have already implemented in Statistics Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d1c72",
   "metadata": {},
   "source": [
    "## Job Recipe\n",
    "\n",
    "Job is defined via recipe, we will run it in Simulation Execution Env. If you like to run in Production or PoC env. Simply replaced the SimEnv with ProdEnv or PoCEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat job.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00de5e4-4360-4fc5-a819-4eb156e56341",
   "metadata": {},
   "source": [
    "## Run job\n",
    "\n",
    "**Run Job using Simulator API**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361a85e-4187-433c-976c-0dc4021908ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf6e9a-3265-4e45-8b06-c8e543605f21",
   "metadata": {},
   "source": [
    "\n",
    "The results are stored in workspace \"/tmp/nvflare/df/workdir/\"\n",
    "```\n",
    " /tmp/nvflare/simulation/stats_df/server/simulate_job/statistics/adults_stats.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd042db-6ce0-4e37-bcbe-d96051e4d164",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization\n",
    "We can visualize the results easly via the visualizaiton notebook. Before we do that, we need to copy the data to the notebook directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c89693-37b9-450c-85dd-8a2d78fee3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp  /tmp/nvflare/simulation/stats_df/server/simulate_job/statistics/adults_stats.json demo/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6f632-3326-4236-902e-8c0965688d85",
   "metadata": {},
   "source": [
    "now we can visualize via the [visualization notebook](./demo/visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda06c0b-798d-480d-9b4c-a62fab95bcf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We are done !\n",
    "Congratulations, you just completed the federated stats calulation with data represented by data frame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
