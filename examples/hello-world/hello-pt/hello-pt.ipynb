{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c3d67-a6ea-4f59-84d2-effc3ef016e1",
   "metadata": {},
   "source": [
    "# Getting Started with NVFlare (PyTorch)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/NVFlare/blob/main/examples/hello-world/hello-pt/hello-pt.ipynb)\n",
    "\n",
    "NVFlare is an open-source framework that allows researchers and\n",
    "data scientists to seamlessly move their machine learning and deep\n",
    "learning workflows into a federated paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2b4a8-ed42-421d-8898-c0c93f9d8a09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Concepts\n",
    "At the heart of NVFlare lies the concept of collaboration through\n",
    "\"tasks.\" An FL controller assigns tasks (e.g., training on local data) to one or more FL clients, processes returned\n",
    "results (e.g., model weight updates), and may assign additional\n",
    "tasks based on these results and other factors (e.g., a pre-configured\n",
    "number of training rounds). The clients run executors which can listen for tasks and perform the necessary computations locally, such as model training. This task-based interaction repeats\n",
    "until the experimentâ€™s objectives are met. \n",
    "\n",
    "<img src=\"../../../docs/resources/controller_executor_no_filter.png\" alt=\"NVIDIA FLARE Controller and Executor\" width=75% height=75% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907933a8-20fd-4aa7-a3bf-3f5b5829a544",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa5ad3",
   "metadata": {},
   "source": [
    "If running in Google Colab, download the source code for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db44ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --ignore-installed blinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf327add",
   "metadata": {},
   "outputs": [],
   "source": [
    "! npx --yes degit -f NVIDIA/NVFlare/examples/hello-world/hello-pt ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5496ffe",
   "metadata": {},
   "source": [
    "Install nvflare and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65608a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f13d8",
   "metadata": {},
   "source": [
    "> **Note:** Depending on the number of clients, you might run into errors if several clients try to download the CIFAR-10 dataset at the same time. If this happens, try pre-downloading the dataset first or reducing the number of concurrent clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68cb248-dc6a-48d1-880d-33c4324d9723",
   "metadata": {},
   "source": [
    "## Federated Averaging with NVFlare\n",
    "Given the flexible controller and executor concepts, it is easy to implement different computing & communication patterns with NVFlare, such as [FedAvg](https://proceedings.mlr.press/v54/mcmahan17a?ref=https://githubhelp.com) and [cyclic weight transfer](https://academic.oup.com/jamia/article/25/8/945/4956468). \n",
    "\n",
    "The controller's `run()` routine is responsible for assigning tasks and processing task results from the Executors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f84fb1-9dd3-4c72-a727-c4614260f02f",
   "metadata": {},
   "source": [
    "### Server-Side Workflow\n",
    "\n",
    "This example uses the [FedAvgRecipe](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.app_opt.pt.recipes.fedavg.html), which implements the [FedAvg](https://proceedings.mlr.press/v54/mcmahan17a?ref=https://githubhelp.com) algorithm. The Recipe API handles all server-side logic automatically:\n",
    "\n",
    "1. Initialize the global model\n",
    "2. For each training round:\n",
    "   - Sample available clients\n",
    "   - Send the global model to selected clients\n",
    "   - Wait for client updates\n",
    "   - Aggregate client models into a new global model\n",
    "\n",
    "With the Recipe API, **there is no need to write custom server code**. The federated averaging workflow is provided by NVFlare using the `ScatterAndGather` controller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b6476-089a-4e9d-825b-07107bd5d84a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Client Code \n",
    "We take a CIFAR-10 example directly from [PyTorch website](https://github.com/pytorch/tutorials/blob/main/beginner_source/blitz/cifar10_tutorial.py) with some minor modifications, such as removing comments, moving the network to [model.py](model.py), and adding a main method and GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c551053-5460-4d83-8578-796074170342",
   "metadata": {},
   "source": [
    "Now, we need to adapt this centralized training code to something that can run in a federated setting.\n",
    "\n",
    "On the client side, the training workflow is as follows:\n",
    "1. Receive the model from the FL server.\n",
    "2. Perform local training on the received global model\n",
    "and/or evaluate the received global model for model\n",
    "selection.\n",
    "3. Send the new model back to the FL server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bfc2a-783c-494f-9427-c38f40a2e870",
   "metadata": {},
   "source": [
    "Using NVFlare's client API, we can easily adapt machine learning code that was written for centralized training and apply it in a federated scenario.\n",
    "For a general use case, there are three essential methods to achieve this using the Client API :\n",
    "- `init()`: Initializes NVFlare Client API environment.\n",
    "- `receive()`: Receives model from the FL server.\n",
    "- `send()`: Sends the model to the FL server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ee07-d848-4a7c-99ad-64e20ab7093c",
   "metadata": {},
   "source": [
    "With these simple methods, developers can use the Client API to change their centralized training code to an FL scenario with just a few lines of code changes as shown below.\n",
    "\n",
    "```python\n",
    "import nvflare.client as flare\n",
    "\n",
    "flare.init()  # 1. Initialize NVFlare Client API environment\n",
    "input_model = flare.receive()  # 2. Receive model from the FL server\n",
    "params = input_model.params  # 3. Extract parameters from the received model\n",
    "\n",
    "# (optional) Handle cross-site evaluation tasks\n",
    "if flare.is_evaluate():\n",
    "    accuracy = evaluate(params)  # Evaluate the model\n",
    "    flare.send(flare.FLModel(metrics={\"accuracy\": accuracy}))\n",
    "else:\n",
    "    # Original local training code\n",
    "    new_params = local_train(params)\n",
    "    \n",
    "    output_model = flare.FLModel(params=new_params)  # 4. Package results in FLModel\n",
    "    flare.send(output_model)  # 5. Send the model to the FL server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67432f44-4144-4347-8d74-e7f57e065a14",
   "metadata": {},
   "source": [
    "The full client training script is saved in [client.py](client.py), which performs CNN training on the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da34414-bac4-4352-8077-ab7ade998eec",
   "metadata": {},
   "source": [
    "## Run an NVFlare Job\n",
    "Now that we have defined the FedAvg controller to run our federated compute workflow on the FL server, and our client training script to receive the global models, run local training, and send the results back to the FL server, we can put everything together using NVFlare's Job API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedaf75-3a4a-4843-8017-7716b53149a2",
   "metadata": {},
   "source": [
    "#### 1. Define the initial model\n",
    "First, we define the global model used to initialize the model on the FL server. See [model.py](model.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3881b3",
   "metadata": {},
   "source": [
    "This `SimpleNetwork` is a convolutional neural network (CNN) with:\n",
    "- Two convolutional layers (`conv1`, `conv2`) for feature extraction\n",
    "- Max pooling for dimensionality reduction\n",
    "- Three fully connected layers (`fc1`, `fc2`, `fc3`) for classification into 10 CIFAR-10 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93889e62-b725-427c-8839-2771ca81d24c",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70da5d-ba8b-4e65-b47f-44bb9bddae4d",
   "metadata": {},
   "source": [
    "#### 2. Define a FedJob Recipe\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13771bfb-901f-485a-9a23-84db1ccd5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SimpleNetwork\n",
    "\n",
    "from nvflare.app_opt.pt.recipes.fedavg import FedAvgRecipe\n",
    "from nvflare.recipe import SimEnv, add_experiment_tracking\n",
    "from nvflare.recipe.utils import add_cross_site_evaluation\n",
    "\n",
    "n_clients = 2\n",
    "num_rounds = 2\n",
    "batch_size = 16\n",
    "\n",
    "recipe = FedAvgRecipe(\n",
    "    name=\"hello-pt\",\n",
    "    min_clients=n_clients,\n",
    "    num_rounds=num_rounds,\n",
    "    initial_model=SimpleNetwork(),\n",
    "    train_script=\"client.py\",\n",
    "    train_args=f\"--batch_size {batch_size}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155da08-8244-457f-ab8a-ec8cba453732",
   "metadata": {},
   "source": [
    "#### 3. Add experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d4b78-a4ec-4dec-bf70-673b1af07ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_experiment_tracking(recipe, tracking_type=\"tensorboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7859f2",
   "metadata": {},
   "source": [
    "#### 4. (Optional) Add Cross-Site Evaluation\n",
    "\n",
    "To evaluate trained models across all client sites after training, you can add cross-site evaluation:\n",
    "\n",
    "```python\n",
    "# Uncomment to enable cross-site evaluation\n",
    "# add_cross_site_evaluation(recipe)\n",
    "```\n",
    "\n",
    "This will run an additional evaluation phase after training completes, where each client evaluates models from all sites. The framework is auto-detected from the recipe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3f0a8-06bb-4bea-89d3-4a5fc5b76c63",
   "metadata": {},
   "source": [
    "#### 5. Run Job\n",
    "Here, we run the job in a simulation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13068ab7-35cf-49e7-91ed-10993049ef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = SimEnv(num_clients=n_clients)\n",
    "run = recipe.execute(env)\n",
    "print()\n",
    "print(\"Job Status is:\", run.get_status())\n",
    "print(\"Result can be found in :\", run.get_result())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6628eb-ce45-4bf8-90c9-1d8061ce048e",
   "metadata": {},
   "source": [
    "#### 6. Visualize the Training\n",
    "\n",
    "TensorBoard will show training metrics collected from each client, including:\n",
    "- Training loss curves over time\n",
    "- Per-client and aggregated metrics  \n",
    "- Comparison across different rounds\n",
    "\n",
    "You can launch TensorBoard by running:\n",
    "\n",
    "```bash\n",
    "tensorboard --bind_all --logdir /tmp/nvflare/simulation/hello-pt\n",
    "```\n",
    "in another terminal, or directly show the training curves in the next notebook cell.\n",
    "\n",
    "If you enabled cross-site evaluation, you can view the validation results with:\n",
    "```python\n",
    "import json\n",
    "with open('/tmp/nvflare/simulation/hello-pt/server/simulate_job/cross_site_val/cross_val_results.json') as f:\n",
    "    print(json.dumps(json.load(f), indent=2))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f06f0c-a7b0-488c-ac54-35d99e379bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --bind_all --logdir /tmp/nvflare/simulation/hello-pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
