{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e129ede5",
   "metadata": {},
   "source": [
    "   # Hello PyTorch with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7e391",
   "metadata": {},
   "source": [
    "In this example, we like to demonstrate that the example code used in hello-pt-tb with PyTorch Tensorboard tracking can be simply switched to using an MLflow tracking server without changing the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec76f4",
   "metadata": {},
   "source": [
    "\n",
    "Example of using [NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html) to train an image classifier using federated averaging ([FedAvg]([FedAvg](https://arxiv.org/abs/1602.05629))) and [PyTorch](https://pytorch.org/) as the deep learning training framework. This example also highlights the streaming capability from the clients to the server with Tensorboard SummaryWriter sender syntax, but with a MLflow receiver\n",
    "\n",
    "> **_NOTE:_** This example uses the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and will load its data within the trainer code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca0050",
   "metadata": {},
   "source": [
    "### 1. Install NVIDIA FLARE\n",
    "\n",
    "Follow the [Installation](https://nvflare.readthedocs.io/en/main/getting_started.html#installation) instructions.\n",
    "Install additional requirements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision tensorboard mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8226dd7",
   "metadata": {},
   "source": [
    "### 2. Change Configuration\n",
    "\n",
    "in fed_server_config.json\n",
    "\n",
    "add the following to the components\n",
    "```\n",
    "{\n",
    "      \"id\": \"mlflow_receiver\",\n",
    "      \"path\": \"nvflare.app_opt.tracking.mlflow.mlflow_receiver.MLflowReceiver\",\n",
    "      \"args\": {\n",
    "        \"kwargs\": {\"experiment_name\": \"hello-pt-experiment\"},\n",
    "        \"artifact_location\": \"artifacts\"\n",
    "      }\n",
    "}\n",
    "```\n",
    "This indicates that we are registering the MLflow Receiver in additional to the Tensorboard Receiver.\n",
    "\n",
    "Note that the job hello-pt-mlflow is an example using mlflow syntax and the MLflowWriter on the client side, and\n",
    "hello-pt-tb-mlflow has the learner using tb syntax. Both work with MLflowReceiver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3165d",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Run the experiment\n",
    "\n",
    "Use nvflare simulator to run the examples with the additional common python files included in the python path:\n",
    "\n",
    "export PYTHONPATH=${PWD}/..\n",
    "\n",
    "```\n",
    "nvflare simulator -w /tmp/nvflare/ -n 2 -t 2 ./jobs/hello-pt-tb-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f08cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare simulator -w /tmp/nvflare/ -n 2 -t 2 ./jobs/hello-pt-tb-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fe44d",
   "metadata": {},
   "source": [
    "### 4. Tensorboard Tracking\n",
    "\n",
    "On the client side, we are still using the TensorBoard SummaryWriter as the `AnalyticsSender`. \n",
    "\n",
    "Instead of writing to TB files, it actually generates NVFLARE events of type `analytix_log_stats`.\n",
    "The `ConvertToFedEvent` widget will turn the event `analytix_log_stats` into a fed event `fed.analytix_log_stats`,\n",
    "which will be delivered to the server side.\n",
    "\n",
    "On the server side, the `TBAnalyticsReceiver` is configured to process `fed.analytix_log_stats` events,\n",
    "which writes received TB data into appropriate TB files on the server.\n",
    "\n",
    "To view training metrics that are being streamed to the server, run:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/tmp/nvflare/simulate_job/tb_events\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d7879",
   "metadata": {},
   "source": [
    "### 5. MLflow tracking\n",
    "\n",
    "On the server side, we also configured `MLflowReceiver` to process `fed.analytix_log_stats` events,\n",
    "which writes received events to the MLflow tracking server.\n",
    "\n",
    "To view training metrics that are being streamed to the server, run:\n",
    "\n",
    "```\n",
    "mlflow ui --backend-store-uri=/tmp/nvflare/mlruns\n",
    "```\n",
    "\n",
    "Then \n",
    "\n",
    "Look at the URL in browser http://localhost:5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e7952-c3e6-4e90-a42e-648a823ede78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --backend-store-uri=/tmp/nvflare/mlruns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
