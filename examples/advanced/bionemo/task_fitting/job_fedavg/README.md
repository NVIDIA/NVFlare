# Federated MLP Training on Protein Embeddings

This example demonstrates how to use NVIDIA FLARE to train a Multi-Layer Perceptron (MLP) classifier on protein embeddings using federated averaging (FedAvg). The MLP predicts subcellular protein location from embeddings generated by the ESM2 model.

## Overview

This job trains an MLP classifier in a federated learning setting where:
1. Each client has pre-computed protein embeddings from ESM2 inference
2. Clients train a shared MLP model on their local embeddings
3. Model updates are aggregated using FedAvg algorithm
4. Supports both federated and local training modes

## Code Structure

```bash
job_fedavg/
├── client.py    # Client script for MLP training
├── job.py       # Job configuration using FedAvgRecipe
└── README.md    # This file
```

## Prerequisites

Install scikit-learn and NVFlare:

```bash
pip install nvflare scikit-learn torch pandas
```

## Data Preparation

Before running this job, you must first run the inference job to generate embeddings:

```bash
cd ../job_inference
python job.py
```

This will create embedding files in `/tmp/data/mixed_soft/results/` for each client.

## Configuration

Key parameters in `job.py`:
- `n_clients`: Number of federated clients (default: 3)
- `num_rounds`: Number of federated training rounds (default: 100)
- `aggregation_epochs`: Local epochs per round (default: 4)
- `lr`: Learning rate (default: 1e-5)
- `batch_size`: Training batch size (default: 128)
- `embedding_dimensions`: ESM2 embedding size (320 for 8m, 1280 for 650m)

Training modes:
- **Federated** (`SIM_LOCAL=False`): Standard FedAvg with model aggregation
- **Local** (`SIM_LOCAL=True`): Each client trains independently (for comparison)

## Client Code

The client code ([client.py](./client.py)) implements the training workflow:

1. Initialize NVFlare client API
2. Load pre-computed embeddings and labels
3. Initialize scikit-learn MLP classifier
4. Training loop:
   - Receive global model from server
   - Train on local embeddings
   - Compute model differences
   - Send updates to server

```python
import nvflare.client as flare

flare.init()
site_name = flare.get_site_name()

# Training loop
while flare.is_running():
    input_model = flare.receive()
    # Load global weights
    # Train locally
    # Compute differences
    output_model = flare.FLModel(params=model_diff, metrics=metrics)
    flare.send(output_model)
```

## Server Code

The server implements federated averaging to aggregate client model updates:
1. Initialize a random MLP model
2. For each round:
   - Send global model to clients
   - Receive and aggregate model differences
   - Update global model
   - Track metrics

The `FedAvgRecipe` handles all server-side logic automatically.

## Job Recipe

```python
recipe = FedAvgRecipe(
    name=job_name,
    min_clients=n_clients,
    num_rounds=100,
    train_script="client.py",
    train_args=script_args,
    launch_external_process=True,
    command="python3",
)
```

## Run Job

From the `job_fedavg` directory:

**For federated training:**
```bash
python job.py
# Select 'fedavg' when prompted
```

**For local training (baseline):**
```bash
python job.py
# Select 'local' when prompted
```

The job will:
1. Train for 100 rounds of federated averaging
2. Log metrics to TensorBoard
3. Save results to `/tmp/nvflare/bionemo/{job_name}_alpha1.0/`

## View Results

Monitor training progress with TensorBoard:

```bash
tensorboard --logdir /tmp/nvflare/bionemo/
```

Metrics tracked:
- `accuracy`: Test set accuracy
- `train_accuracy`: Training set accuracy
- Per-class precision, recall, F1-score

## Output Summary

#### Initialization
* **TensorBoard**: Logs available at `/tmp/nvflare/bionemo/mlp_fedavg_alpha1.0/`
* **Clients**: site-1, site-2, site-3
* **Model**: MLP with hidden layers (512, 256, 128)

#### Round 0
* **Training**: Each client trains for 4 epochs
* **Aggregation**: Server aggregates model differences
* **Metrics**: Accuracy reported for each client

#### Subsequent Rounds
* Model continues to improve through federated averaging
* Convergence typically occurs around round 50-100

#### Completion
* Final global model achieves competitive accuracy on subcellular location prediction
* Compare with local training baseline to see benefit of federation

## Model Architecture

The MLP classifier uses:
- **Input**: Protein embeddings (320 dimensions for ESM2-8m)
- **Hidden layers**: (512, 256, 128)
- **Output**: 10 classes (subcellular locations)
- **Optimizer**: Adam
- **Loss**: Cross-entropy (built into MLPClassifier)

## Subcellular Location Classes

The model predicts one of 10 subcellular locations:
1. Cell_membrane
2. Cytoplasm
3. Endoplasmic_reticulum
4. Extracellular
5. Golgi_apparatus
6. Lysosome
7. Mitochondrion
8. Nucleus
9. Peroxisome
10. Plastid

## Notes

- This job runs clients **in parallel** (threads=n_clients) since MLP training is CPU-based
- Each client uses a shared test set for comparable metrics
- The `SIM_LOCAL` environment variable controls training mode
- Model differences (not full models) are sent to reduce communication overhead
