{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada310b-e776-4b9a-aabe-f111c31efcc2",
   "metadata": {},
   "source": [
    "# Split Learning with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a00eb-cabe-4461-aa95-639ac8229d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup\n",
    "\n",
    "Install the required packages for training in the current Jupyter kernel\n",
    "\n",
    "**important**:\n",
    "    Make sure you set the python path follows [README](./README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95481-b7fc-49ff-ad50-5dbad398db6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = !python3 -c \"from splitnn.cifar10_vertical_data_splitter import Cifar10VerticalDataSplitter\"\n",
    "assert output == [], \"PYTHONPATH is not set properly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6dcba-9570-4ddf-bc25-b60a5f2a9adc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cbf2-92f2-4a22-8317-69cfb0266e92",
   "metadata": {},
   "source": [
    "## 1. Download and split the CIFAR-10 dataset\n",
    "To simulate a vertical split dataset, we first download the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and distribute it between the two clients, assuming an `OVERLAP` of 10,000 samples between the two clients' datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4130b15-09e6-456f-a3c7-87c8ee9e07f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env SPLIT_DIR=/tmp/cifar10_vert_splits\n",
    "%env OVERLAP=10000\n",
    "!python3 ./cifar10_split_data_vertical.py --split_dir ${SPLIT_DIR} --overlap ${OVERLAP}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af257e69-2bb7-49b6-ac6c-f007b0e6618e",
   "metadata": {},
   "source": [
    "## 2. Run private set intersection\n",
    "We are using NVFlare's FL simulator to run the following experiments.\n",
    "\n",
    "In order to find the overlapping data indices between the different clients participating in split learning, \n",
    "we randomly select an subset of the training indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7290a-48ff-4e80-be58-5e6b0e0f9379",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nvflare import SimulatorRunner\n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"jobs/cifar10_psi\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_psi\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1388dc-6a4f-4965-a09f-4d058fc3833c",
   "metadata": {},
   "source": [
    "The result will be saved on each client's working directory in `intersection.txt`.\n",
    "\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in `overlap.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6bcc-9443-4331-bde3-4576fbfffaec",
   "metadata": {},
   "source": [
    "### Check the PSI result\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in overlap.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6b36f-649f-4e19-ba0a-5dd71dfda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "split_dir = os.environ[\"SPLIT_DIR\"]\n",
    "gt_overlap = np.load(os.path.join(split_dir, \"overlap.npy\"))\n",
    "\n",
    "psi_overlap_1 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/simulate_job/site-1/psi/intersection.txt\")\n",
    "psi_overlap_2 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/simulate_job/site-2/psi/intersection.txt\")\n",
    "                     \n",
    "print(\"gt_overlap\", gt_overlap, f\"n={len(gt_overlap)}\")\n",
    "print(\"psi_overlap_1\", psi_overlap_1, f\"n={len(psi_overlap_1)}\")\n",
    "print(\"psi_overlap_2\", psi_overlap_2, f\"n={len(psi_overlap_2)}\")\n",
    "\n",
    "intersect_1 = np.intersect1d(psi_overlap_1, gt_overlap, assume_unique=True)\n",
    "intersect_2 = np.intersect1d(psi_overlap_2, gt_overlap, assume_unique=True)\n",
    "\n",
    "print(f\"Found {100*len(intersect_1)/len(gt_overlap):.1f}% of the overlapping sample ids for site-1.\")\n",
    "print(f\"Found {100*len(intersect_2)/len(gt_overlap):.1f}% of the overlapping sample ids for site-2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0713e2-e393-41c0-9da0-392535cf8a54",
   "metadata": {},
   "source": [
    "## 3. Run simulated split-learning experiments\n",
    "Next we use the `intersection.txt` files to align the datasets on each participating site in order to do split learning.\n",
    "The [config_fed_client.json](./jobs/cifar10_splitnn/site-1/config/config_fed_client.json) takes as input the previously generated intersection file for each site.\n",
    "```\n",
    "    {\n",
    "        \"id\": \"cifar10-learner\",\n",
    "        \"path\": \"pt.learners.cifar10_learner_splitnn.CIFAR10LearnerSplitNN\",\n",
    "        \"args\": {\n",
    "            \"dataset_root\": \"{DATASET_ROOT}\",\n",
    "            \"intersection_file\": \"{INTERSECTION_FILE}\",\n",
    "            \"lr\": 1e-2,\n",
    "            \"model\": {\"path\": \"pt.networks.split_nn.SplitNN\", \"args\":  {\"split_id\":  0}},\n",
    "            \"timeit\": true\n",
    "        }\n",
    "    }\n",
    "```\n",
    "To set the filename automatically, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978f6ac-f7db-4648-abb3-0fd071f01531",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in {1..2}; \\\n",
    "do \\\n",
    "  CONFIG_FILE=jobs/cifar10_splitnn/site-${i}/config/config_fed_client.json; \\\n",
    "  INTERSECTION_FILE=/tmp/nvflare/cifar10_psi/simulate_job/site-${i}/psi/intersection.txt; \\\n",
    "  python3 ./set_intersection_file.py --config_file ${CONFIG_FILE} --intersection_file ${INTERSECTION_FILE}; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f606a9-55a9-4984-a40c-7951287a5a63",
   "metadata": {},
   "source": [
    "To run the experiment, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c75dcb-014d-40c4-8a4a-7a53847c486b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"jobs/cifar10_splitnn\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_splitnn\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e9ee2-e993-442d-a525-d2baf92af539",
   "metadata": {},
   "source": [
    "The site containing the labels can compute accuracy and losses, which can be visualized in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6814434-4e6d-4460-b480-709cb3e77cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir /tmp/nvflare/cifar10_splitnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2111015-9f36-4fc7-9b82-2139e362645f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
