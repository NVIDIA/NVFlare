{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada310b-e776-4b9a-aabe-f111c31efcc2",
   "metadata": {},
   "source": [
    "# Split Learning with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a00eb-cabe-4461-aa95-639ac8229d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup\n",
    "\n",
    "Install the required packages for training in the current Jupyter kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a6dcba-9570-4ddf-bc25-b60a5f2a9adc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef76950-e43e-4d99-8f66-749ed6078a3a",
   "metadata": {},
   "source": [
    "Set `PYTHONPATH` to include custom files of this example and some reused files from the [CIFAR-10](https://github.com/NVIDIA/NVFlare/tree/main/examples/advanced/cifar10) examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f85872-b039-4f77-b381-ff06b2503b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\", \"cifar10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d95481-b7fc-49ff-ad50-5dbad398db6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from splitnn.cifar10_vertical_data_splitter import Cifar10VerticalDataSplitter\n",
    "except ImportError as e:\n",
    "     raise ImportError(\"PYTHONPATH is not set properly\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cbf2-92f2-4a22-8317-69cfb0266e92",
   "metadata": {},
   "source": [
    "## 1. Download and split the CIFAR-10 dataset\n",
    "To simulate a vertical split dataset, we first download the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset and distribute it between the two clients, assuming an `OVERLAP` of 10,000 samples between the two clients' datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4130b15-09e6-456f-a3c7-87c8ee9e07f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT_DIR = \"/tmp/cifar10_vert_splits\"\n",
    "OVERLAP = \"10000\"\n",
    "%run ./cifar10_split_data_vertical.py --split_dir $SPLIT_DIR --overlap $OVERLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af257e69-2bb7-49b6-ac6c-f007b0e6618e",
   "metadata": {},
   "source": [
    "## 2. Run private set intersection\n",
    "We are using NVFlare's FL simulator to run the following experiments.\n",
    "\n",
    "In order to find the overlapping data indices between the different clients participating in split learning, \n",
    "we randomly select an subset of the training indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7290a-48ff-4e80-be58-5e6b0e0f9379",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nvflare import SimulatorRunner\n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"jobs/cifar10_psi\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_psi\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1388dc-6a4f-4965-a09f-4d058fc3833c",
   "metadata": {},
   "source": [
    "The result will be saved on each client's working directory in `intersection.txt`.\n",
    "\n",
    "We can check the correctness of the result by comparing it to the generated ground truth overlap, saved in `overlap.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6bcc-9443-4331-bde3-4576fbfffaec",
   "metadata": {},
   "source": [
    "### Check the PSI result\n",
    "We can check the correctness of the result by comparing to the generate ground truth overlap, saved in overlap.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a6b36f-649f-4e19-ba0a-5dd71dfda5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_overlap [11841 19602 45519 ... 47278 37020  2217] n=10000\n",
      "psi_overlap_1 [ 4481. 45431. 46253. ... 34846.   179.  7277.] n=10000\n",
      "psi_overlap_2 [38639. 10733. 31911. ... 12172. 46167.   865.] n=10000\n",
      "Found 100.0% of the overlapping sample ids for site-1.\n",
      "Found 100.0% of the overlapping sample ids for site-2.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "gt_overlap = np.load(os.path.join(SPLIT_DIR, \"overlap.npy\"))\n",
    "\n",
    "psi_overlap_1 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/site-1/simulate_job/site-1/psi/intersection.txt\")\n",
    "psi_overlap_2 = np.loadtxt(\"/tmp/nvflare/cifar10_psi/site-2/simulate_job/site-2/psi/intersection.txt\")\n",
    "                     \n",
    "print(\"gt_overlap\", gt_overlap, f\"n={len(gt_overlap)}\")\n",
    "print(\"psi_overlap_1\", psi_overlap_1, f\"n={len(psi_overlap_1)}\")\n",
    "print(\"psi_overlap_2\", psi_overlap_2, f\"n={len(psi_overlap_2)}\")\n",
    "\n",
    "intersect_1 = np.intersect1d(psi_overlap_1, gt_overlap, assume_unique=True)\n",
    "intersect_2 = np.intersect1d(psi_overlap_2, gt_overlap, assume_unique=True)\n",
    "\n",
    "print(f\"Found {100*len(intersect_1)/len(gt_overlap):.1f}% of the overlapping sample ids for site-1.\")\n",
    "print(f\"Found {100*len(intersect_2)/len(gt_overlap):.1f}% of the overlapping sample ids for site-2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0713e2-e393-41c0-9da0-392535cf8a54",
   "metadata": {},
   "source": [
    "## 3. Run simulated split-learning experiments\n",
    "Next we use the `intersection.txt` files to align the datasets on each participating site in order to do split learning.\n",
    "The [config_fed_client.json](./jobs/cifar10_splitnn/site-1/config/config_fed_client.json) takes as input the previously generated intersection file for each site.\n",
    "```\n",
    "    {\n",
    "        \"id\": \"cifar10-learner\",\n",
    "        \"path\": \"pt.learners.cifar10_learner_splitnn.CIFAR10LearnerSplitNN\",\n",
    "        \"args\": {\n",
    "            \"dataset_root\": \"{DATASET_ROOT}\",\n",
    "            \"intersection_file\": \"{INTERSECTION_FILE}\",\n",
    "            \"lr\": 1e-2,\n",
    "            \"model\": {\"path\": \"pt.networks.split_nn.SplitNN\", \"args\":  {\"split_id\":  0}},\n",
    "            \"timeit\": true\n",
    "        }\n",
    "    }\n",
    "```\n",
    "To set the filename automatically, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978f6ac-f7db-4648-abb3-0fd071f01531",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in {1..2}; \\\n",
    "do \\\n",
    "  CONFIG_FILE=jobs/cifar10_splitnn/site-${i}/config/config_fed_client.json; \\\n",
    "  INTERSECTION_FILE=/tmp/nvflare/cifar10_psi/site-${i}/simulate_job/site-${i}/psi/intersection.txt; \\\n",
    "  python3 ./set_intersection_file.py --config_file ${CONFIG_FILE} --intersection_file ${INTERSECTION_FILE}; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f606a9-55a9-4984-a40c-7951287a5a63",
   "metadata": {},
   "source": [
    "To run the experiment, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c75dcb-014d-40c4-8a4a-7a53847c486b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nvflare import SimulatorRunner\n",
    "\n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=f\"jobs/cifar10_splitnn\",\n",
    "    workspace=\"/tmp/nvflare/cifar10_splitnn\",\n",
    "    n_clients=2,\n",
    "    threads=2\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e9ee2-e993-442d-a525-d2baf92af539",
   "metadata": {},
   "source": [
    "The site containing the labels can compute accuracy and losses, which can be visualized in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6814434-4e6d-4460-b480-709cb3e77cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-592d3cca50040bb6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-592d3cca50040bb6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir /tmp/nvflare/cifar10_splitnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
