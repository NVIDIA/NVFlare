{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c3d67-a6ea-4f59-84d2-effc3ef016e1",
   "metadata": {},
   "source": [
    "# Hello FedAvg with Early Stopping Condition\n",
    "\n",
    "Example of using [NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html) to train an image classifier\n",
    "using federated averaging ([FedAvg](https://arxiv.org/abs/1602.05629))\n",
    "and [PyTorch](https://pytorch.org/) as the deep learning training framework.\n",
    "In this example we highlight the flexibility of the ModelController API, and show how to write a Federated Averaging workflow with model selection, early stopping, and saving and loading. We use the train script [client.py](client.py) and network [model.py](model.py) from the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e6719",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Install nvflare and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nvflare~=2.7.0rc torch torchvision tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa82a08",
   "metadata": {},
   "source": [
    "Download the source code for this example if running in Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335fd7f",
   "metadata": {"tags": ["skip-execution", "skip", "colab"]},
   "outputs": [],
   "source": [
    "%pip install --ignore-installed blinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0dad5",
   "metadata": {
    "tags": [
     "skip-execution",
     "skip",
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "! npx degit -f NVIDIA/NVFlare/examples/advanced/fedavg-with-early-stopping . -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907933a8-20fd-4aa7-a3bf-3f5b5829a544",
   "metadata": {},
   "source": [
    "## 2. PTFedAvgEarlyStopping using ModelController API\n",
    "\n",
    "The ModelController API enables the option to easily customize a workflow. \n",
    "We implement additional functionalities on top of the BaseFedAvg class in [PTFedAvgEarlyStopping](https://github.com/NVIDIA/NVFlare/tree/main/nvflare/app_opt/pt/fedavg_early_stopping.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066dfd0",
   "metadata": {},
   "source": [
    "### 2.1 FedAvg\n",
    "We subclass the BaseFedAvg class to leverage the predefined aggregation functions, and add our additional functionalities at the end of each round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab4f8b",
   "metadata": {},
   "source": [
    "```python\n",
    "if self.is_curr_model_better(model):\n",
    "    self.info(\"New best model found\")\n",
    "    self.save_model(model, os.path.join(os.getcwd(), self.save_filename))\n",
    "else:\n",
    "    if self.patience:\n",
    "        self.info(\n",
    "            f\"No metric improvment, num of FL rounds without improvement: \"\n",
    "            f\"{self.num_fl_rounds_without_improvement}\"\n",
    "        )\n",
    "\n",
    "if self.should_stop(model.metrics):\n",
    "    self.info(f\"Stopping at round={self.current_round} out of total_rounds={self.num_rounds}.\")\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba74bd3",
   "metadata": {},
   "source": [
    "### 2.2 Model Selection\n",
    "As an alternative to using an [IntimeModelSelector](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/widgets/intime_model_selector.py) component for model selection, we instead compare the metrics of the models in the workflow to select the best model each round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf63bd",
   "metadata": {},
   "source": [
    "```python\n",
    "def is_curr_model_better(self, curr_model: FLModel) -> bool:\n",
    "    \"\"\"Checks if the new model is better than the current best model.\n",
    "\n",
    "    Args:\n",
    "        curr_model (FLModel): the new model to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        True if the new model is better than the current best model, False otherwise\n",
    "    \"\"\"\n",
    "    if self.stop_condition is None:\n",
    "        return True\n",
    "\n",
    "    curr_metrics = curr_model.metrics\n",
    "    if curr_metrics is None:\n",
    "        return False\n",
    "\n",
    "    target_metric, _, op_fn = self.stop_condition\n",
    "    curr_target_metric = curr_metrics.get(target_metric, None)\n",
    "    if curr_target_metric is None:\n",
    "        return False\n",
    "\n",
    "    if self.best_target_metric_value is None or op_fn(curr_target_metric, self.best_target_metric_value):\n",
    "        if self.patience and self.best_target_metric_value == curr_target_metric:\n",
    "            self.num_fl_rounds_without_improvement += 1\n",
    "            return False\n",
    "        else:\n",
    "            self.best_target_metric_value = curr_target_metric\n",
    "            self.num_fl_rounds_without_improvement = 0\n",
    "            return True\n",
    "\n",
    "    self.num_fl_rounds_without_improvement += 1\n",
    "    return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb107f",
   "metadata": {},
   "source": [
    "### 2.3 Early Stopping\n",
    "We add a `stop_condition` argument (eg. `\"accuracy >= 80\"`) and end the workflow early if the corresponding global model metric meets the condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e772aa",
   "metadata": {},
   "source": [
    "```python\n",
    "def should_stop(self, metrics: Optional[Dict] = None) -> bool:\n",
    "    \"\"\"Checks whether the current FL experiment should stop.\n",
    "\n",
    "    Args:\n",
    "        metrics (Dict, optional): experiment metrics.\n",
    "\n",
    "    Returns:\n",
    "        True if the experiment should stop, False otherwise.\n",
    "    \"\"\"\n",
    "    if self.stop_condition is None or metrics is None:\n",
    "        return False\n",
    "\n",
    "    if self.patience and (self.patience <= self.num_fl_rounds_without_improvement):\n",
    "        self.info(f\"Exceeded the number of FL rounds ({self.patience}) without improvments\")\n",
    "        return True\n",
    "\n",
    "    key, target, op_fn = self.stop_condition\n",
    "    value = metrics.get(key, None)\n",
    "\n",
    "    if value is None:\n",
    "        raise RuntimeError(f\"stop criteria key '{key}' doesn't exists in metrics\")\n",
    "\n",
    "    if op_fn(value, target):\n",
    "        self.info(f\"Early stop condition satisfied: {self.stop_condition}\")\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb8a46",
   "metadata": {},
   "source": [
    "### 2.4 PyTorch Saving and Loading\n",
    "Rather than configuring a persistor such as the [PTFileModelPersistor](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/pt/file_model_persistor.py) component, we choose to utilize PyTorch's save and load functions and save the metadata of the FLModel separately. We load the `initial_model` into a class variable, which requires us to register the [TensorDecomposer](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_opt/pt/decomposers.py) for serialization of PyTorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc959060",
   "metadata": {},
   "source": [
    "```python\n",
    "if self.initial_model:\n",
    "    # Use FOBS for serializing/deserializing PyTorch tensors (self.initial_model)\n",
    "    fobs.register(TensorDecomposer)\n",
    "    # PyTorch weights\n",
    "    initial_weights = self.initial_model.state_dict()\n",
    "else:\n",
    "    initial_weights = {}\n",
    "\n",
    "model = FLModel(params=initial_weights)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc90b4",
   "metadata": {},
   "source": [
    "We use torch `save` and `load`, and save the FLModel metadata separately with the `fobs.dumpf` and `fobs.loadf` serialization utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d47f6",
   "metadata": {},
   "source": [
    "```python\n",
    "def save_model(self, model: FLModel, filepath: Optional[str] = \"\") -> None:\n",
    "    \"\"\"Saves the model to the specified file path.\n",
    "\n",
    "    Args:\n",
    "        model (FLModel): model to save\n",
    "        filepath (str, optional): location where the model will be saved\n",
    "    \"\"\"\n",
    "    params = model.params\n",
    "    # PyTorch save\n",
    "    torch.save(params, filepath)\n",
    "\n",
    "    # save FLModel metadata\n",
    "    model.params = {}\n",
    "    fobs.dumpf(model, f\"{filepath}.metadata\")\n",
    "    model.params = params\n",
    "\n",
    "def load_model(self, filepath: Optional[str] = \"\") -> FLModel:\n",
    "    \"\"\"Loads a model from the provided file path.\n",
    "\n",
    "    Args:\n",
    "        filepath (str, optional): location of the saved model to load\n",
    "    \"\"\"\n",
    "    # PyTorch load\n",
    "    params = torch.load(filepath)\n",
    "\n",
    "    # load FLModel metadata\n",
    "    model: FLModel = fobs.loadf(f\"{filepath}.metadata\")\n",
    "    model.params = params\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ac545",
   "metadata": {},
   "source": [
    "## 3. Run the script\n",
    "\n",
    "Use the Job API to define and run the example with the simulator.\n",
    "(Note: We use `key_metric=None` to use our own model selection logic instead of the `IntimeModelSelector`, which will be configured if `key_metric` is used.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ead88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare import FedJob\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "from nvflare.app_opt.pt.fedavg_early_stopping import PTFedAvgEarlyStopping\n",
    "\n",
    "job = FedJob(name=\"cifar10_fedavg_early_stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1e1d5",
   "metadata": {},
   "source": [
    "Define the `PTFedAvgEarlyStopping` controller workflow with the `stop_cond` and `initial_model` args and send to server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc51ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "\n",
    "n_clients = 2\n",
    "\n",
    "# Define the controller workflow and send to server\n",
    "controller = PTFedAvgEarlyStopping(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=5,\n",
    "    stop_cond=\"accuracy >= 40\",\n",
    "    initial_model=Net(),\n",
    ")\n",
    "job.to(controller, \"server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5050f5d",
   "metadata": {},
   "source": [
    "Use the `ScriptRunner` and send to each of the clients to run the train script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce18462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script = \"client.py\"\n",
    "\n",
    "# Add clients\n",
    "for i in range(n_clients):\n",
    "    executor = ScriptRunner(script=train_script, script_args=\"\")\n",
    "    job.to(executor, f\"site-{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040b41a",
   "metadata": {},
   "source": [
    "Optionally export the job to run in other modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d53177",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.export_job(\"/tmp/nvflare/jobs/job_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8942bc",
   "metadata": {},
   "source": [
    "Run the FedJob using the simulator. View the results in the job workspace: `/tmp/nvflare/jobs/workdir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.simulator_run(\"/tmp/nvflare/jobs/workdir\", gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558038c",
   "metadata": {},
   "source": [
    "### Visualize the Training Results\n",
    "By default, we enable TensorBoard metric [streaming](https://nvflare.readthedocs.io/en/main/examples/tensorboard_streaming.html) using NVFlare's `SummaryWriter` in [src/cifar10_fl.py](src/cifar10_fl.py). \n",
    "\n",
    "The TensorBoard metrics will be received at the server, and you can visualize the training progress by running \n",
    "```commandline\n",
    "tensorboard --logdir=/tmp/nvflare/jobs/workdir/server/simulate_job/tb_events\n",
    "```\n",
    "in a new terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4db1d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
