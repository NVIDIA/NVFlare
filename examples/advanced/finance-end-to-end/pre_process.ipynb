{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d892b5e-2f3b-4182-bedb-d332bfc3a353",
   "metadata": {},
   "source": [
    "# PreProcess Step\n",
    "\n",
    "* Encode categorical data\n",
    "* normalize the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8498bf1-d368-4d15-a5bf-559eb6e3918b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9d04f0-a64d-457b-aacf-1a3737e07e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_input_dir = \"/tmp/dataset/horizontal_credit_fraud_data/\"\n",
    "site_name = \"ZHSZUS33_Bank_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84f89f-fe0a-4387-92a2-49ca9143c141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "dataset_names = [\"train\", \"test\"]\n",
    "datasets = {}\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    file_name = os.path.join(site_input_dir, site_name, f\"{ds_name}_enrichment.csv\" )\n",
    "    df = pd.read_csv(file_name)\n",
    "    datasets[ds_name] = df\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200c438-f285-4037-ad22-b496d57588ca",
   "metadata": {},
   "source": [
    "### Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a87c30-5ebe-4fea-9d69-2f31b07f863a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_columns = ['Currency_Country', 'Beneficiary_BIC', 'Currency', 'UETR', 'Receiver_BIC', 'Sender_BIC']\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    df = datasets[ds_name]\n",
    "    df_encoded = pd.get_dummies(df, columns=category_columns)\n",
    "    print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51062ad-cf73-4ddf-86a9-87ce14d216e4",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdc785e-9597-4083-b74a-2cacb25b20cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Time', 'Class', 'Amount', 'Sender_BIC', 'Receiver_BIC',\n",
       "       'UETR', 'Currency', 'Beneficiary_BIC', 'Currency_Country',\n",
       "       'trans_volume', 'total_amount', 'average_amount', 'hist_trans_volume',\n",
       "       'hist_total_amount', 'hist_average_amount', 'x2_y1', 'x3_y2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5be54-c5e7-43c7-ad4f-de29a09bc7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "processed_dfs = {}\n",
    "\n",
    "numerical_columns = ['Timestamp', 'Class', 'Amount', 'trans_volume', 'total_amount', 'average_amount', 'hist_trans_volume',\n",
    "       'hist_total_amount', 'hist_average_amount', 'x2_y1', 'x3_y2']\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    df = datasets[ds_name]\n",
    "    \n",
    "    # Convert 'Time' column to datetime\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    # Convert datetime to Unix timestamp\n",
    "    df['Timestamp'] = df['Time'].astype(int) / 10**9  # convert to seconds\n",
    "    \n",
    "    # Separate numerical and categorical features\n",
    "    numerical_features = df[numerical_columns]\n",
    "    categorical_features = df[category_columns]\n",
    "\n",
    "    # Initialize the MinMaxScaler (or StandardScaler)\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Fit and transform the numerical data\n",
    "    numerical_normalized = pd.DataFrame(scaler.fit_transform(numerical_features), columns=numerical_features.columns)\n",
    "    \n",
    "    # Combine the normalized numerical features with the categorical features\n",
    "    df_combined = pd.concat([categorical_features, numerical_normalized], axis=1)\n",
    "    \n",
    "    \n",
    "#     # one-hot encoding\n",
    "#     df_combined = pd.get_dummies(df_combined, columns=category_columns)\n",
    "\n",
    "    print(\"Combined DataFrame with Normalized Numerical Features:\")\n",
    "    print(df_combined)\n",
    "    \n",
    "    processed_dfs[ds_name] = df_combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326a613-e683-4f67-810d-aece3d90349e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "for name in processed_dfs:\n",
    "    site_dir = os.path.join(site_input_dir, site_name)\n",
    "    os.makedirs(site_dir, exist_ok=True)\n",
    "    pre_processed_file_name = os.path.join(site_dir, f\"{name}_normalized.csv\")\n",
    "    print(pre_processed_file_name)\n",
    "    processed_dfs[name].to_csv(pre_processed_file_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b8925c-6890-4a45-a9c4-f80399b463cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1\u001b[0m\n",
      "├── history.csv\n",
      "├── test.csv\n",
      "├── test_enrichment.csv\n",
      "├── test_normalized.csv\n",
      "├── train.csv\n",
      "├── train_enrichment.csv\n",
      "└── train_normalized.csv\n",
      "\n",
      "0 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "! tree /tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a33628-acc7-4f42-b2fa-d066699e23eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8591e4e1-74b1-465c-8124-eaf9829a6a8e",
   "metadata": {},
   "source": [
    "Let's go back to the [XGBoost Notebook](./xgboost.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
