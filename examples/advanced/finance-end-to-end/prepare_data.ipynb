{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbe823e-df75-4d9a-8d9c-c11af57c3bcd",
   "metadata": {},
   "source": [
    "# Credit Card Fraud End-to-End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03b26e-3129-4499-9743-be17410c46ec",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "### Based on the riginal data, add randome synthentic data to make full dataset\n",
    "* expand time in seconds x 200 times to cover 26 months\n",
    "* double the data record size\n",
    "* add other categorical features, sender_bic, receiever_bic, beneficiary_bic, orginator_bic, currency, country\n",
    "* currency country and beneficiary_bic country are the same country\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fe43c3-2e99-414f-91ef-b104578d8b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path=\"creditcard.csv\"\n",
    "out_folder=\"/tmp/dataset/horizontal_credit_fraud_data\"\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(out_folder):\n",
    "    shutil.rmtree(out_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09248e1f-2066-459d-bf20-8ffc47b7f272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284808 creditcard.csv\n"
     ]
    }
   ],
   "source": [
    "! wc -l {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8edae6-b906-4631-9294-dbe2e11391f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_max_days=1.9999074074074075\n",
      "min_months=0.0, max_months=26.665432098765432\n"
     ]
    }
   ],
   "source": [
    "# %load_ext cudf.pandas\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# expand original data and generate a 2-plus year data\n",
    "\n",
    "origin_df = pd.read_csv(data_path)\n",
    "old_max_time = origin_df['Time'].max()\n",
    "old_max_days = old_max_time/3600/24\n",
    "print(f\"{old_max_days=}\")\n",
    "\n",
    "N = 4\n",
    "\n",
    "df_temp = origin_df[['Time', 'Amount', 'Class']].copy() \n",
    "df_temp['Time'] = df_temp['Time'] * 400/4\n",
    "\n",
    "# Find the maximum value in the 'Time' column\n",
    "\n",
    "max_time = df_temp['Time'].max()\n",
    "df = df_temp\n",
    "\n",
    "for i in range(1, N): \n",
    "    # Create a duplicate of the DataFrame with incremental 'Time' values\n",
    "\n",
    "    df_duplicate = df_temp.copy()\n",
    "    df_duplicate['Time'] = df_duplicate['Time'] + max_time*i\n",
    "    \n",
    "    # Combine the original DataFrame with the duplicated DataFrame\n",
    "    df = pd.concat([df, df_duplicate], ignore_index=True)\n",
    "    \n",
    "\n",
    "min_time = df['Time'].min()\n",
    "max_time = df['Time'].max()\n",
    "\n",
    "min_months = min_time/3600/24/30 \n",
    "max_months = max_time/3600/24/30 \n",
    "\n",
    "# Try to generate a 2-plus year data\n",
    "\n",
    "print(f\"{min_months=}, {max_months=}\")\n",
    "\n",
    "# List of example BICs for demonstration, BIC and names are random created, they are fakes. \n",
    "bic_list = {\n",
    "    'ZHSZUS33': 'United States',  # Bank 1\n",
    "    'SHSHKHH1': 'Hong Kong',      # bank 2\n",
    "    'YXRXGB22': 'United Kingdom', # bank 3\n",
    "    'WPUWDEFF': 'Germany',        # bank 4\n",
    "    'YMNYFRPP': 'France',         # bank 5\n",
    "    'FBSFCHZH': 'Switzerland',    # Bank 6\n",
    "    'YSYCESMM': 'Spain',          # bank 7\n",
    "    'ZNZZAU3M': 'Australia',      # Bank 8\n",
    "    'HCBHSGSG': 'Singapore',      # bank 9\n",
    "    'XITXUS33': 'United States'   # bank 10\n",
    "}\n",
    "\n",
    "# List of currencies and their respective countries\n",
    "currencies = {\n",
    "    'USD': 'United States',\n",
    "    'EUR': 'Eurozone',\n",
    "    'GBP': 'United Kingdom',\n",
    "    'JPY': 'Japan',\n",
    "    'AUD': 'Australia',\n",
    "    'CHF': 'Switzerland',\n",
    "    'SGD': 'Singapore'\n",
    "}\n",
    "\n",
    "\n",
    "# BIC to Bank Name mapping\n",
    "bic_to_bank = {\n",
    "    'ZHSZUS33': 'Bank_1',\n",
    "    'SHSHKHH1': 'Bank_2',\n",
    "    'YXRXGB22': 'Bank_3',\n",
    "    'WPUWDEFF': 'Bank_4',\n",
    "    'YMNYFRPP': 'Bank_5', \n",
    "    'FBSFCHZH': 'Bank_6', \n",
    "    'YSYCESMM': 'Bank_7', \n",
    "    'ZNZZAU3M': 'Bank_8', \n",
    "    'HCBHSGSG': 'Bank_9', \n",
    "    'XITXUS33': 'Bank_10', \n",
    "}\n",
    "\n",
    "# Function to generate random UETR\n",
    "def generate_random_uetr(length=22):\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "# Function to generate random BICs and currency details\n",
    "def generate_random_details(df):\n",
    "    # Ensure the currency and beneficiary BIC match\n",
    "    def match_currency_and_bic():\n",
    "        while True:\n",
    "            currency = random.choice(list(currencies.keys()))\n",
    "            country = currencies[currency]\n",
    "            matching_bics = [bic for bic, bic_country in bic_list.items() if bic_country == country]\n",
    "            if matching_bics:\n",
    "                return currency, random.choice(matching_bics)\n",
    "    \n",
    "    df['Sender_BIC'] = [random.choice(list(bic_list.keys())) for _ in range(len(df))]\n",
    "    df['Receiver_BIC'] = [random.choice(list(bic_list.keys())) for _ in range(len(df))]\n",
    "    df['UETR'] = [generate_random_uetr() for _ in range(len(df))]\n",
    "    \n",
    "    df['Currency'], df['Beneficiary_BIC'] = zip(*[match_currency_and_bic() for _ in range(len(df))])\n",
    "    df['Currency_Country'] = df['Currency'].map(currencies)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add random BIC and currency details to the DataFrame\n",
    "df = generate_random_details(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b36fbf-f6b4-4a85-a022-748c21e6e309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sender_BIC</th>\n",
       "      <th>Receiver_BIC</th>\n",
       "      <th>UETR</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Beneficiary_BIC</th>\n",
       "      <th>Currency_Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>FBSFCHZH</td>\n",
       "      <td>WPUWDEFF</td>\n",
       "      <td>V4ID8QTCIROHAP683AOX78</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ZNZZAU3M</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>YSYCESMM</td>\n",
       "      <td>R7PCTKF9R1PVGXRXU9AB3J</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ZNZZAU3M</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>HCBHSGSG</td>\n",
       "      <td>FBSFCHZH</td>\n",
       "      <td>RP1SBN0Q5U58XBS8LQNE0J</td>\n",
       "      <td>USD</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>YXRXGB22</td>\n",
       "      <td>YMNYFRPP</td>\n",
       "      <td>MAPFA8RU98VZP4MD6VFN1J</td>\n",
       "      <td>USD</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>XITXUS33</td>\n",
       "      <td>FBSFCHZH</td>\n",
       "      <td>3WX5XAGWK7F3CXRX6RZZK3</td>\n",
       "      <td>USD</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139223</th>\n",
       "      <td>69116200.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>XITXUS33</td>\n",
       "      <td>SHSHKHH1</td>\n",
       "      <td>BEEX2F5NEHDU3YV8G17005</td>\n",
       "      <td>GBP</td>\n",
       "      <td>YXRXGB22</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139224</th>\n",
       "      <td>69116300.0</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>ZHSZUS33</td>\n",
       "      <td>9SJQ6WVX8CGS0P1DYYGQ45</td>\n",
       "      <td>GBP</td>\n",
       "      <td>YXRXGB22</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139225</th>\n",
       "      <td>69116400.0</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "      <td>YXRXGB22</td>\n",
       "      <td>WPUWDEFF</td>\n",
       "      <td>CGUZH7AV1YPIQCLCQMAWV6</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ZNZZAU3M</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139226</th>\n",
       "      <td>69116400.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>WPUWDEFF</td>\n",
       "      <td>WPUWDEFF</td>\n",
       "      <td>9FZFL7WK3AA7K5C0Q6X5W3</td>\n",
       "      <td>SGD</td>\n",
       "      <td>HCBHSGSG</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139227</th>\n",
       "      <td>69116800.0</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "      <td>YMNYFRPP</td>\n",
       "      <td>YSYCESMM</td>\n",
       "      <td>AGKF0NGK83CJQTT5CU36PA</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ZNZZAU3M</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1139228 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time  Amount  Class Sender_BIC Receiver_BIC  \\\n",
       "0               0.0  149.62      0   FBSFCHZH     WPUWDEFF   \n",
       "1               0.0    2.69      0   ZHSZUS33     YSYCESMM   \n",
       "2             100.0  378.66      0   HCBHSGSG     FBSFCHZH   \n",
       "3             100.0  123.50      0   YXRXGB22     YMNYFRPP   \n",
       "4             200.0   69.99      0   XITXUS33     FBSFCHZH   \n",
       "...             ...     ...    ...        ...          ...   \n",
       "1139223  69116200.0    0.77      0   XITXUS33     SHSHKHH1   \n",
       "1139224  69116300.0   24.79      0   ZHSZUS33     ZHSZUS33   \n",
       "1139225  69116400.0   67.88      0   YXRXGB22     WPUWDEFF   \n",
       "1139226  69116400.0   10.00      0   WPUWDEFF     WPUWDEFF   \n",
       "1139227  69116800.0  217.00      0   YMNYFRPP     YSYCESMM   \n",
       "\n",
       "                           UETR Currency Beneficiary_BIC Currency_Country  \n",
       "0        V4ID8QTCIROHAP683AOX78      AUD        ZNZZAU3M        Australia  \n",
       "1        R7PCTKF9R1PVGXRXU9AB3J      AUD        ZNZZAU3M        Australia  \n",
       "2        RP1SBN0Q5U58XBS8LQNE0J      USD        ZHSZUS33    United States  \n",
       "3        MAPFA8RU98VZP4MD6VFN1J      USD        ZHSZUS33    United States  \n",
       "4        3WX5XAGWK7F3CXRX6RZZK3      USD        ZHSZUS33    United States  \n",
       "...                         ...      ...             ...              ...  \n",
       "1139223  BEEX2F5NEHDU3YV8G17005      GBP        YXRXGB22   United Kingdom  \n",
       "1139224  9SJQ6WVX8CGS0P1DYYGQ45      GBP        YXRXGB22   United Kingdom  \n",
       "1139225  CGUZH7AV1YPIQCLCQMAWV6      AUD        ZNZZAU3M        Australia  \n",
       "1139226  9FZFL7WK3AA7K5C0Q6X5W3      SGD        HCBHSGSG        Singapore  \n",
       "1139227  AGKF0NGK83CJQTT5CU36PA      AUD        ZNZZAU3M        Australia  \n",
       "\n",
       "[1139228 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277b3dc-5ef4-441b-bdd0-a5858da18b5c",
   "metadata": {},
   "source": [
    "## Split Historical Train, Test Data\n",
    "\n",
    "We are going to split the data into historical, train and test data by the following rules: \n",
    "* history : 55 %\n",
    "* train : 35% \n",
    "* test : 15%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47961d9f-c0fb-47fc-b901-5512be98ebf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical DataFrame size: 626575\n",
      "Training DataFrame size: 398729\n",
      "Testing DataFrame size: 113924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sort the DataFrame by the Time column\n",
    "df = df.sort_values(by='Time').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "total_size = len(df)\n",
    "historical_size = int(total_size * 0.55)\n",
    "train_size = int(total_size * 0.35)\n",
    "test_size = total_size - historical_size - train_size\n",
    "\n",
    "# Split into historical and remaining data\n",
    "df_history = df.iloc[:historical_size]\n",
    "remaining_df = df.iloc[historical_size:]\n",
    "y = remaining_df.Class\n",
    "\n",
    "\n",
    "ds = remaining_df.drop(\"Class\", axis=1)\n",
    "# Split the remaining data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(ds, y,  test_size=test_size / (train_size + test_size), random_state=42)\n",
    "\n",
    "df_train = pd.concat([y_train, x_train], axis=1)\n",
    "df_test = pd.concat([y_test, x_test], axis=1)\n",
    "\n",
    "# Display sizes of each dataset\n",
    "print(f\"Historical DataFrame size: {len(df_history)}\")\n",
    "print(f\"Training DataFrame size: {len(df_train)}\")\n",
    "print(f\"Testing DataFrame size: {len(df_test)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785c6028-e792-450b-a294-a6460b03fd9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save training and testing sets\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "    \n",
    "df_train.to_csv(path_or_buf=os.path.join(out_folder, \"train.csv\"), index=False)\n",
    "df_test.to_csv(path_or_buf=os.path.join(out_folder, \"test.csv\"), index=False)\n",
    "df_history.to_csv(path_or_buf=os.path.join(out_folder, \"history.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb273b7-4273-414b-9ef9-0da9f7d3e839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/dataset/horizontal_credit_fraud_data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43021d3-fcf2-4249-977e-532363664e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -al {out_folder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1b128-280e-4f20-94c4-e02976bf2c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! find /tmp/dataset/horizontal_credit_fraud_data -exec wc -l {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd187e5-eaf5-41dc-8ea1-111ff2a8497c",
   "metadata": {},
   "source": [
    "## Split Data for differnt Client sites\n",
    "\n",
    "Now, split train, test, history data evenly for n = 2 training sites (Clients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab73eee-5bd3-4ba5-be97-e559b31a0622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "files = [\"history\", \"train\", \"test\"]\n",
    "client_names = set()\n",
    "\n",
    "for f in files: \n",
    "    file_path = os.path.join(out_folder, f + \".csv\") \n",
    "    df = pd.read_csv(file_path)\n",
    "    # Group the DataFrame by 'Sender_BIC'\n",
    "    grouped = df.groupby('Sender_BIC')\n",
    "    # Save each group to a separate file\n",
    "    for name, group in grouped:\n",
    "        bank_name = bic_to_bank[name].replace(\" \", \"_\")\n",
    "        client_name = f\"{name}_{bank_name}\" \n",
    "        client_names.add(client_name)\n",
    "        site_dir = os.path.join(out_folder, client_name)\n",
    "        os.makedirs(site_dir, exist_ok=True)\n",
    "        \n",
    "        filename = os.path.join(site_dir,  f\"{f}.csv\")\n",
    "        group.to_csv(filename, index=False)\n",
    "        print(f\"Saved {name} {f} transactions to {filename}\")\n",
    "\n",
    "print(client_names)\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c238d9-d6a4-4449-accb-6ec0761df19c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! find /tmp/dataset/horizontal_credit_fraud_data -exec wc -l {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e0c91-6c87-44f2-b7a1-f04363ff77a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls -al  /tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454c650-f0f7-4a17-97b7-a413ad6fcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "! find /tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1/ -exec wc -l {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c2c1e5e-8d95-4bc0-97bc-25e15e878433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/tmp/dataset/horizontal_credit_fraud_data/\u001b[0m\n",
      "├── \u001b[01;34mFBSFCHZH_Bank_6\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mHCBHSGSG_Bank_9\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── history.csv\n",
      "├── \u001b[01;34mSHSHKHH1_Bank_2\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── test.csv\n",
      "├── train.csv\n",
      "├── \u001b[01;34mWPUWDEFF_Bank_4\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mXITXUS33_Bank_10\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mYMNYFRPP_Bank_5\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mYSYCESMM_Bank_7\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mYXRXGB22_Bank_3\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mZHSZUS33_Bank_1\u001b[0m\n",
      "│   ├── history.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "└── \u001b[01;34mZNZZAU3M_Bank_8\u001b[0m\n",
      "    ├── history.csv\n",
      "    ├── test.csv\n",
      "    └── train.csv\n",
      "\n",
      "10 directories, 33 files\n"
     ]
    }
   ],
   "source": [
    "!tree  /tmp/dataset/horizontal_credit_fraud_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30661d30-7032-4bde-9fb2-ce67897a2f55",
   "metadata": {},
   "source": [
    "Let's go back to the [XGBoost Notebook](./xgboost.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87163fff-d4cb-485c-ba59-3582104dfcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
