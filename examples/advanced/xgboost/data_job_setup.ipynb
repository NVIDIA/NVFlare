{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada310b-e776-4b9a-aabe-f111c31efcc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Federated Learning for XGBoost - Data and Job Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cbf2-92f2-4a22-8317-69cfb0266e92",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "These examples show how to use [NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html) on tabular data applications.\n",
    "They use [XGBoost](https://github.com/dmlc/xgboost),\n",
    "which is an optimized distributed gradient boosting library.\n",
    "\n",
    "### HIGGS\n",
    "The examples illustrate a binary classification task based on [HIGGS dataset](https://archive.ics.uci.edu/dataset/280/higgs).\n",
    "This dataset contains 11 million instances, each with 28 attributes.\n",
    "Please note that the UCI's website may experience occasional downtime.\n"
    "\n",
    "## Federated Training of XGBoost\n",
    "Several mechanisms have been proposed for training an XGBoost model in a federated learning setting.\n",
    "In these examples, we illustrate the use of NVFlare to carry out *horizontal* federated learning using two approaches: histogram-based collaboration and tree-based collaboration.\n",
    "\n",
    "### Horizontal Federated Learning\n",
    "Under horizontal setting, each participant / client joining the federated learning will have part of the whole data / instances / examples/ records, while each instance has all the features.\n",
    "This is in contrast to vertical federated learning, where each client has part of the feature values for each instance.\n",
    "\n",
    "Below we setup the data and job configs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d872d8a-9e44-49dd-94b1-7862b3815ffe",
   "metadata": {},
   "source": [
    "## 1. Data preparation \n",
    "\n",
    "### Download and Store Data\n",
    "To run the examples, we first download the dataset from the HIGGS link above, which is a single `HIGGS.csv` file.\n",
    "By default, we assume the dataset is downloaded, uncompressed, and stored in `DATASET_ROOT/HIGGS.csv`.\n",
    "\n",
    "### Generate Data Split\n",
    "Since HIGGS dataset is already randomly recorded,\n",
    "data split will be specified by the continuous index ranges for each client,\n",
    "rather than a vector of random instance indices.\n",
    "In this example, we choose uniform data split with 5 clients.\n",
    "**Please change the DATASET_ROOT to the correct local path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906a1c9-dce0-476c-be65-79ebd8ad5da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# please change this DATASET_ROOT to the correct path containing HIGGS dataset\n",
    "%env DATASET_ROOT=/data\n",
    "!python3 utils/prepare_data_split.py \\\n",
    "        --data_path \"${DATASET_ROOT}/HIGGS.csv\" \\\n",
    "        --site_num 5 \\\n",
    "        --size_total 11000000 \\\n",
    "        --size_valid 1000000 \\\n",
    "        --split_method uniform \\\n",
    "        --out_path \"/tmp/nvflare/xgboost/HIGGS/data_splits/5_uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af257e69-2bb7-49b6-ac6c-f007b0e6618e",
   "metadata": {},
   "source": [
    "## 2. Prepare job configs\n",
    "Prepare job configs for both histogram- and tree-based methods under a setting of 5-client, uniform split, and uniform learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8807d89-49f5-4fd0-bf8d-b9fe01047796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env DATA_SPLIT_ROOT=/tmp/nvflare/xgboost/HIGGS/data_splits/\n",
    "!python3 utils/prepare_job_config.py \\\n",
    "        --site_num 5 \\\n",
    "        --training_mode bagging \\\n",
    "        --split_method uniform \\\n",
    "        --lr_mode uniform \\\n",
    "        --nthread 16 \\\n",
    "        --tree_method \"hist\" \\\n",
    "        --data_root \"${DATA_SPLIT_ROOT}\"\n",
    "!python3 utils/prepare_job_config.py \\\n",
    "        --site_num 5 \\\n",
    "        --training_mode histogram \\\n",
    "        --split_method uniform \\\n",
    "        --lr_mode uniform \\\n",
    "        --nthread 16 \\\n",
    "        --tree_method \"hist\" \\\n",
    "        --data_root \"${DATA_SPLIT_ROOT}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
