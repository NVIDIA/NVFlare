{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada310b-e776-4b9a-aabe-f111c31efcc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Histogram-based Federated Learning for XGBoost on HIGGS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653cbf2-92f2-4a22-8317-69cfb0266e92",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Histogram-based Collaboration\n",
    "The histogram-based collaboration federated XGBoost approach leverages NVFlare integration of recently added [federated learning support](https://github.com/dmlc/xgboost/issues/7778) in the XGBoost open-source library,\n",
    "which allows the existing *distributed* XGBoost training algorithm to operate in a federated manner,\n",
    "with the federated clients acting as the distinct workers in the distributed XGBoost algorithm.\n",
    "\n",
    "In distributed XGBoost, the individual workers share and aggregate coarse information about their respective portions of the training data,\n",
    "as required to optimize tree node splitting when building the successive boosted trees.\n",
    "\n",
    "The shared information is in the form of quantile sketches of feature values as well as corresponding sample gradient and sample Hessian histograms.\n",
    "\n",
    "Under federated histogram-based collaboration, precisely the same information is exchanged among the clients.\n",
    "\n",
    "The main differences are that the data is partitioned across the workers according to client data ownership, rather than being arbitrarily partionable, and all communication is via an aggregating federated [gRPC](https://grpc.io) server instead of direct client-to-client communication.\n",
    "\n",
    "Histograms from different clients, in particular, are aggregated in the server and then communicated back to the clients.\n",
    "\n",
    "See [README](./README.md) for more information on the histogram-based collaboration.\n",
    "\n",
    "Below we listed steps to run this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0292c-78b6-4bde-96d6-699dae996173",
   "metadata": {},
   "source": [
    "## 1. Setup NVFLARE\n",
    "\n",
    "Follow the [Getting_Started](https://nvflare.readthedocs.io/en/main/getting_started.html) to setup virtual environment and install NVFLARE\n",
    "\n",
    "We also provide a [Notebook](../../nvflare_setup.ipynb) for this setup process. \n",
    "\n",
    "Assume you have already setup the venv, lets first install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4130b15-09e6-456f-a3c7-87c8ee9e07f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d872d8a-9e44-49dd-94b1-7862b3815ffe",
   "metadata": {},
   "source": [
    "## 2. Data and job configs preparation \n",
    "Follow this [Notebook](../data_job_setup.ipynb) for this setup process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0713e2-e393-41c0-9da0-392535cf8a54",
   "metadata": {},
   "source": [
    "## 3. Run simulated xgboost experiment\n",
    "Now that we have the data and job configs ready, we run the experiment using Simulator.\n",
    "\n",
    "Here we simulate 5 clients under uniform data split.\n",
    "\n",
    "**warning: We suggest you only run this notebook when your machine has more than 25 GB RAM. Otherwise, please try a smaller dataset other than HIGGS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde19b89-3aef-49ac-99d9-800d65829830",
   "metadata": {},
   "source": [
    "Simulator can either be used with CLI command (please run the CLI command in a terminal):\n",
    "\n",
    "```shell\n",
    "nvflare simulator ./jobs/higgs_5_histogram_uniform_split_uniform_lr -w /tmp/nvflare/workspaces/xgboost_workspace_5_histogram_uniform_split_uniform_lr -n 5 -t 5\n",
    "```\n",
    "\n",
    "or via Simulator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c75dcb-014d-40c4-8a4a-7a53847c486b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nvflare.private.fed.app.simulator.simulator_runner import SimulatorRunner  \n",
    "simulator = SimulatorRunner(\n",
    "    job_folder=\"./jobs/higgs_5_histogram_uniform_split_uniform_lr\",\n",
    "    workspace=\"/tmp/nvflare/workspaces/xgboost_workspace_5_histogram_uniform_split_uniform_lr\",\n",
    "    n_clients=5,\n",
    "    threads=5\n",
    ")\n",
    "run_status = simulator.run()\n",
    "print(\"Simulator finished with run_status\", run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9346d",
   "metadata": {},
   "source": [
    "## 4. Result visualization\n",
    "Model accuracy can be visualized in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /tmp/nvflare/workspaces/xgboost_workspace_5_histogram_uniform_split_uniform_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvflare_example",
   "language": "python",
   "name": "nvflare_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
