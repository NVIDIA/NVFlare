{
  "format_version": 2,

  "min_clients": 2,
  "num_rounds": 100,

  "task_data_filters": [],
  "task_result_filters": [],
  "components": [
    {
      "id": "persistor",
      "path": "monai_nvflare.monai_bundle_persistor.MonaiBundlePersistor",
      "args": {
        "bundle_root": "config/spleen_ct_segmentation"
      }
    },
    {
      "id": "shareable_generator",
      "path": "nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator",
      "args": {}
    },
    {
      "id": "aggregator",
      "path": "nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator",
      "args": {
        "expected_data_kind": "WEIGHT_DIFF"
      }
    },
    {
      "id": "model_selector",
      "path": "nvflare.app_common.widgets.intime_model_selector.IntimeModelSelector",
      "args": {}
    },
    {
      "id": "model_locator",
      "path": "nvflare.app_opt.pt.file_model_locator.PTFileModelLocator",
      "args": {
        "pt_persistor_id": "persistor"
      }
    },
    {
      "id": "json_generator",
      "path": "nvflare.app_common.widgets.validation_json_generator.ValidationJsonGenerator",
      "args": {}
    },
    {
      "id": "mlflow_receiver_with_tracking_uri",
      "path": "nvflare.app_opt.tracking.mlflow.mlflow_receiver.MLflowReceiver",
      "args": {
        "tracking_uri": "http://127.0.0.1:5000",
        "kwargs": {
          "experiment_name": "monai-spleen-experiment",
          "run_name": "monai-spleen-with-mlflow",
          "experiment_tags": {
            "mlflow.note.content": "## **MONAI experiment with spleen bundle with MLflow**"
          },
          "run_tags": {
            "mlflow.note.content": "## Federated Experiment tracking with MLflow \n### Example of using **[NVIDIA FLARE](https://nvflare.readthedocs.io/en/main/index.html)** to train and run MONAI-bundle using federated averaging ([FedAvg]([FedAvg](https://arxiv.org/abs/1602.05629))) and [PyTorch](https://pytorch.org/) as the deep learning training framework. This example also highlights the FLARE streaming capability from the clients to the server for server delivery to MLflow.\n"
          }
        },
        "artifact_location": "artifacts"
      }
    }
  ],
  "workflows": [
      {
        "id": "scatter_gather_ctl",
        "path": "nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather",
        "args": {
            "min_clients" : "{min_clients}",
            "num_rounds" : "{num_rounds}",
            "start_round": 0,
            "wait_time_after_min_received": 10,
            "aggregator_id": "aggregator",
            "persistor_id": "persistor",
            "shareable_generator_id": "shareable_generator",
            "train_task_name": "train",
            "train_timeout": 0
        }
      },
      {
        "id": "cross_site_model_eval",
        "path": "nvflare.app_common.workflows.cross_site_model_eval.CrossSiteModelEval",
        "args": {
          "model_locator_id": "model_locator",
          "submit_model_timeout": 600,
          "validation_timeout": 6000,
          "cleanup_models": true
        }
      }
  ]
}
