{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "MONAI Example adopted from https://github.com/Project-MONAI/tutorials/blob/main/2d_classification/monai_101.ipynb\n",
    "\n",
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License.\n",
    "\n",
    "# MONAI 101 tutorial with Federated Learning\n",
    "\n",
    "In this example, the **server** uses the [`FedAvg`](https://github.com/NVIDIA/NVFlare/blob/main/nvflare/app_common/workflows/fedavg.py) controller, which performs the following steps:\n",
    "1. Initialize the global model. This is achieved through the method `load_model()`\n",
    "  from the base class\n",
    "  [`ModelController`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/workflows/model_controller.py#L292),\n",
    "  which relies on the\n",
    "  [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor). \n",
    "2. During each training round, the global model will be sent to the\n",
    "  list of participating clients to perform a training task. This is\n",
    "  done using the\n",
    "  [`send_model()`](https://github.com/NVIDIA/NVFlare/blob/d6827bca96d332adb3402ceceb4b67e876146067/nvflare/app_common/workflows/model_controller.py#L99)\n",
    "  method under the hood from the `ModelController` base class. Once\n",
    "  the clients finish their local training, results will be collected\n",
    "  and sent back to the server as an [`FLModel`](https://nvflare.readthedocs.io/en/main/programming_guide/fl_model.html#flmodel)s.\n",
    "3. Results sent by clients will be aggregated based on the\n",
    "  [`WeightedAggregationHelper`](https://github.com/NVIDIA/NVFlare/blob/fa4d00f76848fe4eb356dcde417c136047eeab36/nvflare/app_common/aggregators/weighted_aggregation_helper.py#L20),\n",
    "  which weighs the contribution from each client based on the number\n",
    "  of local training samples. The aggregated updates are\n",
    "  returned as a new `FLModel`.\n",
    "5. After getting the aggregated results, the global model is [updated](https://github.com/NVIDIA/NVFlare/blob/724140e7dc9081eca7a912a818817f89aadfef5d/nvflare/app_common/workflows/fedavg.py#L63).\n",
    "6. The last step is to save the updated global model, again through\n",
    "  the [`ModelPersistor`](https://nvflare.readthedocs.io/en/main/glossary.html#persistor).\n",
    "\n",
    "The **clients** implement the local training logic using NVFlare's [Client\n",
    "API](https://nvflare.readthedocs.io/en/main/programming_guide/execution_api_type.html#client-api)\n",
    "[here](./code/monai_mednist_train.py). The Client API\n",
    "allows the user to add minimum `nvflare`-specific codes to turn a typical\n",
    "centralized training script to a federated client-side local training\n",
    "script.\n",
    "1. During local training, each client receives a copy of the global\n",
    "  model sent by the server using `flare.receive()` API. The received\n",
    "  global model is an instance of `FLModel`.\n",
    "2. A local validation is first performed, where validation metrics\n",
    "  (accuracy and precision) are streamed to server using the\n",
    "  [`SummaryWriter`](https://nvflare.readthedocs.io/en/main/apidocs/nvflare.client.tracking.html#nvflare.client.tracking.SummaryWriter). The\n",
    "  streamed metrics can be loaded and visualized using [TensorBoard](https://www.tensorflow.org/tensorboard) or [MLflow](https://mlflow.org/).\n",
    "3. Then, each client performs local training as in the non-federated training [notebook](./monai_101.ipynb). At the end of each FL round, each client then sends the computed results (always in\n",
    "  `FLModel` format) to the server for aggregation, using the `flare.send()`\n",
    "  API.\n",
    "\n",
    "This tutorial will use about 7GB of GPU memory and 10 minutes to run.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/NVFlare/blob/main/integration/monai/examples/mednist/monai_101_fl.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite, tqdm]\"\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the NVFlare job templates folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare config -jt ./job_templates\n",
    "!nvflare job list_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create job folder\n",
    "\n",
    "We will use the in-process client API, we prepared a job template ([fedavg_mednist](./job_templates/fedavg_mednist)) based on the [sag_pt in_proc job template](../../../job_templates/sag_pt_in_proc) and run the following command to create the job.\n",
    "The `-f` option allows us to customize some options in the template, such as specifying the training script to be used on the clients and initial arguments to the global model, as well as the number of FL rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare job create -force -j ./jobs/fedavg_mednist -w fedavg_mednist -sd ./code/. \\\n",
    "    -f config_fed_client.conf app_script=monai_mednist_train.py \\\n",
    "    -f config_fed_server.conf model_class_path=monai.networks.nets.densenet121 \\\n",
    "    -f config_fed_server.conf spatial_dims=2 \\\n",
    "    -f config_fed_server.conf in_channels=1 \\\n",
    "    -f config_fed_server.conf out_channels=6 \\\n",
    "    -f config_fed_server.conf num_rounds=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FL experiment\n",
    "Then we can run it using the NVFlare Simulator for `n=2` clients on `t=2` threads in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvflare simulator -n 2 -t 2 ./jobs/fedavg_mednist -w fedavg_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the streamed metrics\n",
    "The accuracy metrics streamed to the server during training can be visualized using either\n",
    "\n",
    "1. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir fedavg_workspace/server/simulate_job/app_server/simulate_job/tb_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/tb.png\" alt=\"TensorBoard Plot\" width=30% height=30% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or\n",
    "\n",
    "2. MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --backend-store-uri fedavg_workspace/server/simulate_job/app_server/mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/mlflow.png\" alt=\"MLflow Plot\" width=50% height=30% />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
