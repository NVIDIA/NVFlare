{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724fee4a",
   "metadata": {},
   "source": [
    "# Parameter-Efficient Fine-Tuning (PEFT) with NeMo\n",
    "\n",
    "In this example, we utilize NeMo's [PEFT](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/nemo_megatron/peft/landing_page.html)\n",
    "methods to showcase how to adapt a large language model (LLM) to \n",
    "a downstream task, such as financial sentiment predictions. \n",
    "\n",
    "With one line configuration change, you can try different PEFT techniques such as [p-tuning](https://arxiv.org/abs/2103.10385), [adapters](https://proceedings.mlr.press/v97/houlsby19a.html), or [LoRA](https://arxiv.org/abs/2106.09685), which add a small number of trainable parameters to the LLM\n",
    "that condition the model to produce the desired output for the downstream task.\n",
    "\n",
    "For more details, see the [PEFT script](https://github.com/NVIDIA/NeMo/blob/main/examples/nlp/language_modeling/tuning/megatron_gpt_peft_tuning.py) in NeMo, which we adapt using NVFlare's Lightning client API to run in a federated scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b07e1a",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "We assume you followed the instructions [here](./README.md) \n",
    "to install the NeMo and NVFlare frameworks and mount the required codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136637e8",
   "metadata": {},
   "source": [
    "## Download the pre-trained LLM\n",
    "In this example, we use a `MegatronGPTModel`, a transformer-based language model based on the GPT architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501fe57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[NeMo W 2025-06-09 20:02:32 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=megatron_gpt_345m,\n",
       " \tdescription=345M parameter GPT generative Megatron model.,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/megatron_gpt_345m.nemo\n",
       " )]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what GPT .nemo models we have available on NGC\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "MegatronGPTModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3702c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megatron_gpt_345m.nemo already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download the model from NGC\n",
    "import os\n",
    "model_file = \"megatron_gpt_345m.nemo\"\n",
    "if not os.path.isfile(model_file):\n",
    "    !wget \"https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/$model_file\"\n",
    "else:\n",
    "    print(f\"{model_file} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f7e84",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "As our downstream task, we will use the [Financial PhraseBank dataset](https://huggingface.co/datasets/financial_phrasebank) for sentiment analysis.\n",
    "\n",
    "The Financial PhraseBank dataset contains the sentiments for financial news headlines from a retail investor's perspective. Further details about the dataset can be found in Malo et al.'s [\"Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts\"](https://arxiv.org/abs/1307.5336).\n",
    "\n",
    "We can configure the prompt template used by NeMo to solve this downstream task by setting `prompt_template: \"{sentence} sentiment: {label}\"` in [megatron_gpt_peft_tuning_config.yaml](./nemo_nvflare/megatron_gpt_peft_tuning_config.yaml) accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c364d4",
   "metadata": {},
   "source": [
    "#### 1. Download the preprocessing scripts\n",
    "We use the preprocessing scripts provided by NeMo which can be downloaded from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc68b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_learning_financial_phrase_bank_preprocessing.py already downloaded.\n"
     ]
    }
   ],
   "source": [
    "script_name = \"prompt_learning_financial_phrase_bank_preprocessing.py\"\n",
    "if not os.path.isfile(script_name):\n",
    "    !wget -N \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/dataset_processing/nlp/financial_phrase_bank/$script_name\"\n",
    "else:\n",
    "    print(f\"{script_name} already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea0b11",
   "metadata": {},
   "source": [
    "#### 2. Download the Financial PhraseBank Dataset\n",
    "\n",
    "Download the `FinancialPhraseBank-v1.0.zip` dataset from [here](https://www.researchgate.net/profile/Pekka_Malo/publication/251231364_FinancialPhraseBank-v1.0/data/0c96051eee4fb1d56e000000/FinancialPhraseBank-v1.0.zip).\n",
    "\n",
    "Then extract it under `./data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a49083",
   "metadata": {},
   "source": [
    "#### 3. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144c7a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_train.jsonl\n",
      "100%|███████████████████████████████████| 1811/1811 [00:00<00:00, 220631.01it/s]\n",
      "Saving val split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "100%|█████████████████████████████████████| 226/226 [00:00<00:00, 250704.23it/s]\n",
      "Saving test split to data/FinancialPhraseBank-v1.0/financial_phrase_bank_test.jsonl\n",
      "100%|█████████████████████████████████████| 227/227 [00:00<00:00, 278719.85it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 prompt_learning_financial_phrase_bank_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff504de",
   "metadata": {},
   "source": [
    "#### 4. Split the dataset to simulate clients\n",
    "Next, we use three clients to simulate federated learning for running PEFT with NeMo. \n",
    "We use a [Dirichlet sampling](https://arxiv.org/abs/2002.06440) strategy for creating a heterogeneous partition. Smaller values of `alpha` cause higher heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc039340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data with 1811 entries\n",
      "After split Dirichlet sampling with alpha=10.0\n",
      "{'site-1': {' negative': 75, ' neutral': 232, ' positive': 129},\n",
      " 'site-2': {' negative': 76, ' neutral': 421, ' positive': 205},\n",
      " 'site-3': {' negative': 95, ' neutral': 454, ' positive': 124}}\n",
      "Save split 1 of 3 with 436 entries to data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl\n",
      "Save split 2 of 3 with 702 entries to data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl\n",
      "Save split 3 of 3 with 673 entries to data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl\n"
     ]
    }
   ],
   "source": [
    "from data.split_financial_phrase_data import clean_memmap\n",
    "\n",
    "# Clean NeMo memmap data before running a new data split\n",
    "clean_memmap(\"./data\")\n",
    "\n",
    "# Split the data\n",
    "alpha = 10.0\n",
    "assert isinstance(alpha, float), \"Expecting float value in filepath names used below.\"\n",
    "!python3 data/split_financial_phrase_data.py --alpha={alpha} --data_path=data/FinancialPhraseBank-v1.0/financial_phrase_bank_train.jsonl --num_clients=3 --out_dir=data/FinancialPhraseBank-v1.0_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb97f8a",
   "metadata": {},
   "source": [
    "Below are some examples of how the training data is distributed amount the three clients when using different values of `alpha`.\n",
    "<div>\n",
    "<img src=\"./figs/summary_alpha1.0.svg\" alt=\"Label distribution with alpha=1.0\" style=\"width: 400px;\"/>\n",
    "<img src=\"./figs/summary_alpha5.0.svg\" alt=\"Label distribution with alpha=5.0\" style=\"width: 400px;\"/>\n",
    "<img src=\"./figs/summary_alpha10.0.svg\" alt=\"Label distribution with alpha=10.0\" style=\"width: 400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b15fad",
   "metadata": {},
   "source": [
    "## Federated learning simulations\n",
    "Next, we are using NVFlare's [simulator](https://nvflare.readthedocs.io/en/latest/user_guide/nvflare_cli/fl_simulator.html) to simulate each client training on their own dataset locally and all three clients training together using the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm implemented in NVFlare.\n",
    "\n",
    "With this setting, we require a GPU with at least 24GB of memory to run all clients in parallel on the same GPU. \n",
    "If you have multiple GPUs in your system, you can use the `gpu` argument to assign one GPU for each client, e.g., `gpu=\"0,1\"`.\n",
    "\n",
    "We will use NVFlare's job command for each setting to create the configurations needed to train the models based on the [sag_nemo](https://github.com/NVIDIA/NVFlare/blob/main/job_templates/sag_nemo/info.md) job template. This template allows the definition of different configurations for each client, which we will use to assign their local training data file to each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7032a",
   "metadata": {},
   "source": [
    "#### 1. Convert NeMo PEFT script to FL\n",
    "\n",
    "To run NeMo in an FL scenario, we convert the NeMo [PEFT script](https://github.com/NVIDIA/NeMo/blob/main/examples/nlp/language_modeling/tuning/megatron_gpt_peft_tuning.py) using the new lightning client API. \n",
    "\n",
    "This conversion can be done with only a few lines of code changes, as highlighted in the figure below:\n",
    "\n",
    "1. Import nvflare lightning api\n",
    "2. Patch your lightning trainer\n",
    "3. (Optionally) validate the current global model\n",
    "4. Train as usually\n",
    "\n",
    "<div>\n",
    "<img src=\"./figs/lightning_client_api.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "</div>\n",
    "\n",
    "You can directly use all the PEFT methods implemented in the NeMo script, by changing the value of [peft_scheme](./nemo_nvflare/megatron_gpt_peft_tuning_config.yaml) in the client configuration shown below accordingly:\n",
    "* p-tuning\n",
    "* adapter + p-tuning\n",
    "* adapter\n",
    "* LoRa\n",
    "* ia3\n",
    "\n",
    "<div>\n",
    "<img src=\"./figs/peft_config.png\" alt=\"PEFT config\" style=\"width: 700px;\"/>\n",
    "</div>\n",
    "\n",
    "In this example, we will use LoRA to run the following experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b2aa0",
   "metadata": {},
   "source": [
    "#### 1. Local training\n",
    "First, we create the job configuration using the Job API.\n",
    "Note, the `app_config` options are specific to the app script (`megatron_gpt_peft_tuning.py`) and modify variables in the NeMo config file (`megatron_gpt_peft_tuning_config.yaml`) directly on execution.\n",
    "\n",
    "At this point, we also modify the local number of clients, local steps, and FL rounds to simulate local training. The PEFT method is [LoRA](https://arxiv.org/abs/2106.09685)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ad90e",
   "metadata": {},
   "source": [
    "Let's create the job and configure it for simulating local training. To do this, we only run 1 round of FL, with each client running 1000 steps on their local dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba037c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nemo_nvflare.peft_model import PEFTmodel\n",
    "\n",
    "from nvflare.app_common.workflows.fedavg import FedAvg\n",
    "from nvflare.app_opt.pt.job_config.base_fed_job import BaseFedJob\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "\n",
    "peft_scheme=\"lora\" # can be either ptuning, adapter, lora, or ia3\n",
    "\n",
    "# Common configs\n",
    "peft_scheme_arg=f\"model.peft.peft_scheme={peft_scheme}\" \n",
    "app_script=\"nemo_nvflare/megatron_gpt_peft_tuning.py\"\n",
    "restore_from_path=f\"{os. getcwd()}/megatron_gpt_345m.nemo\"\n",
    "val_files=f\"model.data.validation_ds.file_names=[{os. getcwd()}/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl]\"\n",
    "train_files_prefix=f\"model.data.train_ds.file_names=[{os. getcwd()}/data/FinancialPhraseBank-v1.0_split/alpha{alpha}_site\"\n",
    "\n",
    "# Simulate local training on the clients\n",
    "n_clients = 3\n",
    "num_rounds=1\n",
    "trainer_config=\"trainer.max_steps=1000 trainer.val_check_interval=100\"\n",
    "\n",
    "# Create BaseFedJob with initial model\n",
    "job = BaseFedJob(\n",
    "  name=f\"peft_{peft_scheme}_local_345M\",\n",
    "  initial_model=PEFTmodel(restore_from_path=restore_from_path),\n",
    ")\n",
    "\n",
    "# Define the controller and send to server\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=num_rounds,\n",
    ")\n",
    "job.to_server(controller)\n",
    "\n",
    "# add NeMo config needed on server\n",
    "job.to_server(\"nemo_nvflare/megatron_gpt_peft_tuning_config.yaml\")\n",
    "\n",
    "# Add clients\n",
    "for i in range(1, n_clients+1):\n",
    "    client_name = f\"site-{i}\"\n",
    "    runner = ScriptRunner(script=app_script, script_args=f\"{peft_scheme_arg} model.restore_from_path={restore_from_path} {trainer_config} {val_files} {train_files_prefix}-{i}.jsonl]\")\n",
    "    job.to(runner, client_name)\n",
    "\n",
    "    # add NeMo config needed on each client\n",
    "    job.to(\"nemo_nvflare/megatron_gpt_peft_tuning_config.yaml\", client_name)\n",
    "\n",
    "job.export_job(\"./jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c05731",
   "metadata": {},
   "source": [
    "Next, simulate each client training on their local dataset using the FL simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb804162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38m2025-06-09 20:02:37,220 - IntimeModelSelector - INFO - model selection weights control: {}\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:38,948 - TBAnalyticsReceiver - INFO - Tensorboard records can be found in /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/server/simulate_job/tb_events you can view it using `tensorboard --logdir=/tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/server/simulate_job/tb_events`\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:43,650 - TaskScriptRunner - INFO - start task run() with full path: /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-1/simulate_job/app_site-1/custom/nemo_nvflare/megatron_gpt_peft_tuning.py\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:43,690 - TaskScriptRunner - INFO - start task run() with full path: /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-2/simulate_job/app_site-2/custom/nemo_nvflare/megatron_gpt_peft_tuning.py\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:43,723 - TaskScriptRunner - INFO - start task run() with full path: /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-3/simulate_job/app_site-3/custom/nemo_nvflare/megatron_gpt_peft_tuning.py\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:48 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:50 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `lightning.pytorch.plugins.precision.MixedPrecision` instead.\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpky57zvro/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpky57zvro/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpky57zvro/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpky57zvro/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n",
      "[NeMo I 2025-06-09 20:02:51 nemo_logging:393] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_loss_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_first_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_last_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: softmax_scale in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: calculate_per_token_loss in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: multi_latent_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: init_model_with_meta_device in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_bf16_reduced_precision_matmul in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: recompute_modules in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_recipe in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_param in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_dot_product_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_multi_head_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: first_last_layers_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_start_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_end_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_intermediate_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_freq in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_ffn_hidden_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_limited_devices in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_group_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_pre_softmax in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_score_function in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_dtype in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_enable_expert_bias in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_bias_update_rate in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_use_legacy_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_enable_deepep in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_expert_capacity_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_pad_expert_input_to_capacity in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_drop_policy in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_recompute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_permute_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_apply_probs_on_input in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cp_comm_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_use_single_mempool in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_retain_backward_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_warmup_steps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: external_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_scope in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: config_logger_dir in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: flash_decode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: inference_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mrope_section in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: is_hybrid_model in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_state_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_head_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: heterogeneous_block_specs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] \n",
      "    \n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    *****  GPTModel is deprecated. Please, use McoreGPTModel instead.  *****\n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:51 nemo_logging:405] Waiting for 2 seconds before this message disappears.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    \n",
      "    ************** Experiment configuration ***********\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    name: megatron_gpt_peft_${model.peft.peft_scheme}_tuning\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      accelerator: gpu\n",
      "      num_nodes: 1\n",
      "      precision: 16\n",
      "      logger: false\n",
      "      enable_checkpointing: false\n",
      "      use_distributed_sampler: false\n",
      "      max_epochs: 9999\n",
      "      max_steps: 1000\n",
      "      log_every_n_steps: 10\n",
      "      val_check_interval: 100\n",
      "      gradient_clip_val: 1.0\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        project: null\n",
      "        name: null\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        monitor: validation_${model.data.validation_ds.metric.name}\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        save_nemo_on_train_end: false\n",
      "        filename: ${name}--{${exp_manager.checkpoint_callback_params.monitor}:.3f}-{step}-{consumed_samples}\n",
      "        model_parallel_size: ${model.tensor_model_parallel_size}\n",
      "        always_save_nemo: false\n",
      "        save_best_model: true\n",
      "      create_early_stopping_callback: false\n",
      "      early_stopping_callback_params:\n",
      "        monitor: val_loss\n",
      "        mode: min\n",
      "        min_delta: 0.001\n",
      "        patience: 10\n",
      "        verbose: true\n",
      "        strict: false\n",
      "    model:\n",
      "      seed: 1234\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 128\n",
      "      micro_batch_size: 4\n",
      "      restore_from_path: /workspace/megatron_gpt_345m.nemo\n",
      "      resume_from_checkpoint: null\n",
      "      save_nemo_on_validation_end: false\n",
      "      sync_batch_comm: false\n",
      "      megatron_amp_O2: false\n",
      "      sequence_parallel: false\n",
      "      activations_checkpoint_granularity: null\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: null\n",
      "      activations_checkpoint_layers_per_pipeline: null\n",
      "      answer_only_loss: true\n",
      "      gradient_as_bucket_view: false\n",
      "      hidden_dropout: 0.0\n",
      "      attention_dropout: 0.0\n",
      "      ffn_dropout: 0.0\n",
      "      peft:\n",
      "        peft_scheme: lora\n",
      "        restore_from_path: null\n",
      "        adapter_tuning:\n",
      "          type: parallel_adapter\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          norm_position: pre\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          norm_type: mixedfusedlayernorm\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        lora_tuning:\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        p_tuning:\n",
      "          virtual_tokens: 10\n",
      "          bottleneck_dim: 1024\n",
      "          embedding_dim: 1024\n",
      "          init_std: 0.023\n",
      "        ia3_tuning:\n",
      "          layer_selection: null\n",
      "      data:\n",
      "        train_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: true\n",
      "          num_workers: 0\n",
      "          memmap_workers: 2\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: true\n",
      "          concat_sampling_probabilities:\n",
      "          - 1.0\n",
      "          label_key: label\n",
      "          add_eos: true\n",
      "          add_sep: false\n",
      "          add_bos: false\n",
      "          truncation_field: sentence\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: '{sentence} sentiment: {label}'\n",
      "          truncation_method: right\n",
      "        validation_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "        test_ds:\n",
      "          file_names: null\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 50\n",
      "          min_lr: 1.0e-06\n",
      "          constant_steps: 0\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "          max_steps: 2000\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:54 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `lightning.pytorch.plugins.precision.MixedPrecision` instead.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    \n",
      "    ************** Experiment configuration ***********\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    name: megatron_gpt_peft_${model.peft.peft_scheme}_tuning\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      accelerator: gpu\n",
      "      num_nodes: 1\n",
      "      precision: 16\n",
      "      logger: false\n",
      "      enable_checkpointing: false\n",
      "      use_distributed_sampler: false\n",
      "      max_epochs: 9999\n",
      "      max_steps: 1000\n",
      "      log_every_n_steps: 10\n",
      "      val_check_interval: 100\n",
      "      gradient_clip_val: 1.0\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        project: null\n",
      "        name: null\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        monitor: validation_${model.data.validation_ds.metric.name}\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        save_nemo_on_train_end: false\n",
      "        filename: ${name}--{${exp_manager.checkpoint_callback_params.monitor}:.3f}-{step}-{consumed_samples}\n",
      "        model_parallel_size: ${model.tensor_model_parallel_size}\n",
      "        always_save_nemo: false\n",
      "        save_best_model: true\n",
      "      create_early_stopping_callback: false\n",
      "      early_stopping_callback_params:\n",
      "        monitor: val_loss\n",
      "        mode: min\n",
      "        min_delta: 0.001\n",
      "        patience: 10\n",
      "        verbose: true\n",
      "        strict: false\n",
      "    model:\n",
      "      seed: 1234\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 128\n",
      "      micro_batch_size: 4\n",
      "      restore_from_path: /workspace/megatron_gpt_345m.nemo\n",
      "      resume_from_checkpoint: null\n",
      "      save_nemo_on_validation_end: false\n",
      "      sync_batch_comm: false\n",
      "      megatron_amp_O2: false\n",
      "      sequence_parallel: false\n",
      "      activations_checkpoint_granularity: null\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: null\n",
      "      activations_checkpoint_layers_per_pipeline: null\n",
      "      answer_only_loss: true\n",
      "      gradient_as_bucket_view: false\n",
      "      hidden_dropout: 0.0\n",
      "      attention_dropout: 0.0\n",
      "      ffn_dropout: 0.0\n",
      "      peft:\n",
      "        peft_scheme: lora\n",
      "        restore_from_path: null\n",
      "        adapter_tuning:\n",
      "          type: parallel_adapter\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          norm_position: pre\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          norm_type: mixedfusedlayernorm\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        lora_tuning:\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        p_tuning:\n",
      "          virtual_tokens: 10\n",
      "          bottleneck_dim: 1024\n",
      "          embedding_dim: 1024\n",
      "          init_std: 0.023\n",
      "        ia3_tuning:\n",
      "          layer_selection: null\n",
      "      data:\n",
      "        train_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: true\n",
      "          num_workers: 0\n",
      "          memmap_workers: 2\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: true\n",
      "          concat_sampling_probabilities:\n",
      "          - 1.0\n",
      "          label_key: label\n",
      "          add_eos: true\n",
      "          add_sep: false\n",
      "          add_bos: false\n",
      "          truncation_field: sentence\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: '{sentence} sentiment: {label}'\n",
      "          truncation_method: right\n",
      "        validation_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "        test_ds:\n",
      "          file_names: null\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 50\n",
      "          min_lr: 1.0e-06\n",
      "          constant_steps: 0\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "          max_steps: 2000\n",
      "    \n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    \n",
      "    ************** Experiment configuration ***********\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] \n",
      "    name: megatron_gpt_peft_${model.peft.peft_scheme}_tuning\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      accelerator: gpu\n",
      "      num_nodes: 1\n",
      "      precision: 16\n",
      "      logger: false\n",
      "      enable_checkpointing: false\n",
      "      use_distributed_sampler: false\n",
      "      max_epochs: 9999\n",
      "      max_steps: 1000\n",
      "      log_every_n_steps: 10\n",
      "      val_check_interval: 100\n",
      "      gradient_clip_val: 1.0\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        project: null\n",
      "        name: null\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        monitor: validation_${model.data.validation_ds.metric.name}\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        save_nemo_on_train_end: false\n",
      "        filename: ${name}--{${exp_manager.checkpoint_callback_params.monitor}:.3f}-{step}-{consumed_samples}\n",
      "        model_parallel_size: ${model.tensor_model_parallel_size}\n",
      "        always_save_nemo: false\n",
      "        save_best_model: true\n",
      "      create_early_stopping_callback: false\n",
      "      early_stopping_callback_params:\n",
      "        monitor: val_loss\n",
      "        mode: min\n",
      "        min_delta: 0.001\n",
      "        patience: 10\n",
      "        verbose: true\n",
      "        strict: false\n",
      "    model:\n",
      "      seed: 1234\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 128\n",
      "      micro_batch_size: 4\n",
      "      restore_from_path: /workspace/megatron_gpt_345m.nemo\n",
      "      resume_from_checkpoint: null\n",
      "      save_nemo_on_validation_end: false\n",
      "      sync_batch_comm: false\n",
      "      megatron_amp_O2: false\n",
      "      sequence_parallel: false\n",
      "      activations_checkpoint_granularity: null\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: null\n",
      "      activations_checkpoint_layers_per_pipeline: null\n",
      "      answer_only_loss: true\n",
      "      gradient_as_bucket_view: false\n",
      "      hidden_dropout: 0.0\n",
      "      attention_dropout: 0.0\n",
      "      ffn_dropout: 0.0\n",
      "      peft:\n",
      "        peft_scheme: lora\n",
      "        restore_from_path: null\n",
      "        adapter_tuning:\n",
      "          type: parallel_adapter\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          norm_position: pre\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          norm_type: mixedfusedlayernorm\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        lora_tuning:\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "        p_tuning:\n",
      "          virtual_tokens: 10\n",
      "          bottleneck_dim: 1024\n",
      "          embedding_dim: 1024\n",
      "          init_std: 0.023\n",
      "        ia3_tuning:\n",
      "          layer_selection: null\n",
      "      data:\n",
      "        train_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: true\n",
      "          num_workers: 0\n",
      "          memmap_workers: 2\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: true\n",
      "          concat_sampling_probabilities:\n",
      "          - 1.0\n",
      "          label_key: label\n",
      "          add_eos: true\n",
      "          add_sep: false\n",
      "          add_bos: false\n",
      "          truncation_field: sentence\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: '{sentence} sentiment: {label}'\n",
      "          truncation_method: right\n",
      "        validation_ds:\n",
      "          file_names:\n",
      "          - /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "        test_ds:\n",
      "          file_names: null\n",
      "          names: null\n",
      "          global_batch_size: ${model.global_batch_size}\n",
      "          micro_batch_size: ${model.micro_batch_size}\n",
      "          shuffle: false\n",
      "          num_workers: 0\n",
      "          memmap_workers: ${model.data.train_ds.memmap_workers}\n",
      "          pin_memory: true\n",
      "          max_seq_length: 2048\n",
      "          min_seq_length: 1\n",
      "          drop_last: false\n",
      "          label_key: ${model.data.train_ds.label_key}\n",
      "          add_eos: ${model.data.train_ds.add_eos}\n",
      "          add_sep: ${model.data.train_ds.add_sep}\n",
      "          add_bos: ${model.data.train_ds.add_bos}\n",
      "          write_predictions_to_file: false\n",
      "          output_file_path_prefix: null\n",
      "          truncation_field: ${model.data.train_ds.truncation_field}\n",
      "          index_mapping_dir: null\n",
      "          prompt_template: ${model.data.train_ds.prompt_template}\n",
      "          tokens_to_generate: 32\n",
      "          truncation_method: right\n",
      "          metric:\n",
      "            name: exact_string_match\n",
      "            average: null\n",
      "            num_classes: null\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 50\n",
      "          min_lr: 1.0e-06\n",
      "          constant_steps: 0\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "          max_steps: 2000\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:54 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `lightning.pytorch.plugins.precision.MixedPrecision` instead.\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:54 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `lightning.pytorch.plugins.precision.MixedPrecision` instead.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] ExpManager schema\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] Experiments will be logged at /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-1/nemo_experiments/megatron_gpt_peft_lora_tuning/2025-06-09_20-02-54\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TensorboardLogger has been set up\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] ExpManager schema\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] Experiments will be logged at /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-3/nemo_experiments/megatron_gpt_peft_lora_tuning/2025-06-09_20-02-54\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TensorboardLogger has been set up\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] ExpManager schema\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] Experiments will be logged at /tmp/nvflare/nemo/peft_lora_local_345M_alpha10.0/site-2/nemo_experiments/megatron_gpt_peft_lora_tuning/2025-06-09_20-02-54\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TensorboardLogger has been set up\n",
      "[NeMo I 2025-06-09 20:02:54 nemo_logging:393] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n",
      "[NeMo I 2025-06-09 20:02:55 nemo_logging:393] Model MegatronGPTSFTModel was successfully restored from /workspace/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2025-06-09 20:02:55 nemo_logging:393] Before adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 354 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    0         Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    354 M     Total params\n",
      "    1,419.485 Total estimated model params size (MB)\n",
      "    301       Modules in train mode\n",
      "    0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmp6se89y7j/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmp6se89y7j/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmp6se89y7j/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmp6se89y7j/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] After adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "\u001b[38m2025-06-09 20:02:56,314 - FedAvg - INFO - Initializing BaseModelController workflow.\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,314 - FedAvg - INFO - Beginning model controller run.\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,315 - FedAvg - INFO - Start FedAvg.\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,315 - FedAvg - INFO - loading initial model from persistor\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,315 - PTFileModelPersistor - INFO - Both source_ckpt_file_full_name and ckpt_preload_path are not provided. Using the default model weights initialized on the persistor side.\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,341 - FedAvg - INFO - Round 0 started.\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,342 - FedAvg - INFO - Sampled clients: ['site-1', 'site-2', 'site-3']\u001b[0m\n",
      "\u001b[38m2025-06-09 20:02:56,342 - FedAvg - INFO - Sending task train to ['site-1', 'site-2', 'site-3']\u001b[0m\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpuwt95_4e/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpuwt95_4e/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpuwt95_4e/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpuwt95_4e/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2025-06-09 20:02:56 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpqvydbaii/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpqvydbaii/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpqvydbaii/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpqvydbaii/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2025-06-09 20:02:56 nemo_logging:393] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_loss_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_first_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_last_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: softmax_scale in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: calculate_per_token_loss in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: multi_latent_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: init_model_with_meta_device in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_bf16_reduced_precision_matmul in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: recompute_modules in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_recipe in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_param in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_dot_product_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_multi_head_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: first_last_layers_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_start_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_end_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_intermediate_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_freq in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_ffn_hidden_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_limited_devices in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_group_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_pre_softmax in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_score_function in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_dtype in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_enable_expert_bias in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_bias_update_rate in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_use_legacy_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_enable_deepep in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_expert_capacity_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_pad_expert_input_to_capacity in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_drop_policy in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_recompute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_permute_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_apply_probs_on_input in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cp_comm_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_use_single_mempool in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_retain_backward_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_warmup_steps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: external_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_scope in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: config_logger_dir in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: flash_decode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: inference_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mrope_section in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: is_hybrid_model in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_state_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_head_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: heterogeneous_block_specs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] \n",
      "    \n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    *****  GPTModel is deprecated. Please, use McoreGPTModel instead.  *****\n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] Waiting for 2 seconds before this message disappears.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_loss_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_first_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_last_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: softmax_scale in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: calculate_per_token_loss in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: multi_latent_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: init_model_with_meta_device in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_bf16_reduced_precision_matmul in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: recompute_modules in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_recipe in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_param in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_dot_product_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_multi_head_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: first_last_layers_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_start_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_end_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_intermediate_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_freq in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_ffn_hidden_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_limited_devices in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_group_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_pre_softmax in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_score_function in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_dtype in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_enable_expert_bias in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_bias_update_rate in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_use_legacy_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_enable_deepep in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_expert_capacity_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_pad_expert_input_to_capacity in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_drop_policy in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_recompute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_permute_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_apply_probs_on_input in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cp_comm_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_use_single_mempool in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_retain_backward_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_warmup_steps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: external_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_scope in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: config_logger_dir in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: flash_decode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: inference_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mrope_section in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: is_hybrid_model in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_state_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_head_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: heterogeneous_block_specs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] \n",
      "    \n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    *****  GPTModel is deprecated. Please, use McoreGPTModel instead.  *****\n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] Waiting for 2 seconds before this message disappears.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_comm_backend in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: hierarchical_context_parallel_sizes in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: expert_tensor_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_extended_tp in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: deterministic_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_loss_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cross_entropy_fusion_impl in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_qkv in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: tp_comm_overlap_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: wgrad_deferral_limit in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: overlap_p2p_comm_warmup_flush in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: microbatch_group_size_per_vp_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mtp_loss_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_first_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_in_last_pipeline_stage in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: softmax_scale in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_query_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: calculate_per_token_loss in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: multi_latent_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: init_model_with_meta_device in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_bf16_reduced_precision_matmul in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: masked_softmax_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: recompute_modules in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_recipe in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_param in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_margin in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_interval in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_history_len in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_amax_compute_algo in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_dot_product_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: fp8_multi_head_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: first_last_layers_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_start_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: num_layers_at_end_in_bf16 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_intermediate_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_shared_expert_overlap in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_freq in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_ffn_hidden_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_limited_devices in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_group_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_pre_softmax in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_topk_scaling_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_score_function in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_dtype in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_enable_expert_bias in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_router_bias_update_rate in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_use_legacy_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_enable_deepep in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_expert_capacity_factor in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_pad_expert_input_to_capacity in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_token_drop_policy in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_layer_recompute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_permute_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: moe_apply_probs_on_input in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cp_comm_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_use_single_mempool in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_retain_backward_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_warmup_steps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: external_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: cuda_graph_scope in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: config_logger_dir in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: flash_decode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: inference_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mrope_section in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: is_hybrid_model in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_state_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_head_dim in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: mamba_num_groups in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] The model: MegatronGPTSFTModel() does not have field.name: heterogeneous_block_specs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] \n",
      "    \n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    *****  GPTModel is deprecated. Please, use McoreGPTModel instead.  *****\n",
      "    ************************************************************************\n",
      "    ************************************************************************\n",
      "    \n",
      "[NeMo W 2025-06-09 20:02:56 nemo_logging:405] Waiting for 2 seconds before this message disappears.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received from server. getTask: train size: 12.6MB (12601064 Bytes) time: 0.102365 seconds\n",
      "pull_task completed. Task name:train Status:True \n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=bfbb9932-0530-4004-9c70-491d7985dd44\n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bfbb9932-0530-4004-9c70-491d7985dd44]: invoking task executor PTInProcessClientAPIExecutor\n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bfbb9932-0530-4004-9c70-491d7985dd44]: execute for task (train)\n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bfbb9932-0530-4004-9c70-491d7985dd44]: send data to peer\n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bfbb9932-0530-4004-9c70-491d7985dd44]: sending payload to peer\n",
      "[identity=site-3, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bfbb9932-0530-4004-9c70-491d7985dd44]: Waiting for result from peer\n",
      "Received from server. getTask: train size: 12.6MB (12601064 Bytes) time: 0.117862 seconds\n",
      "pull_task completed. Task name:train Status:True \n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2\n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2]: invoking task executor PTInProcessClientAPIExecutor\n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2]: execute for task (train)\n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2]: send data to peer\n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2]: sending payload to peer\n",
      "[identity=site-2, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=43a1ac5b-1121-4e68-950c-bf6dbbbf7dd2]: Waiting for result from peer\n",
      "Received from server. getTask: train size: 12.6MB (12601064 Bytes) time: 0.083352 seconds\n",
      "pull_task completed. Task name:train Status:True \n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job]: got task assignment: name=train, id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe\n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe]: invoking task executor PTInProcessClientAPIExecutor\n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe]: execute for task (train)\n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe]: send data to peer\n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe]: sending payload to peer\n",
      "[identity=site-1, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=05c10848-6b26-4a4a-b28b-dbb1abfcb0fe]: Waiting for result from peer\n",
      "[NeMo I 2025-06-09 20:02:59 nemo_logging:393] Model MegatronGPTSFTModel was successfully restored from /workspace/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2025-06-09 20:02:59 nemo_logging:393] Adding adapter weights to the model for PEFT\n",
      "[NeMo I 2025-06-09 20:02:59 nemo_logging:393] Before adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 354 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    0         Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    354 M     Total params\n",
      "    1,419.485 Total estimated model params size (MB)\n",
      "    301       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Model MegatronGPTSFTModel was successfully restored from /workspace/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Adding adapter weights to the model for PEFT\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Model MegatronGPTSFTModel was successfully restored from /workspace/megatron_gpt_345m.nemo.\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Adding adapter weights to the model for PEFT\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Before adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 354 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    0         Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    354 M     Total params\n",
      "    1,419.485 Total estimated model params size (MB)\n",
      "    301       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:00 nemo_logging:393] Before adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 354 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    0         Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    354 M     Total params\n",
      "    1,419.485 Total estimated model params size (MB)\n",
      "    301       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] After adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "--- fl_sys_info ---\n",
      "{'site_name': 'site-3', 'job_id': 'simulate_job'}\n",
      "--- validate global model ---\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] After adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "--- fl_sys_info ---\n",
      "{'site_name': 'site-1', 'job_id': 'simulate_job'}\n",
      "--- validate global model ---\n",
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] After adding PEFT params:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "--- fl_sys_info ---\n",
      "{'site_name': 'site-2', 'job_id': 'simulate_job'}\n",
      "--- validate global model ---\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:161: You have overridden `MegatronGPTSFTModel.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.\n",
      "    \n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[NeMo W 2025-06-09 20:03:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:161: You have overridden `MegatronGPTSFTModel.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.\n",
      "    \n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[NeMo W 2025-06-09 20:03:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:161: You have overridden `MegatronGPTSFTModel.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.\n",
      "    \n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:01 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building indexing for fn = /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Saving idx file = /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl.idx.npy\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Saving metadata file = /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl.idx.info\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 1 / 1 mem-mapped files: 0:00:00.123883\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Processing 1 data files using 2 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:01 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n",
      "[NeMo W 2025-06-09 20:03:02 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n",
      "[NeMo W 2025-06-09 20:03:02 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.126327\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.151809\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.116728\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000669\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "Validation: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:02 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:02 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.127184\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000582\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.146367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000658\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:02 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:02 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:02 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:04 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:05 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:05 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:09 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:10 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:10 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:11 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:11 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:11 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:16 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s][NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by what by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by and by by by by by by by by by by by by by by by by by by by by by by by by By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  - By By By By By by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Sea by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  MarieNirArAttor Attor by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by the Maria by the by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by in by by by since by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by by . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or Reason Reason Reason Reason Reason Reason Reason Reason Reason Reason Att By by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by By by by by by by by by by By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by both by by by by by by by by by no no nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing ter nothing nothing nothing nothing nothing nothing label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  neither by by with by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria Marie by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Sal Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by for by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:16 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m              val_loss               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m    validation_exact_string_match    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36mvalidation_exact_string_match_datalo…\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m           validation_loss           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     validation_loss_dataloader0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────────────────┴──────────────────────────────────────┘\n",
      "[NeMo I 2025-06-09 20:03:16 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:16 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s][NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by what by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by and by by by by by by by by by by by by by by by by by by by by by by by by By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  - By By By By By by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Sea by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  MarieNirArAttor Attor by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by the Maria by the by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by in by by by since by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by by . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or Reason Reason Reason Reason Reason Reason Reason Reason Reason Reason Att By by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by By by by by by by by by by By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by both by by by by by by by by by no no nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing ter nothing nothing nothing nothing nothing nothing label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  neither by by with by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria Marie by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Sal Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by for by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:16 nemo_logging:405] No training data found, reconfiguring microbatches based on validation batch sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s][NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by what by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by and by by by by by by by by by by by by by by by by by by by by by by by by By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  - By By By By By by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Sea by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  MarieNirArAttor Attor by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by the Maria by the by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by in by by by since by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by by . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  or Reason Reason Reason Reason Reason Reason Reason Reason Reason Reason Att By by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by By by by by by by by by by By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by both by by by by by by by by by no no nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing nothing ter nothing nothing nothing nothing nothing nothing label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  neither by by with by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria Marie by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Sal Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by for by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:16 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:16 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m              val_loss               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m    validation_exact_string_match    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36mvalidation_exact_string_match_datalo…\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m           validation_loss           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     validation_loss_dataloader0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────────────────┴──────────────────────────────────────┘\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:17 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m              val_loss               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m    validation_exact_string_match    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36mvalidation_exact_string_match_datalo…\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m           validation_loss           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     validation_loss_dataloader0     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         6.598559856414795          \u001b[0m\u001b[35m \u001b[0m│\n",
      "└───────────────────────────────────────┴──────────────────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:16 nemo_logging:405] No training data found, reconfiguring microbatches based on validation batch sizes.\n",
      "[NeMo W 2025-06-09 20:03:17 nemo_logging:405] No training data found, reconfiguring microbatches based on validation batch sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train new model ---\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.165045\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "--- train new model ---\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "--- train new model ---\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building GPT SFT validation datasets.\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.231014\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.217021\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.231743\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000965\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building GPT SFT traing datasets.\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Building indexing for fn = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Saving idx file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl.idx.npy\n",
      "[NeMo I 2025-06-09 20:03:17 nemo_logging:393] Saving metadata file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl.idx.info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:17 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 1 / 1 mem-mapped files: 0:00:00.189041\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.192465\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.186543\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000927\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building GPT SFT traing datasets.\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0/financial_phrase_bank_val.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000596\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Length of val dataset: 226\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building GPT SFT traing datasets.\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building indexing for fn = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Saving idx file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl.idx.npy\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Saving metadata file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl.idx.info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-09 20:03:18 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n",
      "[NeMo W 2025-06-09 20:03:18 nemo_logging:405] Set dataset max_seq_length to max_position_embeddings 1024 if using learned_absolute position embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building indexing for fn = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Saving idx file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl.idx.npy\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Saving metadata file = /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl.idx.info\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.194826\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 1 / 1 mem-mapped files: 0:00:00.198060\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-3.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000528\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 1 / 1 mem-mapped files: 0:00:00.205600\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "make: Entering directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Processing 1 data files using 2 workers\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "> building indices for blendable datasets ...\n",
      " > sample ratios:\n",
      "   dataset 0, input: 1, achieved: 1\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] > elapsed time for building blendable dataset indices: 0.05 (sec)\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Length of train dataset: 128640\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.179721\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time building 0 / 1 mem-mapped files: 0:00:00.171552\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Configuring DDP for model parallelism.\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-1.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000523\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Computing global indices\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Optimizer groups set:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f36c082fec0>\" \n",
      "    will be used during training (effective maximum steps = 1000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 1.0e-06\n",
      "    constant_steps: 0\n",
      "    max_steps: 1000\n",
      "    )\n",
      "\n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading data files\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Loading /workspace/data/FinancialPhraseBank-v1.0_split/alpha10.0_site-2.jsonl\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Time loading 1 mem-mapped files: 0:00:00.000562\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Computing global indices\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:18 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]make: Entering directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "make: Entering directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "> building indices for blendable datasets ...\n",
      " > sample ratios:\n",
      "   dataset 0, input: 1, achieved: 1\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] > elapsed time for building blendable dataset indices: 0.05 (sec)\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Length of train dataset: 128640\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/opt/NeMo/nemo/collections/nlp/data/language_modeling/megatron'\n",
      "> building indices for blendable datasets ...\n",
      " > sample ratios:\n",
      "   dataset 0, input: 1, achieved: 1\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] > elapsed time for building blendable dataset indices: 0.05 (sec)\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Length of train dataset: 128640\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Building dataloader with consumed samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Configuring DDP for model parallelism.\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Optimizer groups set:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f0d8c7f3500>\" \n",
      "    will be used during training (effective maximum steps = 1000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 1.0e-06\n",
      "    constant_steps: 0\n",
      "    max_steps: 1000\n",
      "    )\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Configuring DDP for model parallelism.\n",
      "\n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:18 nemo_logging:393] Unfrozen adapter : AdapterName.LORA_KQV_ADAPTER\n",
      "[NeMo I 2025-06-09 20:03:18 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:19 nemo_logging:393] Optimizer groups set:\n",
      "      | Name        | Type       | Params | Mode \n",
      "    ---------------------------------------------------\n",
      "    0 | model       | GPTModel   | 358 M  | train\n",
      "    1 | val_metric  | ModuleList | 0      | train\n",
      "    2 | test_metric | ModuleList | 0      | train\n",
      "    ---------------------------------------------------\n",
      "    3.1 M     Trainable params\n",
      "    354 M     Non-trainable params\n",
      "    358 M     Total params\n",
      "    1,432.068 Total estimated model params size (MB)\n",
      "    421       Modules in train mode\n",
      "    0         Modules in eval mode\n",
      "[NeMo I 2025-06-09 20:03:19 nemo_logging:393] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2025-06-09 20:03:19 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f33782b2e70>\" \n",
      "    will be used during training (effective maximum steps = 1000) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 1.0e-06\n",
      "    constant_steps: 0\n",
      "    max_steps: 1000\n",
      "    )\n",
      "\n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][NeMo I 2025-06-09 20:03:19 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO: \n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model       | GPTModel   | 358 M  | train\n",
      "1 | val_metric  | ModuleList | 0      | train\n",
      "2 | test_metric | ModuleList | 0      | train\n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "354 M     Non-trainable params\n",
      "358 M     Total params\n",
      "1,432.068 Total estimated model params size (MB)\n",
      "421       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 20:03:20 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:20 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:20 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:25 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:25 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:25 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:26 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:27 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:27 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-09 20:03:31 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:13<00:00,  0.15it/s][NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  pharm by the by by by by by by by by by by by Francisco Marion Jean Marie Marie Jean Marie Marie Marie Marie Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Rust by by by by by By By By By By By By By By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction Pat by by by by by Maria by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  no then by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria by by by by by by by by by by by by by and by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by and by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Marie St by by the by the with by by by by by . by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  By By by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by Marie by by By by by by by by by by by By by by by by by to by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  , , , , , by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by saying by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Ed Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  for by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  w by by by by by directed by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  are being by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by the by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  besides by by by by by by by By by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:31 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:31 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Epoch 0: :   0%|          | 0/1000 [00:00<?][NeMo I 2025-06-09 20:03:32 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "[NeMo I 2025-06-09 20:03:32 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:13<00:00,  0.15it/s][NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  pharm by the by by by by by by by by by by by Francisco Marion Jean Marie Marie Jean Marie Marie Marie Marie Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Rust by by by by by By By By By By By By By By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction Pat by by by by by Maria by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  no then by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria by by by by by by by by by by by by by and by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by and by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Marie St by by the by the with by by by by by . by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  By By by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by Marie by by By by by by by by by by by By by by by by by to by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  , , , , , by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by saying by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Ed Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  for by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  w by by by by by directed by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  are being by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by the by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  besides by by by by by by by By by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:13<00:00,  0.15it/s][NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  pharm by the by by by by by by by by by by by Francisco Marion Jean Marie Marie Jean Marie Marie Marie Marie Maria Maria Maria Maria Maria Maria Maria Maria label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Rust by by by by by By By By By By By By By By By By By By By By By By By By By label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction Pat by by by by by Maria by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  no then by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria by by by by by by by by by by by by by and by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by and by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Marie St by by the by the with by by by by by . by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  By By by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by Marie by by Marie by by By by by by by by by by by By by by by by by to by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  , , , , , by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria by by by by by by by by by by by by by saying by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Ed Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  for by by Marie by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  w by by by by by directed by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  are being by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  by by by by by by by the by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  besides by by by by by by by By by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] skipping autogenerated example example The bridge will be 1.2 km long and is located between Anasmotet by the road E20 and the new traffic junction in Marieholm by the road E45 . sentiment: prediction  Maria Maria Maria Maria Maria by by by by by by by by by by by by by by by by by by by by by by by by by by by label  neutral\n",
      "[NeMo I 2025-06-09 20:03:32 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:32 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Epoch 0: :   0%|          | 0/1000 [00:00<?][NeMo I 2025-06-09 20:03:32 nemo_logging:393] validation exact_string_match: 0.0\n",
      "[NeMo I 2025-06-09 20:03:32 num_microbatches_calculator:228] setting number of microbatches to constant 32\n",
      "Epoch 0: :   1%|          | 10/1000 [00:37<1:01:37, v_num=2-54, reduced_train_loss=6.580, global_step=9.000, consumed_samples=1280.0, train_step_timing in s=3.720]"
     ]
    }
   ],
   "source": [
    "# required by NeMo models\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# we run all clients on the same GPU. If you have several GPUs, you can use, gpu=\"0,1,2\"\n",
    "job.simulator_run(f\"/tmp/nvflare/nemo/peft_{peft_scheme}_local_345M_alpha{alpha}\", threads=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bff735",
   "metadata": {},
   "source": [
    "#### 2. Federated training\n",
    "Next, we use the [FedAvg](https://arxiv.org/abs/1602.05629) algorithm to adapt the model in a federated scenario. First, create and modify the configuration files again. \n",
    "This time, we increase the number of FL rounds and decrease the number of local steps per round to match the federated scenario. \n",
    "\n",
    "Here, each client runs LoRA for one 200 steps before sending their local model updates to the server for aggregation. This is repeated for 5 FL rounds. All the other parameters are the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f13c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FedAvg setting\n",
    "num_rounds=5\n",
    "trainer_config=\"trainer.max_steps\\=200 trainer.val_check_interval\\=100\"\n",
    "\n",
    "# Create BaseFedJob with initial model\n",
    "job = BaseFedJob(\n",
    "  name=f\"peft_{peft_scheme}_fedavg_345M\",\n",
    "  initial_model=PEFTmodel(restore_from_path=restore_from_path),\n",
    ")\n",
    "\n",
    "# Define the controller and send to server\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=num_rounds,\n",
    ")\n",
    "job.to_server(controller)\n",
    "\n",
    "# add NeMo config needed on server\n",
    "job.to_server(\"nemo_nvflare/megatron_gpt_peft_tuning_config.yaml\")\n",
    "\n",
    "# Add clients\n",
    "for i in range(1, n_clients+1):\n",
    "    client_name = f\"site-{i}\"\n",
    "    runner = ScriptRunner(script=app_script, script_args=f\"{peft_scheme_arg} model.restore_from_path={restore_from_path} {trainer_config} {val_files} {train_files_prefix}-{i}.jsonl]\")\n",
    "    job.to(runner, client_name)\n",
    "\n",
    "    # add NeMo config needed on each client\n",
    "    job.to(\"nemo_nvflare/megatron_gpt_peft_tuning_config.yaml\", client_name)\n",
    "\n",
    "job.export_job(\"./jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b08fc2",
   "metadata": {},
   "source": [
    "Next, simulate the federated training using FedAvg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd93a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# required by NeMo models\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# we run all clients on the same GPU. If you have several GPUs, you can use, gpu=\"0,1,2\"\n",
    "job.simulator_run(f\"/tmp/nvflare/nemo/peft_{peft_scheme}_local_345M_alpha{alpha}\", threads=n_clients, gpu=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c364f6b",
   "metadata": {},
   "source": [
    "You can visualize the training process using TensorBoard by running `tensorboard --logdir /tmp/nvflare/nemo` in a new terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8d9fc",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this scenario, all clients utilize the same validation set, allowing for a direct comparison between the locally p-tuned and federated global models. As anticipated, the FedAvg-trained models achieve a higher overall mean accuracy than those trained solely on their local datasets for different values of `alpha`. This is because the global model has access to all client datasets and can, consequently, generalize better, especially in settings of higher client data heterogeneity.\n",
    "\n",
    "Below are some examples of how the training data is distributed among the three clients when using different values of `alpha`. The lines show the mean accuracy of local models during training and shaded areas indicate the 95% confidence interval. \n",
    "<div>\n",
    "<img src=\"./figs/val_accuracy_alpha1.0.svg\" alt=\"Validation accuracy with alpha=1.0\" style=\"width: 400px;\"/>\n",
    "<img src=\"./figs/val_accuracy_alpha5.0.svg\" alt=\"Validation accuracy with alpha=5.0\" style=\"width: 400px;\"/>\n",
    "<img src=\"./figs/val_accuracy_alpha10.0.svg\" alt=\"Validation accuracy with alpha=10.0\" style=\"width: 400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd3861",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We can use `model.generate()` to run inference after adapting the model. \n",
    "Let's define some test examples to feed to the tuned model to see its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff92d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" sentiment:\"\n",
    "test_examples = [f\"The products have a low salt and fat content .{prompt}\",\n",
    "    f\"The agreement is valid for four years .{prompt}\",\n",
    "    f\"Diluted EPS rose to EUR3 .68 from EUR0 .50 .{prompt}\",\n",
    "    f\"The company is well positioned in Brazil and Uruguay .{prompt}\",\n",
    "    f\"Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier .{prompt}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925529f6",
   "metadata": {},
   "source": [
    "First, we need to convert the best global PEFT model into a NeMo ckpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nemo_nvflare.utils import convert_global_to_ckpt\n",
    "server_workspace = f\"/tmp/nvflare/nemo/peft_{peft_scheme}_fedavg_345M_alpha{alpha}/server/simulate_job/app_server\"\n",
    "global_model_filepath = os.path.join(server_workspace, \"best_FL_global_model.pt\")\n",
    "assert global_model_filepath.endswith(\".pt\")\n",
    "ckpt_path = global_model_filepath.replace(\".pt\", \".ckpt\")\n",
    "convert_global_to_ckpt(global_model_filepath, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f951b5",
   "metadata": {},
   "source": [
    "Next, we will load the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a29fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_sft_model import MegatronGPTSFTModel\n",
    "from nemo.collections.nlp.parts.megatron_trainer_builder import MegatronLMPPTrainerBuilder\n",
    "from nemo.collections.nlp.parts.peft_config import PEFT_CONFIG_MAP\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load model configuration inference of the global model\n",
    "cfg = OmegaConf.load(\"nemo_nvflare/megatron_gpt_peft_fl_eval_config.yaml\")\n",
    "\n",
    "# Build trainer\n",
    "trainer = MegatronLMPPTrainerBuilder(cfg).create_trainer()\n",
    "\n",
    "# Set restore from paths with pre-trained model(s)\n",
    "cfg.model.restore_from_path = \"megatron_gpt_345m.nemo\"\n",
    "\n",
    "# Set the global peft weights\n",
    "cfg.model.peft.restore_from_path = ckpt_path\n",
    "\n",
    "model_cfg = MegatronGPTSFTModel.merge_cfg_with(cfg.model.restore_from_path, cfg)\n",
    "model = MegatronGPTSFTModel.restore_from(cfg.model.restore_from_path, model_cfg, trainer=trainer)\n",
    "peft_cfg_cls = PEFT_CONFIG_MAP[cfg.model.peft.peft_scheme]\n",
    "\n",
    "print(\"PEFT Weights will be loaded from\", cfg.model.peft.restore_from_path)\n",
    "model.load_adapters(cfg.model.peft.restore_from_path, peft_cfg_cls(model_cfg))\n",
    "model.freeze()\n",
    "\n",
    "print(\"Model initialized\", type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac89a917",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the sampling parameters as needed\n",
    "sampling_params = {\n",
    "    \"use_greedy\": True,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_k\": 0,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"add_BOS\": False,\n",
    "    \"all_probs\": False,\n",
    "    \"compute_logprob\": False,\n",
    "    \"end_strings\": [\"<|endoftext|>\", \"<extra_id_1>\"],\n",
    "}\n",
    "\n",
    "response = model.generate(inputs=test_examples, length_params=None, sampling_params=sampling_params)\n",
    "\n",
    "print('The prediction results of some sample queries with the trained model:')\n",
    "for result in response['sentences']:\n",
    "    print(\"-\" * 30)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf078a",
   "metadata": {},
   "source": [
    "The expected output of a well-trained model looks something like this. Note, the test sentences do not include ground truth labels.\n",
    "\n",
    ">      The products have a low salt and fat content . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      The agreement is valid for four years . sentiment: neutral\n",
    ">      ------------------------------\n",
    ">      Diluted EPS rose to EUR3 .68 from EUR0 .50 . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      The company is well positioned in Brazil and Uruguay . sentiment: positive\n",
    ">      ------------------------------\n",
    ">      Profit before taxes decreased by 9 % to EUR 187.8 mn in the first nine months of 2008 , compared to EUR 207.1 mn a year earlier . sentiment: negative\n",
    ">      ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28989209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
