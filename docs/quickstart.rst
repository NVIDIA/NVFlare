.. _quickstart:

######################
Quick Start Series
######################

Welcome to the NVIDIA FLARE Quick Start Series! This guide provides a set of hello-world examples to help you quickly learn how to build federated learning programs using NVIDIA FLARE.

Make sure you have completed the :ref:`installation` steps before proceeding.

Prerequisites
=============
- Python 3.9+
- pip
- Git
- NVFlare installed (see :ref:`installation`)

Quick Start Examples
====================

The following hello-world examples demonstrate different federated learning algorithms and workflows. Each example includes instructions and code to help you get started.

1. **hello-fedavg-pytorch**
   - Federated averaging with PyTorch models and training loops.
   - See: :ref:`hello_pt`
2. **hello-fedavg-lightning**
   - Example using PyTorch Lightning for streamlined model training.
   - See: :ref:`hello_lightning`
3. **hello-fedavg-tensorflow**
   - Federated averaging using TensorFlow models.
   - See: :ref:`hello_tf`
4. **hello-LR**
   - Federated logistic regression example using scikit-learn.
   - See: :ref:`hello_lr`
5. **hello-KMeans**
   - Federated KMeans clustering example.
   - See: :ref:`hello_kmeans`
6. **hello-survival-analysis-KM**
   - Federated Kaplan-Meier survival analysis.
   - See: :ref:`hello_km`
7. **hello_statistics**
   - Federated statistics computation example.
   - See: :ref:`hello_fedstats`
8. **hello-cyclic**
   - Cyclic federated learning workflow example.
   - See: :ref:`hello_cyclic`
9. **hello-cross-site-evaluation**
   - Cross-site evaluation of models in a federated setting.
   - See: :ref:`hello-cross_val`
10. **hello-xgboost**
    - Federated XGBoost example demonstrating gradient boosting for tabular data in a federated setting.
    - See: :ref:`hello_xgboost`

Let's start with hello fedavg with numpy.
