.. _quickstart:

###################
Quick Start Series
###################

Welcome to the NVIDIA FLARE Quick Start Series! This guide provides a set of hello-world examples to help you quickly learn how to build federated learning programs using NVIDIA FLARE.

Make sure you have completed the :ref:`installation` steps before proceeding.

Prerequisites
=============
- Python 3.9+
- pip
- Git
- NVFlare installed (see :ref:`installation`)

Hello-world Examples
====================

The following hello-world examples demonstrate different federated learning algorithms and workflows. Each example includes instructions and code to help you get started.

1. **hello pytorch** `<hello-world/hello-pt/index.html>`_
   - Federated averaging with PyTorch models and training loops.
2. **hello lightning** `<hello-world/hello-lightning/index.html>`_
   - Example using PyTorch Lightning for streamlined model training.
3. **hello tensorflow** `<hello-world/hello-tf/index.html>`_
   - todo
   - Federated averaging using TensorFlow models.
4. **hello Logistic Regression** `<hello-world/hello-lr/index.html>`_
   - Federated logistic regression example using scikit-learn.
5. **hello cyclic** `<hello-world/hello-cyclic/index.html>`_
   - Cyclic federated learning workflow example.
6. **hello tabular statistics** `<hello-world/hello-tabular-stats/index.html>`_
   - Federated statistics computation example.
7. **hello flower** `<hello-world/hello-flower/index.html>`_
   - todo
   - running flower apps in FLARE (todo)
8. **hello xgboost** `<hello-world/hello-xgboost/index.html>`_
    - todo
    - Federated XGBoost example demonstrating gradient boosting for tabular data in a federated setting.


Let's start with hello federated average with pytorch: `<hello-world/hello-pt/index.html>`_