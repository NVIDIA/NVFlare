<!--
# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->


<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Quickstart (Numpy) &mdash; NVIDIA FLARE 2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/additions.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quickstart (TensorFlow 2)" href="hello_tf2.html" />
    <link rel="prev" title="Quickstart (PyTorch)" href="hello_pt.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
           

          
            <a href="../index.html" class="icon icon-home"> NVIDIA FLARE
          

          
          </a>

          
            
            
              <div class="version">
                2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 80%;
    }

    .floatleftcol {
      float: left;
      max-width: 60%;
      padding-right: 20px;
    }
  </style>
  
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../quickstart.html">Quickstart</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hello_pt.html">Quickstart (PyTorch)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Quickstart (Numpy)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#before-you-start">Before You Start</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nvidia-flare-client">NVIDIA FLARE Client</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nvidia-flare-server-application">NVIDIA FLARE Server &amp; Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#model-persistor">Model Persistor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#application-configuration">Application Configuration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#federated-numpy-with-scatter-and-gather-workflow">Federated Numpy with Scatter and Gather Workflow!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setting-up-the-application-environment">Setting Up the Application Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-the-fl-system">Running the FL System</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hello_tf2.html">Quickstart (TensorFlow 2)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide.html">User Guide - Provision, Start, Operate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming_guide.html">Programming Guide - Developing Apps with NVIDIA FLARE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apidocs/modules.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix.html">Appendix</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NVIDIA FLARE</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../quickstart.html">Quickstart</a> &raquo;</li>
        
      <li>Quickstart (Numpy)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/examples/hello_numpy.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="quickstart-numpy">
<h1>Quickstart (Numpy)<a class="headerlink" href="#quickstart-numpy" title="Permalink to this headline">¶</a></h1>
<div class="section" id="before-you-start">
<h2>Before You Start<a class="headerlink" href="#before-you-start" title="Permalink to this headline">¶</a></h2>
<p>Before jumping into this QuickStart guide, make sure you have an environment with <a class="reference external" href="https://pypi.org/project/nvflare/">NVIDIA FLARE</a>
installed. You can follow <a class="reference internal" href="../installation.html"><span class="doc">installation</span></a> on the general concept of setting up a Python virtual
environment (the recommended environment) and how to install NVIDIA FLARE.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This tutorial is meant to solely demonstrate how the NVIDIA FLARE system works, without introducing any actual deep
learning concepts. Through this exercise, you will learn how to use NVIDIA FLARE with numpy to perform basic
computations across two clients with the included Scatter and Gather workflow, which broadcasts the training tasks then
aggregates the results that come back. Due to the simplified weights, you will be able to clearly see and understand
the results of the FL aggregation and the model persistor process.</p>
<p>The design of this exercise consists of one <strong>server</strong> and two <strong>clients</strong> starting with weights <code class="docutils literal notranslate"><span class="pre">[[1,</span> <span class="pre">2,</span> <span class="pre">3],</span> <span class="pre">[4,</span> <span class="pre">5,</span> <span class="pre">6],</span> <span class="pre">[7,</span> <span class="pre">8,</span> <span class="pre">9]]</span></code>.
The following steps compose one cycle of weight updates, called a <strong>round</strong>:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Clients are responsible for adding a delta to the weights to calculate new weights for the model.</p></li>
<li><p>These updates are then sent to the server which will aggregate them to produce a model with new weights.</p></li>
<li><p>Finally, the server sends this updated version of the model back to each client, so the clients can continue to calculate the next model weights in future rounds.</p></li>
</ol>
</div></blockquote>
<p>For this exercise, we will be working with the <code class="docutils literal notranslate"><span class="pre">hello-numpy-sag</span></code> application in the examples folder.
Custom FL applications can contain the folders:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><strong>custom</strong>: contains the custom components (<code class="docutils literal notranslate"><span class="pre">np_trainer.py</span></code>, <code class="docutils literal notranslate"><span class="pre">np_model_persistor.py</span></code>)</p></li>
<li><p><strong>config</strong>: contains client and server configurations (<code class="docutils literal notranslate"><span class="pre">config_fed_client.json</span></code>, <code class="docutils literal notranslate"><span class="pre">config_fed_server.json</span></code>)</p></li>
<li><p><strong>resources</strong>: contains the logger config (<code class="docutils literal notranslate"><span class="pre">log.config</span></code>)</p></li>
</ol>
</div></blockquote>
<p>Let’s get started. First clone the repo, if you haven’t already:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/NVIDIA/NVFlare.git
</pre></div>
</div>
<p>Remember to activate your NVIDIA FLARE Python virtual environment from the installation guide. Ensure numpy is installed.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>nvflare-env<span class="o">)</span> $ python3 -m pip install numpy
</pre></div>
</div>
<p>Now that you have all your dependencies installed, let’s implement the federated learning system.</p>
</div>
<div class="section" id="nvidia-flare-client">
<h2>NVIDIA FLARE Client<a class="headerlink" href="#nvidia-flare-client" title="Permalink to this headline">¶</a></h2>
<p>In a file called <code class="docutils literal notranslate"><span class="pre">np_trainer.py</span></code>, import nvflare and numpy.
Now we will implement the <code class="docutils literal notranslate"><span class="pre">execute</span></code> function to enable the clients to perform
a simple addition of a diff to represent one calculation of training a round.</p>
<p>See <a class="reference internal" href="hello_numpy_np_trainer.html#hello-numpy-np-trainer"><span class="std std-ref">Code of np_trainer</span></a> or find the full code of <code class="docutils literal notranslate"><span class="pre">np_trainer.py</span></code> at
<code class="docutils literal notranslate"><span class="pre">examples/hello-numpy-sag/custom/np_trainer.py</span></code> to follow along.</p>
<p>The server sends either the initial weights or any stored weights to each of the clients
through the <code class="docutils literal notranslate"><span class="pre">Shareable</span></code> object passed into <code class="docutils literal notranslate"><span class="pre">execute()</span></code>. Each client adds the
diff to the model data after retrieving it from the DXO (see <a class="reference internal" href="../programming_guide/data_exchange_object.html#data-exchange-object"><span class="std std-ref">Data Exchange Object (DXO)</span></a>)
obtained from the Shareable, and creates a new <code class="docutils literal notranslate"><span class="pre">Shareable</span></code> to include the new weights also contained
within a DXO.</p>
<p>In a real federated learning training scenario, each client does its training independently on its own dataset.
As such, the weights returned to the server will likely be different for each of the clients.</p>
<p>The FL server can <code class="docutils literal notranslate"><span class="pre">aggregrate</span></code> (in this case average) the clients’ results to produce the aggregated model.</p>
<p>You can learn more about <code class="docutils literal notranslate"><span class="pre">Shareable</span></code> and <code class="docutils literal notranslate"><span class="pre">FLContext</span></code> in the <a class="reference internal" href="../programming_guide.html#programming-guide"><span class="std std-ref">documentation</span></a>.</p>
</div>
<div class="section" id="nvidia-flare-server-application">
<h2>NVIDIA FLARE Server &amp; Application<a class="headerlink" href="#nvidia-flare-server-application" title="Permalink to this headline">¶</a></h2>
<div class="section" id="model-persistor">
<h3>Model Persistor<a class="headerlink" href="#model-persistor" title="Permalink to this headline">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">np_model_persistor.py</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># Copyright (c) 2021, NVIDIA CORPORATION.</span>
<span class="linenos"> 2</span><span class="c1">#</span>
<span class="linenos"> 3</span><span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="linenos"> 4</span><span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="linenos"> 5</span><span class="c1"># You may obtain a copy of the License at</span>
<span class="linenos"> 6</span><span class="c1">#</span>
<span class="linenos"> 7</span><span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="linenos"> 8</span><span class="c1">#</span>
<span class="linenos"> 9</span><span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="linenos">10</span><span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="linenos">11</span><span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="linenos">12</span><span class="c1"># See the License for the specific language governing permissions and</span>
<span class="linenos">13</span><span class="c1"># limitations under the License.</span>
<span class="linenos">14</span>
<span class="linenos">15</span><span class="kn">import</span> <span class="nn">os</span>
<span class="linenos">16</span>
<span class="linenos">17</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos">18</span>
<span class="linenos">19</span><span class="kn">from</span> <span class="nn">constants</span> <span class="kn">import</span> <span class="n">NPConstants</span>
<span class="linenos">20</span><span class="kn">from</span> <span class="nn">nvflare.apis.fl_constant</span> <span class="kn">import</span> <span class="n">FLContextKey</span>
<span class="linenos">21</span><span class="kn">from</span> <span class="nn">nvflare.apis.fl_context</span> <span class="kn">import</span> <span class="n">FLContext</span>
<span class="linenos">22</span><span class="kn">from</span> <span class="nn">nvflare.app_common.abstract.model</span> <span class="kn">import</span> <span class="n">ModelLearnable</span><span class="p">,</span> <span class="n">make_model_learnable</span><span class="p">,</span> <span class="n">ModelLearnableKey</span>
<span class="linenos">23</span><span class="kn">from</span> <span class="nn">nvflare.app_common.abstract.model_persistor</span> <span class="kn">import</span> <span class="n">ModelPersistor</span>
<span class="linenos">24</span><span class="kn">from</span> <span class="nn">nvflare.app_common.app_constant</span> <span class="kn">import</span> <span class="n">AppConstants</span>
<span class="linenos">25</span>
<span class="linenos">26</span>
<span class="linenos">27</span><span class="k">class</span> <span class="nc">NPModelPersistor</span><span class="p">(</span><span class="n">ModelPersistor</span><span class="p">):</span>
<span class="linenos">28</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;server.npy&quot;</span><span class="p">):</span>
<span class="linenos">29</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos">30</span>
<span class="linenos">31</span>        <span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span> <span class="o">=</span> <span class="n">model_dir</span>
<span class="linenos">32</span>        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
<span class="linenos">33</span>
<span class="linenos">34</span>        <span class="c1"># This is default model that will be used if not local model is provided.</span>
<span class="linenos">35</span>        <span class="bp">self</span><span class="o">.</span><span class="n">default_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="linenos">36</span>            <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
<span class="linenos">37</span>        <span class="p">)</span>
<span class="linenos">38</span>
<span class="linenos">39</span>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fl_ctx</span><span class="p">:</span> <span class="n">FLContext</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelLearnable</span><span class="p">:</span>
<span class="linenos">40</span>        <span class="c1"># Get start round from FLContext. If start_round &gt; 0, we will try loading model from disk.</span>
<span class="linenos">41</span>        <span class="n">start_round</span> <span class="o">=</span> <span class="n">fl_ctx</span><span class="o">.</span><span class="n">get_prop</span><span class="p">(</span><span class="n">AppConstants</span><span class="o">.</span><span class="n">START_ROUND</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="linenos">42</span>        <span class="n">engine</span> <span class="o">=</span> <span class="n">fl_ctx</span><span class="o">.</span><span class="n">get_engine</span><span class="p">()</span>
<span class="linenos">43</span>        <span class="n">run_number</span> <span class="o">=</span> <span class="n">fl_ctx</span><span class="o">.</span><span class="n">get_prop</span><span class="p">(</span><span class="n">FLContextKey</span><span class="o">.</span><span class="n">CURRENT_RUN</span><span class="p">)</span>
<span class="linenos">44</span>        <span class="n">run_dir</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">get_workspace</span><span class="p">()</span><span class="o">.</span><span class="n">get_run_dir</span><span class="p">(</span><span class="n">run_number</span><span class="p">)</span>
<span class="linenos">45</span>        <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">run_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
<span class="linenos">46</span>
<span class="linenos">47</span>        <span class="c1"># Create a new numpy model</span>
<span class="linenos">48</span>        <span class="k">if</span> <span class="n">start_round</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">49</span>            <span class="k">try</span><span class="p">:</span>
<span class="linenos">50</span>                <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="linenos">51</span>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="linenos">52</span>                <span class="bp">self</span><span class="o">.</span><span class="n">log_exception</span><span class="p">(</span>
<span class="linenos">53</span>                    <span class="n">fl_ctx</span><span class="p">,</span>
<span class="linenos">54</span>                    <span class="sa">f</span><span class="s2">&quot;Unable to load model from </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">. Using default data instead.&quot;</span><span class="p">,</span>
<span class="linenos">55</span>                    <span class="n">fire_event</span><span class="o">=</span><span class="kc">False</span>
<span class="linenos">56</span>                <span class="p">)</span>
<span class="linenos">57</span>                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">58</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">59</span>            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">60</span>
<span class="linenos">61</span>        <span class="c1"># Generate model dictionary and create model_learnable.</span>
<span class="linenos">62</span>        <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span><span class="n">NPConstants</span><span class="o">.</span><span class="n">NUMPY_KEY</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span>
<span class="linenos">63</span>        <span class="n">model_learnable</span> <span class="o">=</span> <span class="n">make_model_learnable</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">{})</span>
<span class="linenos">64</span>
<span class="linenos">65</span>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded initial model: </span><span class="si">{</span><span class="n">model_learnable</span><span class="p">[</span><span class="n">ModelLearnableKey</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">66</span>        <span class="k">return</span> <span class="n">model_learnable</span>
<span class="linenos">67</span>
<span class="linenos">68</span>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelLearnable</span><span class="p">,</span> <span class="n">fl_ctx</span><span class="p">:</span> <span class="n">FLContext</span><span class="p">):</span>
<span class="linenos">69</span>        <span class="n">engine</span> <span class="o">=</span> <span class="n">fl_ctx</span><span class="o">.</span><span class="n">get_engine</span><span class="p">()</span>
<span class="linenos">70</span>        <span class="n">run_number</span> <span class="o">=</span> <span class="n">fl_ctx</span><span class="o">.</span><span class="n">get_prop</span><span class="p">(</span><span class="n">FLContextKey</span><span class="o">.</span><span class="n">CURRENT_RUN</span><span class="p">)</span>
<span class="linenos">71</span>        <span class="n">run_dir</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">get_workspace</span><span class="p">()</span><span class="o">.</span><span class="n">get_run_dir</span><span class="p">(</span><span class="n">run_number</span><span class="p">)</span>
<span class="linenos">72</span>        <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">run_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
<span class="linenos">73</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
<span class="linenos">74</span>            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="linenos">75</span>
<span class="linenos">76</span>        <span class="n">model_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
<span class="linenos">77</span>        <span class="k">if</span> <span class="n">model_save_path</span><span class="p">:</span>
<span class="linenos">78</span>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_save_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos">79</span>                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="n">ModelLearnableKey</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">][</span><span class="n">NPConstants</span><span class="o">.</span><span class="n">NUMPY_KEY</span><span class="p">])</span>
<span class="linenos">80</span>            <span class="bp">self</span><span class="o">.</span><span class="n">log_info</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Saved numpy model to: </span><span class="si">{</span><span class="n">model_save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The model persistor is used to load and save models on the server. Here, the model is weights packaged into a <code class="docutils literal notranslate"><span class="pre">ModelLearnable</span></code> object.</p>
<p>Internally, DXO is used to manage data after <a class="reference internal" href="../apidocs/nvflare.app_common.shareablegenerators.html#nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator" title="nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullModelShareableGenerator</span></code></a>
converts Learnable to Shareable on the FL server. The DXO helps all of the FL components agree on the format.</p>
<p>In this exercise, we can simply save the model as a binary “.npy” file.
Depending on the frameworks and tools, the methods of saving the model may vary.</p>
</div>
<div class="section" id="application-configuration">
<h3>Application Configuration<a class="headerlink" href="#application-configuration" title="Permalink to this headline">¶</a></h3>
<p>Inside the config folder there are two files, <code class="docutils literal notranslate"><span class="pre">config_fed_client.json</span></code> and <code class="docutils literal notranslate"><span class="pre">config_fed_server.json</span></code>.
For now, the default configurations are sufficient.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">config_fed_server.json</span><a class="headerlink" href="#id2" title="Permalink to this code">¶</a></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="p">{</span>
<span class="linenos"> 2</span>  <span class="nt">&quot;format_version&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos"> 3</span>  <span class="nt">&quot;server&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 4</span>    <span class="nt">&quot;heart_beat_timeout&quot;</span><span class="p">:</span> <span class="mi">600</span>
<span class="linenos"> 5</span>  <span class="p">},</span>
<span class="linenos"> 6</span>  <span class="nt">&quot;task_data_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos"> 7</span>  <span class="nt">&quot;task_result_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos"> 8</span>  <span class="nt">&quot;components&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 9</span>    <span class="p">{</span>
<span class="linenos">10</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;persistor&quot;</span><span class="p">,</span>
<span class="linenos">11</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;np_model_persistor.NPModelPersistor&quot;</span><span class="p">,</span>
<span class="linenos">12</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{}</span>
<span class="linenos">13</span>    <span class="p">},</span>
<span class="linenos">14</span>    <span class="p">{</span>
<span class="linenos">15</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;shareable_generator&quot;</span><span class="p">,</span>
<span class="linenos">16</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator&quot;</span><span class="p">,</span>
<span class="linenos">17</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{}</span>
<span class="linenos">18</span>    <span class="p">},</span>
<span class="linenos">19</span>    <span class="p">{</span>
<span class="linenos">20</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;aggregator&quot;</span><span class="p">,</span>
<span class="linenos">21</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator&quot;</span><span class="p">,</span>
<span class="linenos">22</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">23</span>        <span class="nt">&quot;expected_data_kind&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHTS&quot;</span>
<span class="linenos">24</span>      <span class="p">}</span>
<span class="linenos">25</span>    <span class="p">}</span>
<span class="linenos">26</span>  <span class="p">],</span>
<span class="linenos">27</span>  <span class="nt">&quot;workflows&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">28</span>    <span class="p">{</span>
<span class="linenos">29</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter_and_gather&quot;</span><span class="p">,</span>
<span class="linenos">30</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather&quot;</span><span class="p">,</span>
<span class="linenos">31</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">32</span>        <span class="nt">&quot;min_clients&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">33</span>        <span class="nt">&quot;num_rounds&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="linenos">34</span>        <span class="nt">&quot;start_round&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="linenos">35</span>        <span class="nt">&quot;wait_time_after_min_received&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<span class="linenos">36</span>        <span class="nt">&quot;aggregator_id&quot;</span><span class="p">:</span> <span class="s2">&quot;aggregator&quot;</span><span class="p">,</span>
<span class="linenos">37</span>        <span class="nt">&quot;persistor_id&quot;</span><span class="p">:</span> <span class="s2">&quot;persistor&quot;</span><span class="p">,</span>
<span class="linenos">38</span>        <span class="nt">&quot;shareable_generator_id&quot;</span><span class="p">:</span> <span class="s2">&quot;shareable_generator&quot;</span><span class="p">,</span>
<span class="linenos">39</span>        <span class="nt">&quot;train_task_name&quot;</span><span class="p">:</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
<span class="linenos">40</span>        <span class="nt">&quot;train_timeout&quot;</span><span class="p">:</span> <span class="mi">6000</span>
<span class="linenos">41</span>      <span class="p">}</span>
<span class="linenos">42</span>    <span class="p">}</span>
<span class="linenos">43</span>  <span class="p">]</span>
<span class="linenos">44</span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>Note that the component with id <code class="docutils literal notranslate"><span class="pre">persistor</span></code> points to the custom <code class="docutils literal notranslate"><span class="pre">NPModelPersistor</span></code> with full Python module path.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">config_fed_client.json</span><a class="headerlink" href="#id3" title="Permalink to this code">¶</a></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="p">{</span>
<span class="linenos"> 2</span>  <span class="nt">&quot;format_version&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos"> 3</span>  <span class="nt">&quot;executors&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 4</span>    <span class="p">{</span>
<span class="linenos"> 5</span>      <span class="nt">&quot;tasks&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 6</span>        <span class="s2">&quot;train&quot;</span>
<span class="linenos"> 7</span>      <span class="p">],</span>
<span class="linenos"> 8</span>      <span class="nt">&quot;executor&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 9</span>        <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;np_trainer.NPTrainer&quot;</span><span class="p">,</span>
<span class="linenos">10</span>        <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{}</span>
<span class="linenos">11</span>      <span class="p">}</span>
<span class="linenos">12</span>    <span class="p">}</span>
<span class="linenos">13</span>  <span class="p">],</span>
<span class="linenos">14</span>  <span class="nt">&quot;task_result_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos">15</span>  <span class="nt">&quot;task_data_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos">16</span>  <span class="nt">&quot;components&quot;</span><span class="p">:</span> <span class="p">[]</span>
<span class="linenos">17</span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>Here, in <code class="docutils literal notranslate"><span class="pre">executors</span></code>, the Trainer implementation <code class="docutils literal notranslate"><span class="pre">NPTrainer</span></code> is configured for the task “train”.</p>
</div>
</div>
<div class="section" id="federated-numpy-with-scatter-and-gather-workflow">
<h2>Federated Numpy with Scatter and Gather Workflow!<a class="headerlink" href="#federated-numpy-with-scatter-and-gather-workflow" title="Permalink to this headline">¶</a></h2>
<p>Now you must set up a local environment and generate packages to simulate the server, clients, and admin.</p>
<div class="section" id="setting-up-the-application-environment">
<h3>Setting Up the Application Environment<a class="headerlink" href="#setting-up-the-application-environment" title="Permalink to this headline">¶</a></h3>
<p>This command generates a poc folder with server, two clients, and one admin:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ poc -n <span class="m">2</span>
</pre></div>
</div>
<p>Copy necessary files (the exercise code in the examples directory of the NVFlare repository) to a working folder (upload
folder for the admin):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ mkdir -p poc/admin/transfer
$ cp -rf examples/* poc/admin/transfer
</pre></div>
</div>
<p>With both the client and server ready, you can now run everything and see federated
learning in action. FL systems usually have a server and multiple clients. We
therefore have to start the server first:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./poc/server/startup/start.sh
</pre></div>
</div>
<p>Once the server is running you can start the clients in different terminals.
Open a new terminal and start the first client:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./poc/site-1/startup/start.sh
</pre></div>
</div>
<p>Open another terminal and start the second client:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./poc/site-2/startup/start.sh
</pre></div>
</div>
<p>In one last terminal, start the admin:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./poc/admin/startup/fl_admin.sh localhost
</pre></div>
</div>
<p>This will launch a command prompt, where you can input commands to control and monitor many aspects of
the FL process. Log in by entering <code class="docutils literal notranslate"><span class="pre">admin</span></code> for both the username and password.</p>
</div>
<div class="section" id="running-the-fl-system">
<h3>Running the FL System<a class="headerlink" href="#running-the-fl-system" title="Permalink to this headline">¶</a></h3>
<p>Enter the commands below in order.  Pay close attention to what happens in each of four terminals.  You
can see how the admin controls the server and clients with each command.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; upload_app hello-numpy-sag
</pre></div>
</div>
<p>Uploads the application from the admin client to the server’s staging area.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; set_run_number <span class="m">1</span>
</pre></div>
</div>
<p>Creates a run directory in the workspace for the run_number on the server and all clients. The run directory allows for
the isolation of different runs so the information in one particular run does not interfere with other runs.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; deploy_app hello-numpy-sag all
</pre></div>
</div>
<p>This will make the hello-numpy-sag application the active one in the run_number workspace.  After the above two commands, the
server and all the clients know the hello-numpy-sag application will reside in the <code class="docutils literal notranslate"><span class="pre">run_1</span></code> workspace.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; start_app all
</pre></div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">start_app</span></code> command instructs the NVIDIA FLARE server and clients to start training with the hello-numpy-sag
application in the <code class="docutils literal notranslate"><span class="pre">run_1</span></code> workspace.</p>
<p>From time to time, you can issue <code class="docutils literal notranslate"><span class="pre">check_status</span> <span class="pre">server</span></code> in the admin client to check the entire training progress.</p>
<p>You should now see how the training does in the very first terminal (the one that started the server).</p>
<p>After starting the server and clients, you should begin to see
some outputs in each terminal tracking the progress of the FL run. If everything went as
planned, you should see that through 10 rounds, the FL system has aggregated new models on the server
with the results produced by the clients.</p>
<p>Once the fl run is complete and the server has successfully aggregated the client’s results after all the rounds, run
the following commands in the fl_admin to shutdown the system (while inputting <code class="docutils literal notranslate"><span class="pre">admin</span></code> when prompted with password):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; shutdown client
&gt; shutdown server
&gt; bye
</pre></div>
</div>
<p>In order to stop all processes, run <code class="docutils literal notranslate"><span class="pre">./stop_fl.sh</span></code>.</p>
<p>Congratulations!
You’ve successfully built and run your first numpy federated learning system.
You now have a decent grasp of the main FL concepts, and are ready to start exploring how NVIDIA FLARE can be applied to many other tasks.</p>
<p>The full <a class="reference external" href="https://github.com/NVIDIA/NVFlare/tree/main/examples/hello-numpy-sag">source code</a> for this exercise can be found in <code class="docutils literal notranslate"><span class="pre">examples/hello-numpy-sag</span></code>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="hello_tf2.html" class="btn btn-neutral float-right" title="Quickstart (TensorFlow 2)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="hello_pt.html" class="btn btn-neutral float-left" title="Quickstart (PyTorch)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, NVIDIA.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  p {
    margin-bottom: 1em;
  }

  .rst-content dl dt {
    font-weight: unset;
    margin-bottom: 0;
  }

  .rst-content .section ul p {
    margin-bottom: 0px;
  }
  </style>
  

</body>
</html>