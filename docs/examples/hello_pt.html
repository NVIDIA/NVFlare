<!--
# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->


<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Quickstart (PyTorch) &mdash; NVIDIA FLARE 2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/additions.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quickstart (Numpy)" href="hello_numpy.html" />
    <link rel="prev" title="Quickstart" href="../quickstart.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
           

          
            <a href="../index.html" class="icon icon-home"> NVIDIA FLARE
          

          
          </a>

          
            
            
              <div class="version">
                2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 80%;
    }

    .floatleftcol {
      float: left;
      max-width: 60%;
      padding-right: 20px;
    }
  </style>
  
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../highlights.html">NVIDIA FLARE Key Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../quickstart.html">Quickstart</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#setting-up-the-application-environment-in-poc-mode">Setting Up the Application Environment in POC Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#starting-the-application-environment-in-poc-mode">Starting the Application Environment in POC Mode</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../quickstart.html#example-apps-for-nvidia-flare">Example Apps for NVIDIA FLARE</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Quickstart (PyTorch)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#before-you-start">Before You Start</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nvidia-flare-client">NVIDIA FLARE Client</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#neural-network">Neural Network</a></li>
<li class="toctree-l5"><a class="reference internal" href="#dataset-setup">Dataset &amp; Setup</a></li>
<li class="toctree-l5"><a class="reference internal" href="#local-train">Local Train</a></li>
<li class="toctree-l5"><a class="reference internal" href="#integrate-nvidia-flare-with-local-train">Integrate NVIDIA FLARE with Local Train</a></li>
<li class="toctree-l5"><a class="reference internal" href="#flcontext">FLContext</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#nvidia-flare-server-application">NVIDIA FLARE Server &amp; Application</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#application-configuration">Application Configuration</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#train-the-model-federated">Train the Model, Federated!</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#running-the-fl-system">Running the FL System</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hello_numpy.html">Quickstart (Numpy)</a></li>
<li class="toctree-l3"><a class="reference internal" href="hello_tf2.html">Quickstart (TensorFlow 2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="hello_cross_val.html">Quickstart (Numpy - Cross Site Validation)</a></li>
<li class="toctree-l3"><a class="reference external" href="https://github.com/NVIDIA/NVFlare/tree/main/examples/cifar10">Federated Learning with CIFAR-10</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide.html">User Guide - Provision, Start, Operate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming_guide.html">Programming Guide - Developing Apps with NVIDIA FLARE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apidocs/modules.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix.html">Appendix</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NVIDIA FLARE</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../quickstart.html">Quickstart</a> &raquo;</li>
        
      <li>Quickstart (PyTorch)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/examples/hello_pt.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="quickstart-pytorch">
<h1>Quickstart (PyTorch)<a class="headerlink" href="#quickstart-pytorch" title="Permalink to this headline">¶</a></h1>
<div class="section" id="before-you-start">
<h2>Before You Start<a class="headerlink" href="#before-you-start" title="Permalink to this headline">¶</a></h2>
<p>Feel free to refer to the official <a class="reference internal" href="../programming_guide.html"><span class="doc">documentation</span></a> at any point to learn more about the specifics of <a class="reference external" href="https://pypi.org/project/nvflare/">NVIDIA FLARE</a>.</p>
<p>Make sure you have an environment with NVIDIA FLARE installed.  You can follow the
<a class="reference internal" href="../installation.html"><span class="doc">installation</span></a> guide on the general concept of Python virtual environment (the recommended environment) and how to
install NVIDIA FLARE.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Through this exercise, you will integrate NVIDIA FLARE with the popular
deep learning framework <a class="reference external" href="https://pytorch.org/">PyTorch</a> and learn how to use NVIDIA FLARE to train a convolutional
network with the CIFAR10 dataset using the included Scatter and Gather workflow.</p>
<p>The design of this exercise consists of one <strong>server</strong> and two <strong>clients</strong> all having the same PyTorch model.
The following steps compose one cycle of weight updates, called a <strong>round</strong>:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Clients are responsible for generating individual weight-updates for the model using their own CIFAR10 dataset.</p></li>
<li><p>These updates are then sent to the server which will aggregate them to produce a model with new weights.</p></li>
<li><p>Finally, the server sends this updated version of the model back to each client.</p></li>
</ol>
</div></blockquote>
<p>For this exercise, we will be working with the <code class="docutils literal notranslate"><span class="pre">hello-pt</span></code> application in the examples folder.
Custom FL applications can contain the folders:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><strong>custom</strong>: contains the custom components (<code class="docutils literal notranslate"><span class="pre">simple_network.py</span></code>, <code class="docutils literal notranslate"><span class="pre">cifar10trainer.py</span></code>)</p></li>
<li><p><strong>config</strong>: contains client and server configurations (<code class="docutils literal notranslate"><span class="pre">config_fed_client.json</span></code>, <code class="docutils literal notranslate"><span class="pre">config_fed_server.json</span></code>)</p></li>
<li><p><strong>resources</strong>: contains the logger config (<code class="docutils literal notranslate"><span class="pre">log.config</span></code>)</p></li>
</ol>
</div></blockquote>
<p>Now that you have a rough idea of what is going on, let’s get started. First clone the repo:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/NVIDIA/NVFlare.git
</pre></div>
</div>
<p>Now remember to activate your NVIDIA FLARE Python virtual environment from the installation guide.</p>
<p>Since you will use PyTorch and torchvision for this exercise, let’s go ahead and install both libraries:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>nvflare-env<span class="o">)</span> $ python3 -m pip install torch torchvision
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is a pending fix related to Pillow, PyTorch==1.9 and Numpy.  If you see exception related to
<code class="docutils literal notranslate"><span class="pre">enumerate(self.train_loader)</span></code>, downgrade your Pillow to 8.2.0.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>nvflare-env<span class="o">)</span> $ python3 -m pip install torch torchvision <span class="nv">Pillow</span><span class="o">==</span><span class="m">8</span>.2.0
</pre></div>
</div>
</div>
<p>If you would like to go ahead and run the exercise now, you can skip directly to <a class="reference internal" href="#hands-on"><span class="std std-ref">Train the Model, Federated!</span></a>.</p>
</div>
<div class="section" id="nvidia-flare-client">
<h2>NVIDIA FLARE Client<a class="headerlink" href="#nvidia-flare-client" title="Permalink to this headline">¶</a></h2>
<div class="section" id="neural-network">
<h3>Neural Network<a class="headerlink" href="#neural-network" title="Permalink to this headline">¶</a></h3>
<p>With all the required dependencies installed, you are ready to run a Federated Learning
with two clients and one server. The training procedure and network
architecture are modified from
<a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">Training a Classifier</a>.</p>
<p>Let’s see what an extremely simplified CIFAR10 training looks like:</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">simple_network.py</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">15</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="linenos">16</span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="linenos">17</span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="linenos">18</span>
<span class="linenos">19</span>
<span class="linenos">20</span><span class="k">class</span> <span class="nc">SimpleNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos">21</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">22</span>        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos">23</span>
<span class="linenos">24</span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="linenos">25</span>        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="linenos">26</span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="linenos">27</span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
<span class="linenos">28</span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
<span class="linenos">29</span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="linenos">30</span>
<span class="linenos">31</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos">32</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="linenos">33</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="linenos">34</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># flatten all dimensions except batch</span>
<span class="linenos">35</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="linenos">36</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="linenos">37</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">38</span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">SimpleNetwork</span></code> class is your convolutional neural network to train with the CIFAR10 dataset.
This is not related to NVIDIA FLARE, so we implement it in a file called <code class="docutils literal notranslate"><span class="pre">simple_network.py</span></code>.</p>
</div>
<div class="section" id="dataset-setup">
<h3>Dataset &amp; Setup<a class="headerlink" href="#dataset-setup" title="Permalink to this headline">¶</a></h3>
<p>Now implement the custom class <code class="docutils literal notranslate"><span class="pre">Cifar10Trainer</span></code> as an NVIDIA FLARE Executor in a file
called <code class="docutils literal notranslate"><span class="pre">cifar10trainer.py</span></code>.</p>
<p>In a real FL experiment, each client would have their own dataset used for their local training.
For simplicity’s sake, you can download the same CIFAR10 dataset from the Internet via torchvision’s datasets module.
Additionally, you need to set up the optimizer, loss function and transform to process the data.
You can think of all of this code as part of your local training loop, as every deep learning training has a similar setup.</p>
<p>Since you will encapsulate every training-related step in the <code class="docutils literal notranslate"><span class="pre">Cifar10Trainer</span></code> class, let’s put this preparation stage into the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">37</span><span class="k">class</span> <span class="nc">Cifar10Trainer</span><span class="p">(</span><span class="n">Executor</span><span class="p">):</span>
<span class="linenos">38</span>
<span class="linenos">39</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">train_task_name</span><span class="o">=</span><span class="n">AppConstants</span><span class="o">.</span><span class="n">TASK_TRAIN</span><span class="p">,</span>
<span class="linenos">40</span>                 <span class="n">submit_model_task_name</span><span class="o">=</span><span class="n">AppConstants</span><span class="o">.</span><span class="n">TASK_SUBMIT_MODEL</span><span class="p">,</span> <span class="n">exclude_vars</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="linenos">41</span>        <span class="sd">&quot;&quot;&quot;Cifar10 Trainer handles train and submit_model tasks. During train_task, it trains a</span>
<span class="linenos">42</span><span class="sd">        simple network on CIFAR10 dataset. For submit_model task, it sends the locally trained model</span>
<span class="linenos">43</span><span class="sd">        (if present) to the server.</span>
<span class="linenos">44</span>
<span class="linenos">45</span><span class="sd">        Args:</span>
<span class="linenos">46</span><span class="sd">            lr (float, optional): Learning rate. Defaults to 0.01</span>
<span class="linenos">47</span><span class="sd">            epochs (int, optional): Epochs. Defaults to 5</span>
<span class="linenos">48</span><span class="sd">            train_task_name (str, optional): Task name for train task. Defaults to &quot;train&quot;.</span>
<span class="linenos">49</span><span class="sd">            submit_model_task_name (str, optional): Task name for submit model. Defaults to &quot;submit_model&quot;.</span>
<span class="linenos">50</span><span class="sd">            exclude_vars (list): List of variables to exclude during model loading.</span>
<span class="linenos">51</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos">52</span>        <span class="nb">super</span><span class="p">(</span><span class="n">Cifar10Trainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos">53</span>
<span class="linenos">54</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_lr</span> <span class="o">=</span> <span class="n">lr</span>
<span class="linenos">55</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_epochs</span> <span class="o">=</span> <span class="n">epochs</span>
<span class="linenos">56</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_train_task_name</span> <span class="o">=</span> <span class="n">train_task_name</span>
<span class="linenos">57</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_submit_model_task_name</span> <span class="o">=</span> <span class="n">submit_model_task_name</span>
<span class="linenos">58</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_exclude_vars</span> <span class="o">=</span> <span class="n">exclude_vars</span>
<span class="linenos">59</span>
<span class="linenos">60</span>        <span class="c1"># Training setup</span>
<span class="linenos">61</span>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNetwork</span><span class="p">()</span>
<span class="linenos">62</span>        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="linenos">63</span>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="linenos">64</span>        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="linenos">65</span>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="linenos">66</span>
<span class="linenos">67</span>        <span class="c1"># Create Cifar10 dataset for training.</span>
<span class="linenos">68</span>        <span class="n">transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span>
<span class="linenos">69</span>            <span class="n">ToTensor</span><span class="p">(),</span>
<span class="linenos">70</span>            <span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
<span class="linenos">71</span>        <span class="p">])</span>
<span class="linenos">72</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;~/data&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span>
<span class="linenos">73</span>                                      <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">74</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">75</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">)</span>
<span class="linenos">76</span>
<span class="linenos">77</span>        <span class="c1"># Setup the persistence manager to save PT model.</span>
<span class="linenos">78</span>        <span class="c1"># The default training configuration is used by persistence manager</span>
<span class="linenos">79</span>        <span class="c1"># in case no initial model is found.</span>
<span class="linenos">80</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_default_train_conf</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}}</span>
<span class="linenos">81</span>        <span class="bp">self</span><span class="o">.</span><span class="n">persistence_manager</span> <span class="o">=</span> <span class="n">PTModelPersistenceFormatManager</span><span class="p">(</span>
<span class="linenos">82</span>            <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">default_train_conf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_train_conf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="local-train">
<h3>Local Train<a class="headerlink" href="#local-train" title="Permalink to this headline">¶</a></h3>
<p>Now that you have your network and dataset setup, in the <code class="docutils literal notranslate"><span class="pre">Cifar10Trainer</span></code> class let’s also implement a local training loop in a method called <code class="docutils literal notranslate"><span class="pre">local_train</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">local_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fl_ctx</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">abort_signal</span><span class="p">):</span>
        <span class="c1"># Set the model weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># Basic training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_epochs</span><span class="p">):</span>
            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">abort_signal</span><span class="o">.</span><span class="n">triggered</span><span class="p">:</span>
                    <span class="c1"># If abort_signal is triggered, we simply return.</span>
                    <span class="c1"># The outside function will check it again and decide steps to take.</span>
                    <span class="k">return</span>

                <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">cost</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">cost</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">/</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_info</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_epochs</span><span class="si">}</span><span class="s2">, Iteration: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, &quot;</span>
                                          <span class="sa">f</span><span class="s2">&quot;Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="o">/</span><span class="mi">3000</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Everything up to this point is completely independent of NVIDIA FLARE. It is just purely a PyTorch
deep learning exercise.  You will now build the NVIDIA FLARE application based on this PyTorch code.</p>
</div>
</div>
<div class="section" id="integrate-nvidia-flare-with-local-train">
<h3>Integrate NVIDIA FLARE with Local Train<a class="headerlink" href="#integrate-nvidia-flare-with-local-train" title="Permalink to this headline">¶</a></h3>
<p>NVIDIA FLARE makes it easy to integrate your local train code into the NVIDIA FLARE API.</p>
<p>The simplest way to do this is to subclass the <code class="docutils literal notranslate"><span class="pre">Executor</span></code> class and
implement one method <code class="docutils literal notranslate"><span class="pre">execute</span></code>, which is called every time the client receives
an updated model from the server with the task “train” (the server will broadcast the “train” task in the Scatter and
Gather workflow we will configure below). We can then call our local train inside the <code class="docutils literal notranslate"><span class="pre">execute</span></code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">execute</span></code> method inside the <code class="docutils literal notranslate"><span class="pre">Executor</span></code> class is where all of the client side computation occurs.
In these exercises, we update the weights by training on a local dataset, however, it is important to remember that NVIDIA FLARE is not restricted to just deep learning.
The type of data passed between the server and the clients, and the computations that the clients perform can be anything, as long as all of the FL Components agree on the same format.</p>
</div>
<p>Take a look at the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">shareable</span><span class="p">:</span> <span class="n">Shareable</span><span class="p">,</span> <span class="n">fl_ctx</span><span class="p">:</span> <span class="n">FLContext</span><span class="p">,</span> <span class="n">abort_signal</span><span class="p">:</span> <span class="n">Signal</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Shareable</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">task_name</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_task_name</span><span class="p">:</span>
                <span class="c1"># Get model weights</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">dxo</span> <span class="o">=</span> <span class="n">from_shareable</span><span class="p">(</span><span class="n">shareable</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="s2">&quot;Unable to extract dxo from shareable.&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">make_reply</span><span class="p">(</span><span class="n">ReturnCode</span><span class="o">.</span><span class="n">BAD_TASK_DATA</span><span class="p">)</span>

                <span class="c1"># Ensure data kind is weights.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">dxo</span><span class="o">.</span><span class="n">data_kind</span> <span class="o">==</span> <span class="n">DataKind</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;data_kind expected WEIGHTS but got </span><span class="si">{</span><span class="n">dxo</span><span class="o">.</span><span class="n">data_kind</span><span class="si">}</span><span class="s2"> instead.&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">make_reply</span><span class="p">(</span><span class="n">ReturnCode</span><span class="o">.</span><span class="n">BAD_TASK_DATA</span><span class="p">)</span>

                <span class="c1"># Convert weights to tensor. Run training</span>
                <span class="n">torch_weights</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dxo</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_train</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="n">torch_weights</span><span class="p">,</span> <span class="n">abort_signal</span><span class="p">)</span>

                <span class="c1"># Check the abort_signal after training.</span>
                <span class="c1"># local_train returns early if abort_signal is triggered.</span>
                <span class="k">if</span> <span class="n">abort_signal</span><span class="o">.</span><span class="n">triggered</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">make_reply</span><span class="p">(</span><span class="n">ReturnCode</span><span class="o">.</span><span class="n">TASK_ABORTED</span><span class="p">)</span>

                <span class="c1"># Save the local model after training.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_local_model</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">)</span>

                <span class="c1"># Get the new state dict and send as weights</span>
                <span class="n">new_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
                <span class="n">new_weights</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">new_weights</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                <span class="n">outgoing_dxo</span> <span class="o">=</span> <span class="n">DXO</span><span class="p">(</span><span class="n">data_kind</span><span class="o">=</span><span class="n">DataKind</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_weights</span><span class="p">,</span>
                                   <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="n">MetaKey</span><span class="o">.</span><span class="n">NUM_STEPS_CURRENT_ROUND</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">})</span>
                <span class="k">return</span> <span class="n">outgoing_dxo</span><span class="o">.</span><span class="n">to_shareable</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">task_name</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_submit_model_task_name</span><span class="p">:</span>
                <span class="c1"># Load local model</span>
                <span class="n">ml</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_local_model</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">)</span>

                <span class="c1"># Get the model parameters and create dxo from it</span>
                <span class="n">dxo</span> <span class="o">=</span> <span class="n">model_learnable_to_dxo</span><span class="p">(</span><span class="n">ml</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">dxo</span><span class="o">.</span><span class="n">to_shareable</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">make_reply</span><span class="p">(</span><span class="n">ReturnCode</span><span class="o">.</span><span class="n">TASK_UNKNOWN</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_exception</span><span class="p">(</span><span class="n">fl_ctx</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Exception in simple trainer.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">make_reply</span><span class="p">(</span><span class="n">ReturnCode</span><span class="o">.</span><span class="n">EXECUTION_EXCEPTION</span><span class="p">)</span>
</pre></div>
</div>
<p>The concept of <code class="docutils literal notranslate"><span class="pre">Shareable</span></code> is described in <a class="reference internal" href="../programming_guide/shareable.html#shareable"><span class="std std-ref">shareable</span></a>. Essentially, every
NVIDIA FLARE client receives the model weights from the server in <code class="docutils literal notranslate"><span class="pre">shareable</span></code> passed into the <code class="docutils literal notranslate"><span class="pre">execute</span></code> method, and
returns a new <code class="docutils literal notranslate"><span class="pre">shareable</span></code> back to the server. The data is managed by using DXO (see <a class="reference internal" href="../programming_guide/data_exchange_object.html#data-exchange-object"><span class="std std-ref">Data Exchange Object (DXO)</span></a>
for details).</p>
<p>Thus, the first thing is to retrieve the model weights delivered by server via <code class="docutils literal notranslate"><span class="pre">shareable</span></code>, and this can be seen in
the first part of the code block above before <code class="docutils literal notranslate"><span class="pre">local_train</span></code> is called.</p>
<p>We then perform a local train so the client’s model is trained with its own dataset.</p>
<p>After finishing the local train, the train method builds a new <code class="docutils literal notranslate"><span class="pre">shareable</span></code> with newly-trained weights and metadata and returns it
back to the NVIDIA FLARE server for aggregation.</p>
<p>There is additional logic to handle the “submit_model” task, but that is for the CrossSiteModelEval workflow, so we will
be addressing that in a later example.</p>
</div>
<div class="section" id="flcontext">
<h3>FLContext<a class="headerlink" href="#flcontext" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">FLContext</span></code> is used to set and retrieve FL related information among the FL components via <code class="docutils literal notranslate"><span class="pre">set_prop()</span></code> and
<code class="docutils literal notranslate"><span class="pre">get_prop()</span></code> as well as get services provided by the underlying infrastructure. You can find more details in the
<a class="reference internal" href="../programming_guide/fl_context.html#fl-context"><span class="std std-ref">documentation</span></a>.</p>
</div>
</div>
<div class="section" id="nvidia-flare-server-application">
<h2>NVIDIA FLARE Server &amp; Application<a class="headerlink" href="#nvidia-flare-server-application" title="Permalink to this headline">¶</a></h2>
<p>In this exercise, you can use the default settings, which leverage NVIDIA FLARE built-in components for NVIDIA FLARE server.  These
built-in components are commonly used in most deep learning scenarios.  However, you are encouraged to build your own components
to fully customize NVIDIA FLARE to meet your environment, which we will demonstrate in the following exercises.</p>
<div class="section" id="application-configuration">
<h3>Application Configuration<a class="headerlink" href="#application-configuration" title="Permalink to this headline">¶</a></h3>
<p>Inside the config folder there are two files, <code class="docutils literal notranslate"><span class="pre">config_fed_client.json</span></code> and <code class="docutils literal notranslate"><span class="pre">config_fed_server.json</span></code>.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">config_fed_client.json</span><a class="headerlink" href="#id2" title="Permalink to this code">¶</a></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="p">{</span>
<span class="linenos"> 2</span>  <span class="nt">&quot;format_version&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span>  <span class="nt">&quot;executors&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 5</span>    <span class="p">{</span>
<span class="linenos"> 6</span>      <span class="nt">&quot;tasks&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;submit_model&quot;</span><span class="p">],</span>
<span class="linenos"> 7</span>      <span class="nt">&quot;executor&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 8</span>        <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;cifar10trainer.Cifar10Trainer&quot;</span><span class="p">,</span>
<span class="linenos"> 9</span>        <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">10</span>          <span class="nt">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="linenos">11</span>          <span class="nt">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">1</span>
<span class="linenos">12</span>        <span class="p">}</span>
<span class="linenos">13</span>      <span class="p">}</span>
<span class="linenos">14</span>    <span class="p">},</span>
<span class="linenos">15</span>    <span class="p">{</span>
<span class="linenos">16</span>      <span class="nt">&quot;tasks&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;validate&quot;</span><span class="p">],</span>
<span class="linenos">17</span>      <span class="nt">&quot;executor&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">18</span>        <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;cifar10validator.Cifar10Validator&quot;</span><span class="p">,</span>
<span class="linenos">19</span>        <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">20</span>        <span class="p">}</span>
<span class="linenos">21</span>      <span class="p">}</span>
<span class="linenos">22</span>    <span class="p">}</span>
<span class="linenos">23</span>  <span class="p">],</span>
<span class="linenos">24</span>  <span class="nt">&quot;task_result_filters&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">25</span>  <span class="p">],</span>
<span class="linenos">26</span>  <span class="nt">&quot;task_data_filters&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">27</span>  <span class="p">],</span>
<span class="linenos">28</span>  <span class="nt">&quot;components&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">29</span>  <span class="p">]</span>
<span class="linenos">30</span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>Take a look at line 8.  This is the <code class="docutils literal notranslate"><span class="pre">Cifar10Trainer</span></code> you just implemented.  The NVIDIA FLARE client loads this
application configuration and picks your implementation.  You can easily change it to another class so
your NVIDIA FLARE client has different training logic.</p>
<p>The tasks “train” and “submit_model” have been configured to work with the <code class="docutils literal notranslate"><span class="pre">Cifar10Trainer</span></code> Executor. The “validate”
task for <code class="docutils literal notranslate"><span class="pre">Cifar10Validator</span></code> and the “submit_model” task are used for the CrossSiteModelEval workflow, so we will
be addressing that in a later example.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">config_fed_server.json</span><a class="headerlink" href="#id3" title="Permalink to this code">¶</a></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="p">{</span>
<span class="linenos"> 2</span>  <span class="nt">&quot;format_version&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span>  <span class="nt">&quot;server&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos"> 5</span>    <span class="nt">&quot;heart_beat_timeout&quot;</span><span class="p">:</span> <span class="mi">600</span>
<span class="linenos"> 6</span>  <span class="p">},</span>
<span class="linenos"> 7</span>  <span class="nt">&quot;task_data_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos"> 8</span>  <span class="nt">&quot;task_result_filters&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="linenos"> 9</span>  <span class="nt">&quot;components&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">10</span>    <span class="p">{</span>
<span class="linenos">11</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;persistor&quot;</span><span class="p">,</span>
<span class="linenos">12</span>      <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;PTFileModelPersistor&quot;</span><span class="p">,</span>
<span class="linenos">13</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">14</span>        <span class="nt">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">15</span>          <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;simple_network.SimpleNetwork&quot;</span>
<span class="linenos">16</span>        <span class="p">}</span>
<span class="linenos">17</span>      <span class="p">}</span>
<span class="linenos">18</span>    <span class="p">},</span>
<span class="linenos">19</span>    <span class="p">{</span>
<span class="linenos">20</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;shareable_generator&quot;</span><span class="p">,</span>
<span class="linenos">21</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;nvflare.app_common.shareablegenerators.full_model_shareable_generator.FullModelShareableGenerator&quot;</span><span class="p">,</span>
<span class="linenos">22</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{}</span>
<span class="linenos">23</span>    <span class="p">},</span>
<span class="linenos">24</span>    <span class="p">{</span>
<span class="linenos">25</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;aggregator&quot;</span><span class="p">,</span>
<span class="linenos">26</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;nvflare.app_common.aggregators.intime_accumulate_model_aggregator.InTimeAccumulateWeightedAggregator&quot;</span><span class="p">,</span>
<span class="linenos">27</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">28</span>        <span class="nt">&quot;expected_data_kind&quot;</span><span class="p">:</span> <span class="s2">&quot;WEIGHTS&quot;</span>
<span class="linenos">29</span>      <span class="p">}</span>
<span class="linenos">30</span>    <span class="p">},</span>
<span class="linenos">31</span>    <span class="p">{</span>
<span class="linenos">32</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;model_locator&quot;</span><span class="p">,</span>
<span class="linenos">33</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;pt_model_locator.PTModelLocator&quot;</span><span class="p">,</span>
<span class="linenos">34</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">35</span>
<span class="linenos">36</span>      <span class="p">}</span>
<span class="linenos">37</span>    <span class="p">},</span>
<span class="linenos">38</span>    <span class="p">{</span>
<span class="linenos">39</span>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;json_generator&quot;</span><span class="p">,</span>
<span class="linenos">40</span>      <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;validation_json_generator.ValidationJsonGenerator&quot;</span><span class="p">,</span>
<span class="linenos">41</span>      <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">42</span>      <span class="p">}</span>
<span class="linenos">43</span>    <span class="p">}</span>
<span class="linenos">44</span>  <span class="p">],</span>
<span class="linenos">45</span>  <span class="nt">&quot;workflows&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos">46</span>      <span class="p">{</span>
<span class="linenos">47</span>        <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter_and_gather&quot;</span><span class="p">,</span>
<span class="linenos">48</span>        <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;ScatterAndGather&quot;</span><span class="p">,</span>
<span class="linenos">49</span>        <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">50</span>            <span class="nt">&quot;min_clients&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">51</span>            <span class="nt">&quot;num_rounds&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">52</span>            <span class="nt">&quot;start_round&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="linenos">53</span>            <span class="nt">&quot;wait_time_after_min_received&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<span class="linenos">54</span>            <span class="nt">&quot;aggregator_id&quot;</span><span class="p">:</span> <span class="s2">&quot;aggregator&quot;</span><span class="p">,</span>
<span class="linenos">55</span>            <span class="nt">&quot;persistor_id&quot;</span><span class="p">:</span> <span class="s2">&quot;persistor&quot;</span><span class="p">,</span>
<span class="linenos">56</span>            <span class="nt">&quot;shareable_generator_id&quot;</span><span class="p">:</span> <span class="s2">&quot;shareable_generator&quot;</span><span class="p">,</span>
<span class="linenos">57</span>            <span class="nt">&quot;train_task_name&quot;</span><span class="p">:</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
<span class="linenos">58</span>            <span class="nt">&quot;train_timeout&quot;</span><span class="p">:</span> <span class="mi">0</span>
<span class="linenos">59</span>        <span class="p">}</span>
<span class="linenos">60</span>      <span class="p">},</span>
<span class="linenos">61</span>      <span class="p">{</span>
<span class="linenos">62</span>        <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;cross_site_validate&quot;</span><span class="p">,</span>
<span class="linenos">63</span>        <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;CrossSiteModelEval&quot;</span><span class="p">,</span>
<span class="linenos">64</span>        <span class="nt">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
<span class="linenos">65</span>          <span class="nt">&quot;model_locator_id&quot;</span><span class="p">:</span> <span class="s2">&quot;model_locator&quot;</span>
<span class="linenos">66</span>        <span class="p">}</span>
<span class="linenos">67</span>      <span class="p">}</span>
<span class="linenos">68</span>  <span class="p">]</span>
<span class="linenos">69</span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>The server application configuration, like said before, leverages NVIDIA FLARE built-in components. Remember, you
are encouraged to change them to your own classes whenever you have different application logic.</p>
<p>Note that on line 12, <code class="docutils literal notranslate"><span class="pre">persistor</span></code> points to <code class="docutils literal notranslate"><span class="pre">PTFileModelPersistor</span></code>.
NVIDIA FLARE provides a built-in PyTorch implementation for a model persistor, however for other frameworks/libraries, you will have to implement your own.</p>
<p>The Scatter and Gather workflow is implemented by <a class="reference internal" href="../apidocs/nvflare.app_common.workflows.html#nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather" title="nvflare.app_common.workflows.scatter_and_gather.ScatterAndGather"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScatterAndGather</span></code></a>
and is configured to make use of the components with id “aggregator”, “persistor”, and “shareable_generator”. The workflow
code is all open source now, so feel free to study and use it as inspiration to write your own workflows to support your needs.</p>
</div>
</div>
<div class="section" id="train-the-model-federated">
<span id="hands-on"></span><h2>Train the Model, Federated!<a class="headerlink" href="#train-the-model-federated" title="Permalink to this headline">¶</a></h2>
<p>Now you can use admin commands to upload, deploy, and start this example app. To do this on a proof of concept local
FL system, follow the sections <a class="reference internal" href="../quickstart.html#setting-up-poc"><span class="std std-ref">Setting Up the Application Environment in POC Mode</span></a> and <a class="reference internal" href="../quickstart.html#starting-poc"><span class="std std-ref">Starting the Application Environment in POC Mode</span></a> if you have not already.</p>
<div class="section" id="running-the-fl-system">
<h3>Running the FL System<a class="headerlink" href="#running-the-fl-system" title="Permalink to this headline">¶</a></h3>
<p>With the admin client command prompt successfully connected and logged in, enter the commands below in order.  Pay close
attention to what happens in each of four terminals.  You can see how the admin controls the server and clients with
each command.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; upload_app hello-pt
</pre></div>
</div>
<p>Uploads the application from the admin client to the server’s staging area.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; set_run_number <span class="m">1</span>
</pre></div>
</div>
<p>Creates a run directory in the workspace for the run_number on the server and all clients. The run directory allows for
the isolation of different runs so the information in one particular run does not interfere with other runs.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; deploy_app hello-pt all
</pre></div>
</div>
<p>This will make the hello-pt application the active one in the run_number workspace.  After the above two commands,
the server and all the clients know the hello-pt application will reside in the <code class="docutils literal notranslate"><span class="pre">run_1</span></code> workspace.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; start_app all
</pre></div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">start_app</span></code> command instructs the NVIDIA FLARE server and clients to start training with the hello-pt application in that <code class="docutils literal notranslate"><span class="pre">run_1</span></code> workspace.</p>
<p>From time to time, you can issue <code class="docutils literal notranslate"><span class="pre">check_status</span> <span class="pre">server</span></code> in the admin client to check the entire training progress.</p>
<p>You should now see how the training does in the very first terminal (the one that started the server).</p>
<p>Once the fl run is complete and the server has successfully aggregated the clients’ results after all the rounds,
run the following commands in the fl_admin to shutdown the system (while inputting <code class="docutils literal notranslate"><span class="pre">admin</span></code> when prompted with user name):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; shutdown client
&gt; shutdown server
&gt; bye
</pre></div>
</div>
<p>In order to stop all processes, run <code class="docutils literal notranslate"><span class="pre">./stop_fl.sh</span></code>.</p>
<p>All artifacts from the FL run can be found in the server run folder you created with <code class="docutils literal notranslate"><span class="pre">set_run_number</span></code>.  In this exercise, the folder is <code class="docutils literal notranslate"><span class="pre">run_1</span></code>.</p>
<p>Congratulations!
You’ve successfully built and run your first federated learning system.
The full <a class="reference external" href="https://github.com/NVIDIA/NVFlare/tree/main/examples/hello-pt/">source code</a> for this exercise can be found in <code class="docutils literal notranslate"><span class="pre">examples/hello-pt</span></code>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="hello_numpy.html" class="btn btn-neutral float-right" title="Quickstart (Numpy)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../quickstart.html" class="btn btn-neutral float-left" title="Quickstart" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, NVIDIA.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  p {
    margin-bottom: 1em;
  }

  .rst-content dl dt {
    font-weight: unset;
    margin-bottom: 0;
  }

  .rst-content .section ul p {
    margin-bottom: 0px;
  }
  </style>
  

</body>
</html>