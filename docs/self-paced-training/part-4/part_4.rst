===============================
Part 4: Advanced Federated Learning
===============================

`Chapter 7: Federated Learning Algorithms and Workflows <https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/self-paced-training/part-4_advanced_federated_learning/chapter-7_algorithms_and_workflows/07.0_introduction/introduction.ipynb>`_

`Chapter 8: Federated LLM Training <https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/self-paced-training/part-4_advanced_federated_learning/chapter-8_federated_LLM_training/08.0_introduction/introduction.ipynb>`_

`Chapter 9: FLARE Low-level APIs <https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/self-paced-training/part-4_advanced_federated_learning/chapter-9_flare_low_level_apis/09.0_introduction/introduction.ipynb>`_

`Chapter 10: Federated XGBoost <https://github.com/NVIDIA/NVFlare/blob/main/examples/tutorials/self-paced-training/part-4_advanced_federated_learning/chapter-10_federated_XGBoost/10.0_introduction/introduction.ipynb>`_

In previous parts, we discussed the basics of federated learning, introduced the federated computing platform, simulation, deployment, and interactions, and delved into privacy and security. Now, we will explore advanced topics in federated learning:

- Different federated learning algorithms such as FedOpt, FedProx, etc.
- Various federated learning workflows: cyclic, split learning, swarm learning
- How to train or fine-tune large language models
- How to train secure federated XGBoost
- FLARE high-level vs. low-level APIs: an exploration of low-level but powerful APIs