{
  # version of the configuration
  format_version = 2

  # task data filter: if filters are provided, the filter will filter the data flow out of server to client.
  task_data_filters = []

  # task result filter: if filters are provided, the filter will filter the result flow out of client to server.
  task_result_filters = []

  # workflows: Array of workflows the control the Federated Learning workflow lifecycle.
  # One can specify multiple workflows. The NVFLARE will run them in the order specified.
  workflows = [
      {
        # 1st workflow"
        id = "scatter_and_gather"
        name = "ScatterAndGather"
        args {
            # argument of the ScatterAndGather class.
            # min number of clients required for ScatterAndGather controller to move to the next round
            # during the workflow cycle. The controller will wait until the min_clients returned from clients
            # before move to the next step.
            min_clients = 3

            # number of global round of the training.
            num_rounds = 5

            # starting round is 0-based
            start_round = 0

            # after received min number of clients' result,
            # how much time should we wait further before move to the next step
            wait_time_after_min_received = 0

            # For ScatterAndGather, the server will aggregate the weights based on the client's result.
            # the aggregator component id is named here. One can use the this ID to find the corresponding
            # aggregator component listed below
            aggregator_id = "aggregator"

            # The Scatter and Gather controller use an persistor to load the model and save the model.
            # The persistent component can be identified by component ID specified here.
            persistor_id = "persistor"

            # Shareable to a communication message, i.e. shared between clients and server.
            # Shareable generator is a component that responsible to take the model convert to/from this communication message: Shareable.
            # The component can be identified via "shareable_generator_id"
            shareable_generator_id = "shareable_generator"

            # train task name: Client will start training once received such task.
            train_task_name = "train"

            # train timeout in second. If zero, meaning no timeout.
            train_timeout = 0
        }
      }
  ]

  # List of components used in the server side workflow.
  components = [
    {
      # This is the persistence component used in above workflow.
      # JoblibModelParamPersistor is a persistor which save/read the model to/from file with JobLib format.
      id = "persistor"
      path = "nvflare.app_opt.sklearn.joblib_model_param_persistor.JoblibModelParamPersistor"

      # the persitor class take initial model specs as argument
      # This imply that the model parameters are initialized from the server-side.
      # The model paramters will be broadcast to all the clients to set up local models for training.
      args {
        initial_params {
          n_clusters = 2
        }
      }
    },
    {
      # This is the generator that convert the model to shareable communication message structure used in workflow
      id = "shareable_generator"
      name = "FullModelShareableGenerator"
      args = {}
    },
    {
      # This is the aggregator that perform the model aggregation.
      # the acutual aggregation function is defined by a "assembler" to specify how to handle the collected updates
      id = "aggregator"
      path = "nvflare.app_common.aggregators.collect_and_assemble_aggregator.CollectAndAssembleAggregator"
      args {
        assembler_id = "kmeans_assembler"
      }
    },
    {
      # This is the assembler designed for k-Means algorithm
      id = "kmeans_assembler"
      path = "kmeans_assembler.KMeansAssembler"
      args = {}
    }
  ]

}
