{
  # version of the configuration
  format_version = 2

  # This is the application script which will be invoked. Client can replace this script with user's own training script.
  app_script = "cifar10.py"

  # Additional arguments needed by the training code. For example, in lightning, these can be --trainer.batch_size=xxx.
  app_config = ""

  # Additional arguments needed by DDP.
  ddp_config = "--nnodes=1 --nproc_per_node=2 --master_port=7777"

  # Client Computing Executors.
  executors = [
    {
      # tasks the executors are defined to handle
      tasks = ["train"]

      # This particular executor
      executor {

        # Eexecutor name : PTClientAPILauncherExecutor
        # This is an executor for pytorch + Client API. The underline data exchange is using FilePipe.
        path = "nvflare.app_opt.pt.client_api_launcher_executor.PTClientAPILauncherExecutor"

        args {

          # This executor take an component named "launcher"
          launcher_id = "launcher"

          # Timeout in seconds for waiting for a heartbeat from the training script. Defaults to 30 seconds.
          # Please refer to the class docstring for all available arguments
          heartbeat_timeout = 60

          # data_exchange_path: is the directory location of the parameters exchange.
          # If empty string, it will be set to the app_dir of the running job.
          # You can also set it to an absolute path in your system.
          data_exchange_path = ""

          # format of the exchange parameters
          params_exchange_format =  "pytorch"

          # if the transfer_type is FULL, then it will be sent directly
          # if the transfer_type is DIFF, then we will calculate the
          # difference VS received parameters and send the difference
          params_transfer_type = "DIFF"

          # if training is true, the executor will expect
          # the custom code need to send back the trained parameters
          training = true

          # if global_evaluation is true, the executor will expect the
          # custom code to send back the evaluation metric
          global_evaluation = true

          # if launch_once is true, the executor will only call launcher.launch_task once
          # for the whole job, if launch_once is false, the executor will call launcher.launch_task
          # everytime it receives a task from server
          launch_once = false
        }
      }
    }
  ],

  # this defined an array of task data filters. If provided, it will control the data from server controller to client executor
  task_data_filters =  []

  # this defined an array of task result filters. If provided, it will control the result from client executor to server controller
  task_result_filters = []

  components =  [
    {
      # This "launcher" component
      id = "launcher"

      # the name of component is SubprocessLauncher and path is the class path
      path = "nvflare.app_common.launchers.subprocess_launcher.SubprocessLauncher"

      # the launcher will invoke the scrupt
      args.script = "python3 -m torch.distributed.run {ddp_config} custom/{app_script}  {app_config} "
    }
  ]
}
