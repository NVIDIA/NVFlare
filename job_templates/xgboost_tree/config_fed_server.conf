{
  # version of the configuration
  format_version = 2

  # task data filter: if filters are provided, the filter will filter the data flow out of server to client.
  task_data_filters = []

  # task result filter: if filters are provided, the filter will filter the result flow out of client to server.
  task_result_filters = []

  # workflows: Array of workflows the control the Federated Learning workflow lifecycle.
  # One can specify multiple workflows. The NVFLARE will run them in the order specified.
  workflows = [
    {
        # 1st workflow"
        id = "scatter_and_gather"
        name = "ScatterAndGather"
        args {
            # argument of the ScatterAndGather class.
            # min number of clients required for ScatterAndGather controller to move to the next round
            # during the workflow cycle. The controller will wait until the min_clients returned from clients
            # before move to the next step.
            min_clients = 3

            # number of global round of the training.
            num_rounds = 100

            # starting round is 0-based
            start_round = 0

            # after received min number of clients' result,
            # how much time should we wait further before move to the next step
            wait_time_after_min_received = 0

            # For ScatterAndGather, the server will aggregate the weights based on the client's result.
            # the aggregator component id is named here. One can use the this ID to find the corresponding
            # aggregator component listed below
            aggregator_id = "aggregator"

            # The Scatter and Gather controller use an persistor to load the model and save the model.
            # The persistent component can be identified by component ID specified here.
            persistor_id = "persistor"

            # Shareable to a communication message, i.e. shared between clients and server.
            # Shareable generator is a component that responsible to take the model convert to/from this communication message: Shareable.
            # The component can be identified via "shareable_generator_id"
            shareable_generator_id = "shareable_generator"

            # train task name: Client will start training once received such task.
            train_task_name = "train"

            # train timeout in second. If zero, meaning no timeout.
            train_timeout = 0

            # the first round will send nothing, so turning this on
            allow_empty_global_weights = true
        }
      }
  ]

  # List of components used in the server side workflow.
  components = [
    {
      # This is the persistence component used in above workflow.
      # XGBModelPersistor is a persistor which save/read the model to/from file for XGBoost method.
      id = "persistor"
      path = "nvflare.app_opt.xgboost.tree_based.model_persistor.XGBModelPersistor"

      # the persitor class takes the model filename as argument
      args {
        save_name = "xgboost_model.json"
      }
    },
    {
      # This is the generator that convert the model to shareable communication message structure used in workflow
      # designed for XGBoost model
      id = "shareable_generator"
      path = "nvflare.app_opt.xgboost.tree_based.shareable_generator.XGBModelShareableGenerator"
      args = {}
    },
    {
      # This is the aggregator that perform the model aggregation.
      # for bagging the tree updates from clients together
      id = "aggregator"
      path = "nvflare.app_opt.xgboost.tree_based.bagging_aggregator.XGBBaggingAggregator"
      args {}
    }
  ]

}
